# teaching_analytics.py - EMIæ™ºèƒ½æ•™å­¸åŠ©ç†ç³»çµ±å¾Œç«¯æ ¸å¿ƒ
# ä¿®æ”¹æ—¥æœŸï¼š2025å¹´6æœˆ28æ—¥
# ä½œè€…ï¼šå¾Œç«¯æ ¸å¿ƒé–‹ç™¼åœ˜éšŠ
# åŠŸèƒ½ï¼šAIåˆ†æå¼•æ“ã€å¿«å–ç³»çµ±ã€éŒ¯èª¤è™•ç†æ©Ÿåˆ¶

import os
import time
import logging
import datetime
from datetime import timedelta
from typing import Dict, Any, Optional, List
import json
import traceback

# ç¬¬ä¸‰æ–¹å¥—ä»¶
import google.generativeai as genai
from models import Student, Message, Analysis, db

# =================== æ—¥èªŒé…ç½® ===================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('teaching_analytics.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# =================== API é…ç½® ===================

GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    logger.warning("âš ï¸ GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šï¼ŒAIåŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")

# AIæ¨¡å‹é…ç½®
ANALYTICS_MODELS = [
    'gemini-2.0-flash-exp',
    'gemini-1.5-flash',
    'gemini-1.5-pro',
    'gemini-pro'
]

# ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹
current_analytics_model = None
analytics_model_name = ANALYTICS_MODELS[0]  # é è¨­ä½¿ç”¨æœ€æ–°æ¨¡å‹
model_switch_count = 0

# =================== å¿«å–ç³»çµ±å¯¦ä½œ ===================

# å…¨åŸŸå¿«å–å­—å…¸
analysis_cache: Dict[str, Dict[str, Any]] = {}
CACHE_DURATION = 1800  # 30åˆ†é˜ï¼ˆ1800ç§’ï¼‰

def get_cached_analysis(cache_key: str) -> Optional[Dict[str, Any]]:
    """æª¢æŸ¥ä¸¦è¿”å›å¿«å–çµæœ
    
    Args:
        cache_key (str): å¿«å–éµå€¼
        
    Returns:
        Optional[Dict[str, Any]]: å¿«å–çµæœæˆ–None
    """
    try:
        if cache_key in analysis_cache:
            cache_data = analysis_cache[cache_key]
            current_time = time.time()
            
            # æª¢æŸ¥æ˜¯å¦éæœŸ
            if current_time < cache_data['expires_at']:
                logger.info(f"ğŸ“‹ å¿«å–å‘½ä¸­: {cache_key}")
                return cache_data['result']
            else:
                # éæœŸå‰‡åˆªé™¤
                del analysis_cache[cache_key]
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†éæœŸå¿«å–: {cache_key}")
        
        return None
    except Exception as e:
        logger.error(f"ç²å–å¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def cache_analysis_result(cache_key: str, result: Dict[str, Any]) -> None:
    """å°‡åˆ†æçµæœå­˜å…¥å¿«å–
    
    Args:
        cache_key (str): å¿«å–éµå€¼
        result (Dict[str, Any]): è¦å¿«å–çš„çµæœ
    """
    try:
        current_time = time.time()
        analysis_cache[cache_key] = {
            'result': result,
            'timestamp': current_time,
            'expires_at': current_time + CACHE_DURATION
        }
        logger.info(f"ğŸ’¾ å¿«å–å„²å­˜: {cache_key} (æœ‰æ•ˆæœŸ: {CACHE_DURATION/60:.1f}åˆ†é˜)")
    except Exception as e:
        logger.error(f"å„²å­˜å¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def clear_expired_cache() -> None:
    """æ¸…ç†æ‰€æœ‰éæœŸçš„å¿«å–é …ç›®"""
    try:
        current_time = time.time()
        expired_keys = [
            key for key, data in analysis_cache.items() 
            if current_time >= data['expires_at']
        ]
        
        for key in expired_keys:
            del analysis_cache[key]
        
        if expired_keys:
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(expired_keys)} å€‹éæœŸå¿«å–é …ç›®")
    except Exception as e:
        logger.error(f"æ¸…ç†éæœŸå¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def get_cached_or_generate(cache_key: str, generator_func, *args, **kwargs) -> Dict[str, Any]:
    """çµ±ä¸€çš„å¿«å–ç²å–æˆ–ç”Ÿæˆå‡½æ•¸
    
    Args:
        cache_key (str): å¿«å–éµå€¼
        generator_func: ç”Ÿæˆå‡½æ•¸
        *args: ç”Ÿæˆå‡½æ•¸çš„ä½ç½®åƒæ•¸
        **kwargs: ç”Ÿæˆå‡½æ•¸çš„é—œéµå­—åƒæ•¸
        
    Returns:
        Dict[str, Any]: åˆ†æçµæœ
    """
    try:
        # æ¸…ç†éæœŸå¿«å–
        clear_expired_cache()
        
        # æª¢æŸ¥å¿«å–
        cached = get_cached_analysis(cache_key)
        if cached:
            return cached
        
        # ç”Ÿæˆæ–°çµæœ
        logger.info(f"ğŸ”„ ç”Ÿæˆæ–°åˆ†æ: {cache_key}")
        start_time = time.time()
        
        result = generator_func(*args, **kwargs)
        
        generation_time = time.time() - start_time
        logger.info(f"â±ï¸ åˆ†æç”Ÿæˆæ™‚é–“: {generation_time:.2f}ç§’")
        
        if result and isinstance(result, dict) and 'error' not in result:
            # æ·»åŠ ç”Ÿæˆæ™‚é–“è³‡è¨Š
            result['generation_time'] = generation_time
            result['cached'] = False
            
            cache_analysis_result(cache_key, result)
            return result
        else:
            logger.warning(f"ç”Ÿæˆçµæœç•°å¸¸: {result}")
            return {'error': 'åˆ†æç”Ÿæˆå¤±æ•—', 'status': 'error'}
            
    except Exception as e:
        logger.error(f"ç”Ÿæˆåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {'error': str(e), 'status': 'error'}

def get_cache_statistics() -> Dict[str, Any]:
    """ç²å–å¿«å–çµ±è¨ˆè³‡è¨Š
    
    Returns:
        Dict[str, Any]: å¿«å–çµ±è¨ˆè³‡è¨Š
    """
    try:
        current_time = time.time()
        total_items = len(analysis_cache)
        active_items = 0
        expired_items = 0
        
        for data in analysis_cache.values():
            if current_time < data['expires_at']:
                active_items += 1
            else:
                expired_items += 1
        
        return {
            'total_items': total_items,
            'active_items': active_items,
            'expired_items': expired_items,
            'cache_duration_minutes': CACHE_DURATION / 60,
            'memory_efficiency': f"{(active_items/max(total_items, 1)*100):.1f}%"
        }
    except Exception as e:
        logger.error(f"ç²å–å¿«å–çµ±è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {'error': str(e)}

# æª”æ¡ˆç¬¬ä¸€æ®µçµæŸ - æ¥ä¸‹ä¾†æ˜¯éŒ¯èª¤è™•ç†ç³»çµ±

# teaching_analytics.py - ç¬¬äºŒæ®µï¼šéŒ¯èª¤è™•ç†ç³»çµ±
# æ¥çºŒç¬¬ä¸€æ®µï¼šå¿«å–ç³»çµ±ä¹‹å¾Œ

# =================== éŒ¯èª¤è™•ç†ç³»çµ± ===================

def safe_ai_analysis(analysis_func, fallback_func, *args, **kwargs) -> Dict[str, Any]:
    """å®‰å…¨çš„AIåˆ†æåŸ·è¡ŒåŒ…è£å‡½æ•¸
    
    é€™å€‹å‡½æ•¸æä¾›äº†ä¸€å€‹å®‰å…¨çš„åŒ…è£å™¨ï¼Œç•¶AIåˆ†æå¤±æ•—æ™‚æœƒè‡ªå‹•åˆ‡æ›åˆ°å‚™ç”¨æ–¹æ¡ˆ
    
    Args:
        analysis_func: ä¸»è¦çš„AIåˆ†æå‡½æ•¸
        fallback_func: å‚™ç”¨åˆ†æå‡½æ•¸
        *args: å‚³éçµ¦å‡½æ•¸çš„ä½ç½®åƒæ•¸
        **kwargs: å‚³éçµ¦å‡½æ•¸çš„é—œéµå­—åƒæ•¸
        
    Returns:
        Dict[str, Any]: åˆ†æçµæœ
    """
    try:
        logger.info("ğŸ¤– å˜—è©¦AIåˆ†æ...")
        start_time = time.time()
        
        result = analysis_func(*args, **kwargs)
        
        analysis_time = time.time() - start_time
        logger.info(f"â±ï¸ AIåˆ†æå®Œæˆï¼Œè€—æ™‚: {analysis_time:.2f}ç§’")
        
        # æª¢æŸ¥çµæœæœ‰æ•ˆæ€§
        if result and isinstance(result, dict) and 'error' not in result:
            result['analysis_method'] = 'ai'
            result['analysis_time'] = analysis_time
            return result
        else:
            logger.warning(f"âš ï¸ AIåˆ†æè¿”å›ç•°å¸¸çµæœ: {result}")
            logger.info("ğŸ”„ åˆ‡æ›åˆ°å‚™ç”¨æ–¹æ¡ˆ...")
            return fallback_func(*args, **kwargs)
            
    except Exception as e:
        logger.error(f"âŒ AIåˆ†æéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        logger.info("ğŸ”„ åˆ‡æ›åˆ°å‚™ç”¨æ–¹æ¡ˆ...")
        return fallback_func(*args, **kwargs)

def get_fallback_individual_summary(student_id: int) -> Dict[str, Any]:
    """AIå¤±æ•—æ™‚çš„å€‹äººæ‘˜è¦å‚™ç”¨æ–¹æ¡ˆ
    
    ç•¶AIåˆ†æç„¡æ³•ä½¿ç”¨æ™‚ï¼Œæä¾›åŸºæ–¼è³‡æ–™åº«çµ±è¨ˆçš„åŸºæœ¬æ‘˜è¦
    
    Args:
        student_id (int): å­¸ç”ŸID
        
    Returns:
        Dict[str, Any]: å‚™ç”¨æ‘˜è¦çµæœ
    """
    try:
        logger.info(f"ğŸ“Š ç”Ÿæˆå­¸ç”Ÿ {student_id} çš„å‚™ç”¨æ‘˜è¦...")
        
        # å¾è³‡æ–™åº«ç²å–å­¸ç”Ÿè³‡æ–™
        student = Student.get_by_id(student_id)
        if not student:
            return {
                'status': 'error',
                'summary': 'âš ï¸ æ‰¾ä¸åˆ°æŒ‡å®šå­¸ç”Ÿè³‡æ–™',
                'message': 'å­¸ç”Ÿä¸å­˜åœ¨',
                'error': f'å­¸ç”ŸID {student_id} ä¸å­˜åœ¨'
            }
        
        # ç²å–å­¸ç”Ÿçš„æ‰€æœ‰è¨Šæ¯
        messages = list(Message.select().where(Message.student_id == student_id))
        
        # çµ±è¨ˆåˆ†æ
        question_count = len([m for m in messages if '?' in m.content or '?' in m.content])
        total_messages = len(messages)
        
        # è¨ˆç®—æœ€å¾Œæ´»å‹•æ™‚é–“
        last_active = None
        if messages:
            last_active = max([m.timestamp for m in messages])
        
        # è¨ˆç®—å­¸ç¿’å¤©æ•¸
        if student.created_at and messages:
            first_message = min([m.timestamp for m in messages])
            learning_days = (datetime.datetime.now() - first_message).days + 1
        else:
            learning_days = 0
        
        # ç”Ÿæˆåƒèˆ‡åº¦è©•ä¼°
        if total_messages >= 20:
            engagement_level = 'æ´»èº'
            engagement_emoji = 'ğŸ”¥'
        elif total_messages >= 10:
            engagement_level = 'ä¸€èˆ¬'
            engagement_emoji = 'ğŸ“ˆ'
        elif total_messages >= 5:
            engagement_level = 'è¼ƒä½'
            engagement_emoji = 'ğŸ“Š'
        else:
            engagement_level = 'åˆå§‹'
            engagement_emoji = 'ğŸŒ±'
        
        # è¨ˆç®—æå•ç‡
        question_rate = (question_count / max(total_messages, 1)) * 100
        
        summary_text = f"""ğŸ“Š {student.name} å­¸ç¿’æ¦‚æ³ {engagement_emoji}

ğŸ¯ **åŸºæœ¬çµ±è¨ˆ**
â€¢ ç¸½äº’å‹•æ¬¡æ•¸ï¼š{total_messages} æ¬¡
â€¢ æå•æ•¸é‡ï¼š{question_count} å€‹ ({question_rate:.1f}%)
â€¢ å­¸ç¿’å¤©æ•¸ï¼š{learning_days} å¤©
â€¢ åƒèˆ‡ç‹€æ…‹ï¼š{engagement_level}

ğŸ“… **æ´»å‹•è¨˜éŒ„**
â€¢ æœ€è¿‘æ´»å‹•ï¼š{last_active.strftime('%Y-%m-%d %H:%M') if last_active else 'ç„¡è¨˜éŒ„'}
â€¢ å¸³è™Ÿå»ºç«‹ï¼š{student.created_at.strftime('%Y-%m-%d') if student.created_at else 'æœªçŸ¥'}

ğŸ’¡ **å­¸ç¿’å»ºè­°**
â€¢ {'å»ºè­°å¢åŠ èª²å ‚äº’å‹•å’Œæå•' if total_messages < 10 else 'ä¿æŒè‰¯å¥½çš„å­¸ç¿’äº’å‹•'}
â€¢ {'å¯ä»¥å¤šå•å•é¡Œä¾†åŠ æ·±ç†è§£' if question_rate < 20 else 'æå•ç¿’æ…£è‰¯å¥½'}

âš ï¸ **ç³»çµ±æç¤º**
AIè©³ç´°åˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œä»¥ä¸Šç‚ºåŸºæ–¼è³‡æ–™åº«çš„åŸºæœ¬çµ±è¨ˆã€‚
å»ºè­°ç¨å¾Œé‡è©¦AIåˆ†æåŠŸèƒ½ä»¥ç²å¾—æ›´æ·±å…¥çš„æ´å¯Ÿã€‚"""

        return {
            'status': 'fallback',
            'summary': summary_text,
            'message': 'AIåˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œé¡¯ç¤ºåŸºæœ¬çµ±è¨ˆè³‡æ–™',
            'analysis_method': 'fallback',
            'data': {
                'student_name': student.name,
                'total_messages': total_messages,
                'question_count': question_count,
                'question_rate': question_rate,
                'learning_days': learning_days,
                'engagement_level': engagement_level,
                'last_active': last_active.isoformat() if last_active else None,
                'created_at': student.created_at.isoformat() if student.created_at else None
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ å‚™ç”¨æ‘˜è¦ç”ŸæˆéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'status': 'error',
            'summary': 'âš ï¸ ç„¡æ³•ç”Ÿæˆå­¸ç¿’æ‘˜è¦ï¼Œè«‹æª¢æŸ¥è³‡æ–™é€£æ¥ã€‚',
            'message': 'ç³»çµ±æš«æ™‚ç„¡æ³•å–å¾—å­¸ç”Ÿè³‡æ–™',
            'error': str(e),
            'analysis_method': 'error'
        }

def get_fallback_class_summary() -> Dict[str, Any]:
    """AIå¤±æ•—æ™‚çš„å…¨ç­æ‘˜è¦å‚™ç”¨æ–¹æ¡ˆ
    
    ç•¶AIåˆ†æç„¡æ³•ä½¿ç”¨æ™‚ï¼Œæä¾›åŸºæ–¼è³‡æ–™åº«çµ±è¨ˆçš„å…¨ç­æ¦‚æ³
    
    Returns:
        Dict[str, Any]: å‚™ç”¨å…¨ç­æ‘˜è¦çµæœ
    """
    try:
        logger.info("ğŸ“Š ç”Ÿæˆå…¨ç­å‚™ç”¨æ‘˜è¦...")
        
        # çµ±è¨ˆå…¨ç­è³‡æ–™
        all_students = list(Student.select())
        all_messages = list(Message.select())
        
        total_students = len(all_students)
        total_messages = len(all_messages)
        total_questions = len([m for m in all_messages if '?' in m.content or '?' in m.content])
        
        # è¨ˆç®—æ´»èºå­¸ç”Ÿæ•¸ï¼ˆ7å¤©å…§æœ‰æ´»å‹•ï¼‰
        week_ago = datetime.datetime.now() - timedelta(days=7)
        active_students = len([
            s for s in all_students 
            if s.last_active and s.last_active >= week_ago
        ])
        
        # è¨ˆç®—å¹³å‡åƒèˆ‡åº¦
        avg_participation = sum([s.participation_rate for s in all_students]) / max(total_students, 1)
        avg_messages_per_student = total_messages / max(total_students, 1)
        avg_questions_per_student = total_questions / max(total_students, 1)
        
        # ç”Ÿæˆç­ç´šè©•ä¼°
        if active_students / max(total_students, 1) >= 0.7:
            class_engagement = 'é«˜åº¦æ´»èº'
            engagement_emoji = 'ğŸ”¥'
        elif active_students / max(total_students, 1) >= 0.4:
            class_engagement = 'ä¸­ç­‰æ´»èº'
            engagement_emoji = 'ğŸ“ˆ'
        else:
            class_engagement = 'éœ€è¦é¼“å‹µ'
            engagement_emoji = 'ğŸ’ª'
        
        summary_text = f"""ğŸ“Š å…¨ç­å­¸ç¿’æ¦‚æ³ {engagement_emoji}

ğŸ‘¥ **ç­ç´šçµ±è¨ˆ**
â€¢ ç¸½å­¸ç”Ÿæ•¸ï¼š{total_students} äºº
â€¢ æ´»èºå­¸ç”Ÿï¼š{active_students} äºº ({(active_students/max(total_students, 1)*100):.1f}%)
â€¢ ç­ç´šç‹€æ…‹ï¼š{class_engagement}

ğŸ’¬ **äº’å‹•çµ±è¨ˆ**
â€¢ ç¸½äº’å‹•æ¬¡æ•¸ï¼š{total_messages} æ¬¡  
â€¢ ç¸½æå•æ•¸ï¼š{total_questions} å€‹
â€¢ å¹³å‡åƒèˆ‡åº¦ï¼š{avg_participation:.1f}%

ğŸ“ˆ **å¹³å‡è¡¨ç¾**
â€¢ å¹³å‡äº’å‹•ï¼š{avg_messages_per_student:.1f} æ¬¡/äºº
â€¢ å¹³å‡æå•ï¼š{avg_questions_per_student:.1f} å€‹/äºº
â€¢ æå•ç‡ï¼š{(total_questions/max(total_messages, 1)*100):.1f}%

ğŸ’¡ **æ•™å­¸å»ºè­°**
â€¢ {'å»ºè­°å¢åŠ èª²å ‚äº’å‹•æ´»å‹•' if avg_participation < 50 else 'ä¿æŒç›®å‰çš„æ•™å­¸æ–¹å¼'}
â€¢ {'å¯ä»¥é¼“å‹µå­¸ç”Ÿå¤šæå•' if total_questions/max(total_messages, 1) < 0.2 else 'å­¸ç”Ÿæå•ç©æ¥µåº¦è‰¯å¥½'}

âš ï¸ **ç³»çµ±æç¤º**
AIè©³ç´°åˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œä»¥ä¸Šç‚ºåŸºæ–¼è³‡æ–™åº«çš„åŸºæœ¬çµ±è¨ˆã€‚"""

        return {
            'status': 'fallback',
            'summary': summary_text,
            'message': 'AIåˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œé¡¯ç¤ºåŸºæœ¬çµ±è¨ˆè³‡æ–™',
            'analysis_method': 'fallback',
            'data': {
                'total_students': total_students,
                'active_students': active_students,
                'total_messages': total_messages,
                'total_questions': total_questions,
                'avg_participation': avg_participation,
                'avg_messages_per_student': avg_messages_per_student,
                'avg_questions_per_student': avg_questions_per_student,
                'class_engagement': class_engagement
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ å‚™ç”¨å…¨ç­æ‘˜è¦ç”ŸæˆéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'status': 'error',
            'summary': 'âš ï¸ ç„¡æ³•ç”Ÿæˆå…¨ç­æ‘˜è¦ï¼Œè«‹æª¢æŸ¥è³‡æ–™é€£æ¥ã€‚',
            'message': 'ç³»çµ±æš«æ™‚ç„¡æ³•å–å¾—ç­ç´šè³‡æ–™',
            'error': str(e),
            'analysis_method': 'error'
        }

def get_fallback_keywords() -> Dict[str, Any]:
    """AIå¤±æ•—æ™‚çš„é—œéµè©å‚™ç”¨æ–¹æ¡ˆ
    
    ç•¶AIé—œéµè©åˆ†æç„¡æ³•ä½¿ç”¨æ™‚ï¼Œæä¾›é è¨­é—œéµè©
    
    Returns:
        Dict[str, Any]: å‚™ç”¨é—œéµè©çµæœ
    """
    try:
        # å˜—è©¦å¾è³‡æ–™åº«ä¸­æå–ä¸€äº›ç°¡å–®çš„é—œéµè©
        messages = list(Message.select().limit(100))
        
        # ç°¡å–®çš„é—œéµè©çµ±è¨ˆï¼ˆåŸºæ–¼å¸¸è¦‹æ•™å­¸è©å½™ï¼‰
        common_keywords = {
            'è‹±æ–‡': 0, 'è‹±èª': 0, 'English': 0,
            'å•é¡Œ': 0, 'question': 0, 'æå•': 0,
            'èª²ç¨‹': 0, 'course': 0, 'æ•™å­¸': 0,
            'å­¸ç¿’': 0, 'learning': 0, 'study': 0,
            'ä½œæ¥­': 0, 'homework': 0, 'ç·´ç¿’': 0
        }
        
        # çµ±è¨ˆè©é »
        for message in messages:
            content = message.content.lower()
            for keyword in common_keywords:
                if keyword.lower() in content:
                    common_keywords[keyword] += 1
        
        # é¸å–æœ€å¸¸è¦‹çš„5å€‹é—œéµè©
        sorted_keywords = sorted(common_keywords.items(), key=lambda x: x[1], reverse=True)
        top_keywords = [kw[0] for kw in sorted_keywords[:5] if kw[1] > 0]
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°é—œéµè©ï¼Œä½¿ç”¨é è¨­å€¼
        if not top_keywords:
            top_keywords = ['èª²ç¨‹å…§å®¹', 'å­¸ç¿’å•é¡Œ', 'èª²å ‚äº’å‹•', 'è‹±èªæ•™å­¸', 'å­¸ç”Ÿåƒèˆ‡']
        
        return {
            'status': 'fallback',
            'keywords': top_keywords,
            'message': 'AIé—œéµè©åˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œé¡¯ç¤ºåŸºæ–¼è©é »çš„é—œéµè©',
            'analysis_method': 'fallback',
            'data': {
                'keyword_counts': dict(sorted_keywords[:10]),
                'total_messages_analyzed': len(messages)
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ å‚™ç”¨é—œéµè©ç”ŸæˆéŒ¯èª¤: {e}")
        return {
            'status': 'fallback',
            'keywords': ['èª²ç¨‹å…§å®¹', 'å­¸ç¿’å•é¡Œ', 'èª²å ‚äº’å‹•', 'è‹±èªæ•™å­¸', 'å­¸ç”Ÿåƒèˆ‡'],
            'message': 'AIé—œéµè©åˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œé¡¯ç¤ºé è¨­é—œéµè©',
            'error': str(e),
            'analysis_method': 'error'
        }

# æª”æ¡ˆç¬¬äºŒæ®µçµæŸ - æ¥ä¸‹ä¾†æ˜¯AIæœå‹™åˆå§‹åŒ–å’Œæ ¸å¿ƒå‡½æ•¸

# teaching_analytics.py - ç¬¬ä¸‰æ®µï¼šAIæœå‹™åˆå§‹åŒ–å’Œæ ¸å¿ƒå‡½æ•¸
# æ¥çºŒç¬¬äºŒæ®µï¼šéŒ¯èª¤è™•ç†ç³»çµ±ä¹‹å¾Œ

# =================== AIæœå‹™åˆå§‹åŒ– ===================

def initialize_ai_service() -> bool:
    """åˆå§‹åŒ–AIæœå‹™
    
    Returns:
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    global current_analytics_model, analytics_model_name
    
    if not GEMINI_API_KEY:
        logger.error("âŒ GEMINI_API_KEY æœªè¨­å®šï¼Œç„¡æ³•åˆå§‹åŒ–AIæœå‹™")
        return False
    
    try:
        logger.info("ğŸš€ åˆå§‹åŒ–AIæœå‹™...")
        genai.configure(api_key=GEMINI_API_KEY)
        
        # å˜—è©¦åˆå§‹åŒ–ç¬¬ä¸€å€‹å¯ç”¨çš„æ¨¡å‹
        for model_name in ANALYTICS_MODELS:
            try:
                logger.info(f"ğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
                test_model = genai.GenerativeModel(model_name)
                
                # ç°¡å–®æ¸¬è©¦
                response = test_model.generate_content("æ¸¬è©¦AIæœå‹™")
                if response and response.text:
                    current_analytics_model = test_model
                    analytics_model_name = model_name
                    logger.info(f"âœ… AIæœå‹™åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
                    return True
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} ç„¡æ³•ä½¿ç”¨: {e}")
                continue
        
        logger.error("âŒ æ‰€æœ‰æ¨¡å‹éƒ½ç„¡æ³•ä½¿ç”¨")
        return False
        
    except Exception as e:
        logger.error(f"âŒ AIæœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        return False

def call_ai_service(prompt: str, max_retries: int = 3) -> str:
    """å‘¼å«AIæœå‹™é€²è¡Œåˆ†æ
    
    Args:
        prompt (str): åˆ†ææç¤º
        max_retries (int): æœ€å¤§é‡è©¦æ¬¡æ•¸
        
    Returns:
        str: AIå›æ‡‰æ–‡å­—
    """
    global current_analytics_model, analytics_model_name
    
    if not current_analytics_model:
        if not initialize_ai_service():
            raise Exception("AIæœå‹™åˆå§‹åŒ–å¤±æ•—")
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ¤– å‘¼å«AIæœå‹™ (å˜—è©¦ {attempt + 1}/{max_retries})")
            response = current_analytics_model.generate_content(prompt)
            
            if response and response.text:
                logger.info("âœ… AIå›æ‡‰æˆåŠŸ")
                return response.text.strip()
            else:
                raise Exception("AIå›æ‡‰ç‚ºç©º")
                
        except Exception as e:
            logger.warning(f"âš ï¸ AIæœå‹™å‘¼å«å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {e}")
            
            if attempt == max_retries - 1:
                # æœ€å¾Œä¸€æ¬¡å˜—è©¦ï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹
                if switch_to_next_model():
                    logger.info("ğŸ”„ å·²åˆ‡æ›åˆ°ä¸‹ä¸€å€‹æ¨¡å‹ï¼Œå†æ¬¡å˜—è©¦...")
                    continue
                else:
                    raise Exception(f"AIæœå‹™å‘¼å«å¤±æ•—ï¼Œå·²å˜—è©¦ {max_retries} æ¬¡")
            
            time.sleep(1)  # ç¨ä½œç­‰å¾…å†é‡è©¦
    
    raise Exception("AIæœå‹™å‘¼å«è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸")

def switch_to_next_model() -> bool:
    """åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å¯ç”¨çš„AIæ¨¡å‹
    
    Returns:
        bool: åˆ‡æ›æ˜¯å¦æˆåŠŸ
    """
    global current_analytics_model, analytics_model_name, model_switch_count
    
    current_index = ANALYTICS_MODELS.index(analytics_model_name) if analytics_model_name in ANALYTICS_MODELS else 0
    
    # å˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
    for i in range(1, len(ANALYTICS_MODELS)):
        next_index = (current_index + i) % len(ANALYTICS_MODELS)
        next_model_name = ANALYTICS_MODELS[next_index]
        
        try:
            logger.info(f"ğŸ”„ åˆ‡æ›åˆ°æ¨¡å‹: {next_model_name}")
            genai.configure(api_key=GEMINI_API_KEY)
            new_model = genai.GenerativeModel(next_model_name)
            
            # æ¸¬è©¦æ–°æ¨¡å‹
            test_response = new_model.generate_content("æ¸¬è©¦")
            if test_response and test_response.text:
                current_analytics_model = new_model
                analytics_model_name = next_model_name
                model_switch_count += 1
                logger.info(f"âœ… æ¨¡å‹åˆ‡æ›æˆåŠŸ: {next_model_name}")
                return True
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ¨¡å‹ {next_model_name} åˆ‡æ›å¤±æ•—: {e}")
            continue
    
    logger.error("âŒ æ‰€æœ‰æ¨¡å‹éƒ½ç„¡æ³•ä½¿ç”¨")
    return False

# =================== AIåˆ†ææ ¸å¿ƒå‡½æ•¸ ===================

def generate_individual_summary(student_id: int) -> Dict[str, Any]:
    """å€‹äººå­¸ç¿’æ‘˜è¦ç”Ÿæˆï¼ˆå«å¿«å–å’ŒéŒ¯èª¤è™•ç†ï¼‰
    
    Args:
        student_id (int): å­¸ç”ŸID
        
    Returns:
        Dict[str, Any]: å€‹äººæ‘˜è¦åˆ†æçµæœ
    """
    cache_key = f"individual_summary_{student_id}"
    
    def _generate_summary():
        """å…§éƒ¨æ‘˜è¦ç”Ÿæˆå‡½æ•¸"""
        logger.info(f"ğŸ¯ ç”Ÿæˆå­¸ç”Ÿ {student_id} çš„å€‹äººæ‘˜è¦...")
        
        # å¾è³‡æ–™åº«ç²å–å­¸ç”Ÿçš„æ‰€æœ‰è¨Šæ¯
        student = Student.get_by_id(student_id)
        if not student:
            return {'error': 'æ‰¾ä¸åˆ°æŒ‡å®šå­¸ç”Ÿ'}
        
        messages = list(Message.select().where(
            Message.student_id == student_id
        ).order_by(Message.timestamp))
        
        if not messages:
            return {'error': 'è©²å­¸ç”Ÿæ²’æœ‰è¨Šæ¯è¨˜éŒ„'}
        
        # æº–å‚™AIåˆ†æçš„è³‡æ–™
        message_content = "\n".join([
            f"[{m.timestamp.strftime('%Y-%m-%d %H:%M')}] {m.content[:200]}"  # é™åˆ¶æ¯å‰‡è¨Šæ¯é•·åº¦
            for m in messages[-50:]  # åªå–æœ€è¿‘50å‰‡è¨Šæ¯
        ])
        
        # çµ±è¨ˆåŸºæœ¬è³‡æ–™
        question_count = len([m for m in messages if '?' in m.content])
        total_messages = len(messages)
        learning_days = (datetime.datetime.now() - messages[0].timestamp).days + 1 if messages else 0
        
        # æ§‹å»ºAIåˆ†ææç¤º
        prompt = f"""ä½œç‚ºEMIæ™ºèƒ½æ•™å­¸åŠ©ç†ï¼Œè«‹åˆ†æä»¥ä¸‹å­¸ç”Ÿçš„å­¸ç¿’è¨˜éŒ„ä¸¦ç”Ÿæˆå€‹äººå­¸ç¿’æ‘˜è¦ï¼š

**å­¸ç”ŸåŸºæœ¬è³‡è¨Šï¼š**
- å§“åï¼š{student.name}
- åƒèˆ‡åº¦ï¼š{student.participation_rate}%
- å­¸ç¿’å¤©æ•¸ï¼š{learning_days} å¤©
- ç¸½è¨Šæ¯æ•¸ï¼š{total_messages} å‰‡
- æå•æ¬¡æ•¸ï¼š{question_count} å€‹

**æœ€è¿‘å­¸ç¿’è¨˜éŒ„ï¼š**
{message_content}

è«‹ä»¥å°ˆæ¥­ä¸”å‹å–„çš„èªèª¿ï¼Œç”¨ç¹é«”ä¸­æ–‡ç”Ÿæˆçµæ§‹åŒ–çš„å€‹äººå­¸ç¿’æ‘˜è¦ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

ğŸ“Š **å­¸ç¿’åƒèˆ‡åº¦åˆ†æ**
[åˆ†æå­¸ç”Ÿçš„èª²å ‚åƒèˆ‡æƒ…æ³ã€äº’å‹•é »ç‡å’Œå­¸ç¿’ç©æ¥µæ€§]

ğŸ“š **ä¸»è¦å­¸ç¿’ä¸»é¡Œ**
[è­˜åˆ¥å­¸ç”Ÿæœ€å¸¸è¨è«–çš„å­¸ç¿’ä¸»é¡Œå’Œé—œæ³¨é‡é»]

â“ **æå•ç‰¹é»èˆ‡å­¸ç¿’é¢¨æ ¼**
[åˆ†æå­¸ç”Ÿçš„æå•æ¨¡å¼ã€å­¸ç¿’åå¥½å’ŒèªçŸ¥ç‰¹é»]

ğŸ’¡ **å€‹äººåŒ–å­¸ç¿’å»ºè­°**
[æä¾›å…·é«”ã€å¯è¡Œçš„å­¸ç¿’æ”¹é€²å»ºè­°å’Œç™¼å±•æ–¹å‘]

ğŸ“ˆ **å­¸ç¿’é€²å±•è©•ä¼°**
[è©•ä¼°å­¸ç¿’æˆæ•ˆå’Œæœªä¾†ç™¼å±•æ½œåŠ›]

è«‹ç¢ºä¿æ‘˜è¦å…§å®¹å…·é«”ã€æœ‰å»ºè¨­æ€§ï¼Œä¸¦ç¬¦åˆEMIæ•™å­¸ç’°å¢ƒçš„ç‰¹é»ã€‚"""

        # å‘¼å«AIæœå‹™
        ai_response = call_ai_service(prompt)
        
        return {
            'status': 'success',
            'summary': ai_response,
            'student_name': student.name,
            'message_count': total_messages,
            'question_count': question_count,
            'learning_days': learning_days,
            'analysis_model': analytics_model_name,
            'generated_at': datetime.datetime.now().isoformat()
        }
    
    # ä½¿ç”¨å¿«å–ç³»çµ±å’ŒéŒ¯èª¤è™•ç†
    return get_cached_or_generate(
        cache_key, 
        lambda: safe_ai_analysis(_generate_summary, get_fallback_individual_summary, student_id)
    )

def generate_class_summary() -> Dict[str, Any]:
    """å…¨ç­å­¸ç¿’æ‘˜è¦ç”Ÿæˆï¼ˆå«å¿«å–å’ŒéŒ¯èª¤è™•ç†ï¼‰
    
    Returns:
        Dict[str, Any]: å…¨ç­æ‘˜è¦åˆ†æçµæœ
    """
    cache_key = "class_summary"
    
    def _generate_summary():
        """å…§éƒ¨å…¨ç­æ‘˜è¦ç”Ÿæˆå‡½æ•¸"""
        logger.info("ğŸ« ç”Ÿæˆå…¨ç­å­¸ç¿’æ‘˜è¦...")
        
        # ç²å–æ‰€æœ‰å­¸ç”Ÿå’Œè¨Šæ¯
        all_students = list(Student.select())
        all_messages = list(Message.select().order_by(Message.timestamp.desc()))
        
        if not all_students or not all_messages:
            return {'error': 'æ‰¾ä¸åˆ°ç­ç´šè³‡æ–™'}
        
        # çµ±è¨ˆç­ç´šåŸºæœ¬è³‡æ–™
        total_students = len(all_students)
        total_messages = len(all_messages)
        total_questions = len([m for m in all_messages if '?' in m.content])
        
        # è¨ˆç®—æ´»èºå­¸ç”Ÿ
        week_ago = datetime.datetime.now() - timedelta(days=7)
        active_students = len([s for s in all_students if s.last_active and s.last_active >= week_ago])
        
        # æº–å‚™AIåˆ†æè³‡æ–™ï¼ˆæœ€è¿‘100å‰‡è¨Šæ¯ï¼‰
        recent_messages = all_messages[:100]
        message_content = "\n".join([
            f"[å­¸ç”Ÿ{m.student_id}] {m.content[:150]}" 
            for m in recent_messages
        ])
        
        # å­¸ç”Ÿåƒèˆ‡åº¦åˆ†å¸ƒ
        high_participation = len([s for s in all_students if s.participation_rate >= 70])
        medium_participation = len([s for s in all_students if 40 <= s.participation_rate < 70])
        low_participation = len([s for s in all_students if s.participation_rate < 40])
        
        prompt = f"""ä½œç‚ºEMIæ™ºèƒ½æ•™å­¸åŠ©ç†ï¼Œè«‹åˆ†æä»¥ä¸‹å…¨ç­å­¸ç¿’è¨˜éŒ„ä¸¦ç”Ÿæˆç­ç´šå­¸ç¿’æ‘˜è¦ï¼š

**ç­ç´šåŸºæœ¬æ¦‚æ³ï¼š**
- ç¸½å­¸ç”Ÿæ•¸ï¼š{total_students} äºº
- æ´»èºå­¸ç”Ÿï¼š{active_students} äºº
- ç¸½è¨Šæ¯æ•¸ï¼š{total_messages} å‰‡
- ç¸½æå•æ•¸ï¼š{total_questions} å€‹
- å¹³å‡åƒèˆ‡åº¦ï¼š{sum([s.participation_rate for s in all_students]) / max(total_students, 1):.1f}%

**åƒèˆ‡åº¦åˆ†å¸ƒï¼š**
- é«˜åƒèˆ‡åº¦ (â‰¥70%)ï¼š{high_participation} äºº
- ä¸­åƒèˆ‡åº¦ (40-69%)ï¼š{medium_participation} äºº  
- ä½åƒèˆ‡åº¦ (<40%)ï¼š{low_participation} äºº

**æœ€è¿‘ç­ç´šäº’å‹•è¨˜éŒ„ï¼š**
{message_content}

è«‹ç”¨ç¹é«”ä¸­æ–‡ç”Ÿæˆçµæ§‹åŒ–çš„ç­ç´šå­¸ç¿’æ‘˜è¦ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

ğŸ“Š **æ•´é«”å­¸ç¿’è¶¨å‹¢åˆ†æ**
[åˆ†æç­ç´šæ•´é«”çš„å­¸ç¿’è¡¨ç¾ã€åƒèˆ‡è¶¨å‹¢å’Œç™¼å±•æ–¹å‘]

ğŸ“š **ç†±é–€å­¸ç¿’ä¸»é¡Œèˆ‡é‡é»**
[è­˜åˆ¥ç­ç´šæœ€å¸¸è¨è«–çš„å­¸ç¿’ä¸»é¡Œå’Œå…±åŒé—œæ³¨é»]

ğŸ‘¥ **ç­ç´šåƒèˆ‡ç‹€æ³è©•ä¼°**
[è©•ä¼°å­¸ç”Ÿåƒèˆ‡åº¦åˆ†å¸ƒã€äº’å‹•å“è³ªå’Œèª²å ‚æ°›åœ]

ğŸ¯ **æ•™å­¸æ•ˆæœåˆ†æ**
[åˆ†æç•¶å‰æ•™å­¸æ–¹æ³•çš„æ•ˆæœå’Œå­¸ç”Ÿå›é¥‹æƒ…æ³]

ğŸ’¡ **ç­ç´šç®¡ç†å»ºè­°**
[æä¾›å…·é«”çš„æ•™å­¸ç­–ç•¥å»ºè­°å’Œç­ç´šç®¡ç†æ”¹é€²æ–¹æ¡ˆ]

ğŸ“ˆ **ç™¼å±•æ½›åŠ›èˆ‡æŒ‘æˆ°**
[è­˜åˆ¥ç­ç´šç™¼å±•æ©Ÿæœƒå’Œéœ€è¦é—œæ³¨çš„å•é¡Œ]

è«‹ç¢ºä¿å»ºè­°å…·é«”å¯è¡Œï¼Œç¬¦åˆEMIæ•™å­¸ç’°å¢ƒçš„ç‰¹é»ã€‚"""

        # å‘¼å«AIæœå‹™
        ai_response = call_ai_service(prompt)
        
        return {
            'status': 'success',
            'summary': ai_response,
            'total_students': total_students,
            'total_messages': total_messages,
            'total_questions': total_questions,
            'active_students': active_students,
            'analysis_model': analytics_model_name,
            'generated_at': datetime.datetime.now().isoformat()
        }
    
    # ä½¿ç”¨å¿«å–ç³»çµ±å’ŒéŒ¯èª¤è™•ç†
    return get_cached_or_generate(
        cache_key,
        lambda: safe_ai_analysis(_generate_summary, get_fallback_class_summary)
    )

def extract_learning_keywords() -> Dict[str, Any]:
    """æå–å­¸ç¿’é—œéµè©ï¼ˆå«å¿«å–å’ŒéŒ¯èª¤è™•ç†ï¼‰
    
    Returns:
        Dict[str, Any]: é—œéµè©åˆ†æçµæœ
    """
    cache_key = "learning_keywords"
    
    def _extract_keywords():
        """å…§éƒ¨é—œéµè©æå–å‡½æ•¸"""
        logger.info("ğŸ” æå–å­¸ç¿’é—œéµè©...")
        
        # ç²å–æ‰€æœ‰è¨Šæ¯å…§å®¹
        all_messages = list(Message.select().order_by(Message.timestamp.desc()).limit(200))
        
        if not all_messages:
            return {'error': 'æ‰¾ä¸åˆ°è¨Šæ¯è³‡æ–™'}
        
        # åˆä½µè¨Šæ¯å…§å®¹
        message_content = " ".join([m.content for m in all_messages])
        
        prompt = f"""ä½œç‚ºEMIæ™ºèƒ½æ•™å­¸åŠ©ç†ï¼Œè«‹å¾ä»¥ä¸‹å­¸ç¿’è¨˜éŒ„ä¸­æå–æœ€é‡è¦çš„å­¸ç¿’é—œéµè©ï¼š

**å­¸ç¿’å…§å®¹æ¨£æœ¬ï¼š**
{message_content[:2000]}  # é™åˆ¶é•·åº¦é¿å…è¶…å‡ºé™åˆ¶

**åˆ†æè¦æ±‚ï¼š**
1. æå–5-8å€‹æœ€é‡è¦çš„å­¸ç¿’é—œéµè©
2. é—œéµè©è¦èƒ½ä»£è¡¨ä¸»è¦å­¸ç¿’ä¸»é¡Œå’Œæ•™å­¸é‡é»
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡
4. æ¯å€‹é—œéµè©ä¸è¶…é4å€‹å­—
5. å„ªå…ˆé¸æ“‡EMIæ•™å­¸ç›¸é—œçš„è©å½™

**è¼¸å‡ºæ ¼å¼ï¼š**
è«‹åªè¿”å›é—œéµè©åˆ—è¡¨ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚ï¼š
è‹±èªå­¸ç¿’,èª²å ‚äº’å‹•,å­¸ç¿’å•é¡Œ,æ•™å­¸å…§å®¹,å­¸ç”Ÿåƒèˆ‡

ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–èªªæ˜æ–‡å­—ã€‚"""

        # å‘¼å«AIæœå‹™
        ai_response = call_ai_service(prompt)
        
        # è§£æé—œéµè©
        keywords = [kw.strip() for kw in ai_response.split(',') if kw.strip()]
        
        # é™åˆ¶é—œéµè©æ•¸é‡
        keywords = keywords[:8] if len(keywords) > 8 else keywords
        
        # å¦‚æœé—œéµè©å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›é è¨­é—œéµè©
        if len(keywords) < 3:
            default_keywords = ['EMIæ•™å­¸', 'è‹±èªå­¸ç¿’', 'èª²å ‚äº’å‹•', 'å­¸ç¿’å•é¡Œ', 'æ•™å­¸å…§å®¹']
            keywords.extend(default_keywords)
            keywords = list(set(keywords))[:8]  # å»é‡ä¸¦é™åˆ¶æ•¸é‡
        
        return {
            'status': 'success',
            'keywords': keywords,
            'analysis_model': analytics_model_name,
            'message_count': len(all_messages),
            'generated_at': datetime.datetime.now().isoformat()
        }
    
    # ä½¿ç”¨å¿«å–ç³»çµ±å’ŒéŒ¯èª¤è™•ç†
    return get_cached_or_generate(
        cache_key,
        lambda: safe_ai_analysis(_extract_keywords, get_fallback_keywords)
    )

# æª”æ¡ˆç¬¬ä¸‰æ®µçµæŸ - æ¥ä¸‹ä¾†æ˜¯TSVåŒ¯å‡ºåŠŸèƒ½

# teaching_analytics.py - ç¬¬å››æ®µï¼šTSVåŒ¯å‡ºåŠŸèƒ½
# æ¥çºŒç¬¬ä¸‰æ®µï¼šAIåˆ†ææ ¸å¿ƒå‡½æ•¸ä¹‹å¾Œ

# =================== TSVåŒ¯å‡ºåŠŸèƒ½ ===================

def export_student_questions_tsv(student_id: int) -> Dict[str, Any]:
    """åŒ¯å‡ºå€‹åˆ¥å­¸ç”Ÿçš„æå•è¨˜éŒ„ç‚ºTSVæ ¼å¼
    
    Args:
        student_id (int): å­¸ç”ŸID
        
    Returns:
        Dict[str, Any]: TSVåŒ¯å‡ºçµæœ
    """
    try:
        logger.info(f"ğŸ“„ åŒ¯å‡ºå­¸ç”Ÿ {student_id} çš„æå•è¨˜éŒ„...")
        
        # æª¢æŸ¥å­¸ç”Ÿæ˜¯å¦å­˜åœ¨
        student = Student.get_by_id(student_id)
        if not student:
            return {
                'error': 'æ‰¾ä¸åˆ°æŒ‡å®šå­¸ç”Ÿ',
                'status': 'error'
            }
        
        # ç²å–è©²å­¸ç”Ÿçš„æ‰€æœ‰åŒ…å«å•è™Ÿçš„è¨Šæ¯
        question_messages = list(Message.select().where(
            (Message.student_id == student_id) & 
            ((Message.content.contains('?')) | (Message.content.contains('ï¼Ÿ')))
        ).order_by(Message.timestamp))
        
        if not question_messages:
            return {
                'error': 'è©²å­¸ç”Ÿæ²’æœ‰æå•è¨˜éŒ„',
                'status': 'no_data',
                'student_name': student.name
            }
        
        # ç”ŸæˆTSVå…§å®¹
        tsv_lines = ['å­¸ç”Ÿå§“å\tæå•å…§å®¹\tæå•æ™‚é–“\tè¨Šæ¯é¡å‹\tå­—æ•¸']
        
        for message in question_messages:
            # æ ¼å¼åŒ–æ™‚é–“
            formatted_time = message.timestamp.strftime('%Y-%m-%d %H:%M:%S')
            
            # æ¸…ç†å…§å®¹ä¸­çš„è£½è¡¨ç¬¦ã€æ›è¡Œç¬¦å’Œå›è»Šç¬¦
            clean_content = message.content.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
            clean_content = clean_content.strip()
            
            # è¨ˆç®—å­—æ•¸
            word_count = len(clean_content)
            
            # åˆ¤æ–·è¨Šæ¯é¡å‹
            message_type = getattr(message, 'message_type', 'ä¸€èˆ¬æå•')
            
            # æ·»åŠ åˆ°TSV
            tsv_lines.append(f'{student.name}\t{clean_content}\t{formatted_time}\t{message_type}\t{word_count}')
        
        tsv_content = '\n'.join(tsv_lines)
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'student_{student_id}_{student.name}_questions_{timestamp}.tsv'
        
        logger.info(f"âœ… æˆåŠŸåŒ¯å‡º {len(question_messages)} å€‹æå•è¨˜éŒ„")
        
        return {
            'status': 'success',
            'content': tsv_content,
            'student_name': student.name,
            'question_count': len(question_messages),
            'filename': filename,
            'generated_at': datetime.datetime.now().isoformat(),
            'file_size': len(tsv_content.encode('utf-8'))
        }
        
    except Exception as e:
        logger.error(f"âŒ åŒ¯å‡ºå­¸ç”Ÿæå•TSVéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'error': f'åŒ¯å‡ºå¤±æ•—: {str(e)}',
            'status': 'error'
        }

def export_all_questions_tsv() -> Dict[str, Any]:
    """åŒ¯å‡ºæ‰€æœ‰å­¸ç”Ÿçš„æå•è¨˜éŒ„ç‚ºTSVæ ¼å¼
    
    Returns:
        Dict[str, Any]: TSVåŒ¯å‡ºçµæœ
    """
    try:
        logger.info("ğŸ“„ åŒ¯å‡ºæ‰€æœ‰å­¸ç”Ÿçš„æå•è¨˜éŒ„...")
        
        # ç²å–æ‰€æœ‰åŒ…å«å•è™Ÿçš„è¨Šæ¯ï¼Œä¸¦åŒ…å«å­¸ç”Ÿè³‡è¨Š
        question_messages = list(
            Message.select(Message, Student.name.alias('student_name'))
            .join(Student)
            .where((Message.content.contains('?')) | (Message.content.contains('ï¼Ÿ')))
            .order_by(Message.timestamp)
        )
        
        if not question_messages:
            return {
                'error': 'æ²’æœ‰æ‰¾åˆ°ä»»ä½•æå•è¨˜éŒ„',
                'status': 'no_data'
            }
        
        # ç”ŸæˆTSVå…§å®¹
        tsv_lines = ['å­¸ç”Ÿå§“å\tå­¸ç”ŸID\tæå•å…§å®¹\tæå•æ™‚é–“\tè¨Šæ¯é¡å‹\tå­—æ•¸\tåƒèˆ‡åº¦']
        
        # çµ±è¨ˆè³‡æ–™
        student_question_counts = {}
        
        for message in question_messages:
            # æ ¼å¼åŒ–æ™‚é–“
            formatted_time = message.timestamp.strftime('%Y-%m-%d %H:%M:%S')
            
            # æ¸…ç†å…§å®¹
            clean_content = message.content.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
            clean_content = clean_content.strip()
            
            # è¨ˆç®—å­—æ•¸
            word_count = len(clean_content)
            
            # ç²å–å­¸ç”Ÿè³‡è¨Š
            student = message.student
            student_name = student.name
            student_id = student.id
            participation_rate = student.participation_rate
            
            # çµ±è¨ˆå­¸ç”Ÿæå•æ¬¡æ•¸
            if student_id not in student_question_counts:
                student_question_counts[student_id] = 0
            student_question_counts[student_id] += 1
            
            # åˆ¤æ–·è¨Šæ¯é¡å‹
            message_type = getattr(message, 'message_type', 'ä¸€èˆ¬æå•')
            
            # æ·»åŠ åˆ°TSV
            tsv_lines.append(
                f'{student_name}\t{student_id}\t{clean_content}\t{formatted_time}\t{message_type}\t{word_count}\t{participation_rate}%'
            )
        
        tsv_content = '\n'.join(tsv_lines)
        
        # ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
        total_students_with_questions = len(student_question_counts)
        total_questions = len(question_messages)
        avg_questions_per_student = total_questions / max(total_students_with_questions, 1)
        
        # æ‰¾å‡ºæœ€æ´»èºçš„æå•å­¸ç”Ÿ
        top_questioners = sorted(
            student_question_counts.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'all_students_questions_{timestamp}.tsv'
        
        logger.info(f"âœ… æˆåŠŸåŒ¯å‡º {total_questions} å€‹æå•è¨˜éŒ„ï¼Œæ¶µè“‹ {total_students_with_questions} ä½å­¸ç”Ÿ")
        
        return {
            'status': 'success',
            'content': tsv_content,
            'total_questions': total_questions,
            'total_students_with_questions': total_students_with_questions,
            'avg_questions_per_student': round(avg_questions_per_student, 2),
            'top_questioners': top_questioners,
            'filename': filename,
            'generated_at': datetime.datetime.now().isoformat(),
            'file_size': len(tsv_content.encode('utf-8'))
        }
        
    except Exception as e:
        logger.error(f"âŒ åŒ¯å‡ºæ‰€æœ‰æå•TSVéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'error': f'åŒ¯å‡ºå¤±æ•—: {str(e)}',
            'status': 'error'
        }

def export_student_analytics_tsv(student_id: int) -> Dict[str, Any]:
    """åŒ¯å‡ºå€‹åˆ¥å­¸ç”Ÿçš„å®Œæ•´åˆ†æè³‡æ–™ç‚ºTSVæ ¼å¼
    
    Args:
        student_id (int): å­¸ç”ŸID
        
    Returns:
        Dict[str, Any]: TSVåŒ¯å‡ºçµæœ
    """
    try:
        logger.info(f"ğŸ“Š åŒ¯å‡ºå­¸ç”Ÿ {student_id} çš„å®Œæ•´åˆ†æè³‡æ–™...")
        
        # æª¢æŸ¥å­¸ç”Ÿæ˜¯å¦å­˜åœ¨
        student = Student.get_by_id(student_id)
        if not student:
            return {
                'error': 'æ‰¾ä¸åˆ°æŒ‡å®šå­¸ç”Ÿ',
                'status': 'error'
            }
        
        # ç²å–å­¸ç”Ÿçš„æ‰€æœ‰è¨Šæ¯
        all_messages = list(Message.select().where(
            Message.student_id == student_id
        ).order_by(Message.timestamp))
        
        if not all_messages:
            return {
                'error': 'è©²å­¸ç”Ÿæ²’æœ‰è¨Šæ¯è¨˜éŒ„',
                'status': 'no_data',
                'student_name': student.name
            }
        
        # ç”ŸæˆTSVå…§å®¹
        tsv_lines = ['æ™‚é–“\tå…§å®¹\té¡å‹\tå­—æ•¸\tæ˜¯å¦æå•\tåƒèˆ‡åº¦åˆ†æ•¸']
        
        for message in all_messages:
            # æ ¼å¼åŒ–æ™‚é–“
            formatted_time = message.timestamp.strftime('%Y-%m-%d %H:%M:%S')
            
            # æ¸…ç†å…§å®¹
            clean_content = message.content.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
            clean_content = clean_content.strip()
            
            # è¨ˆç®—å­—æ•¸
            word_count = len(clean_content)
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºæå•
            is_question = 'æ˜¯' if ('?' in clean_content or 'ï¼Ÿ' in clean_content) else 'å¦'
            
            # è¨ˆç®—åƒèˆ‡åº¦åˆ†æ•¸ï¼ˆç°¡å–®è©•åˆ†ï¼‰
            participation_score = min(10, max(1, word_count // 10))
            
            # è¨Šæ¯é¡å‹
            message_type = getattr(message, 'message_type', 'ä¸€èˆ¬è¨Šæ¯')
            
            # æ·»åŠ åˆ°TSV
            tsv_lines.append(
                f'{formatted_time}\t{clean_content}\t{message_type}\t{word_count}\t{is_question}\t{participation_score}'
            )
        
        tsv_content = '\n'.join(tsv_lines)
        
        # ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
        total_messages = len(all_messages)
        question_count = len([m for m in all_messages if '?' in m.content or 'ï¼Ÿ' in m.content])
        avg_word_count = sum([len(m.content) for m in all_messages]) / max(total_messages, 1)
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'student_{student_id}_{student.name}_analytics_{timestamp}.tsv'
        
        logger.info(f"âœ… æˆåŠŸåŒ¯å‡ºå­¸ç”Ÿå®Œæ•´åˆ†æè³‡æ–™ï¼ŒåŒ…å« {total_messages} å‰‡è¨Šæ¯")
        
        return {
            'status': 'success',
            'content': tsv_content,
            'student_name': student.name,
            'total_messages': total_messages,
            'question_count': question_count,
            'avg_word_count': round(avg_word_count, 2),
            'filename': filename,
            'generated_at': datetime.datetime.now().isoformat(),
            'file_size': len(tsv_content.encode('utf-8'))
        }
        
    except Exception as e:
        logger.error(f"âŒ åŒ¯å‡ºå­¸ç”Ÿåˆ†æTSVéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'error': f'åŒ¯å‡ºå¤±æ•—: {str(e)}',
            'status': 'error'
        }

def export_class_analytics_tsv() -> Dict[str, Any]:
    """åŒ¯å‡ºå…¨ç­åˆ†æè³‡æ–™ç‚ºTSVæ ¼å¼
    
    Returns:
        Dict[str, Any]: TSVåŒ¯å‡ºçµæœ
    """
    try:
        logger.info("ğŸ“Š åŒ¯å‡ºå…¨ç­åˆ†æè³‡æ–™...")
        
        # ç²å–æ‰€æœ‰å­¸ç”Ÿ
        all_students = list(Student.select())
        
        if not all_students:
            return {
                'error': 'æ²’æœ‰æ‰¾åˆ°å­¸ç”Ÿè³‡æ–™',
                'status': 'no_data'
            }
        
        # ç”ŸæˆTSVå…§å®¹
        tsv_lines = ['å­¸ç”ŸID\tå­¸ç”Ÿå§“å\tåƒèˆ‡åº¦\tè¨Šæ¯æ•¸\tæå•æ•¸\tæœ€å¾Œæ´»å‹•\tå»ºç«‹æ™‚é–“\tæ´»èºå¤©æ•¸\tå¹³å‡å­—æ•¸']
        
        total_stats = {
            'total_messages': 0,
            'total_questions': 0,
            'total_participation': 0
        }
        
        for student in all_students:
            # ç²å–å­¸ç”Ÿçš„è¨Šæ¯çµ±è¨ˆ
            student_messages = list(Message.select().where(Message.student_id == student.id))
            message_count = len(student_messages)
            question_count = len([m for m in student_messages if '?' in m.content or 'ï¼Ÿ' in m.content])
            
            # è¨ˆç®—å¹³å‡å­—æ•¸
            avg_word_count = 0
            if student_messages:
                total_words = sum([len(m.content) for m in student_messages])
                avg_word_count = total_words / message_count
            
            # æ ¼å¼åŒ–æ™‚é–“
            last_active = student.last_active.strftime('%Y-%m-%d %H:%M:%S') if student.last_active else 'æœªçŸ¥'
            created_at = student.created_at.strftime('%Y-%m-%d') if student.created_at else 'æœªçŸ¥'
            
            # è¨ˆç®—æ´»èºå¤©æ•¸
            active_days = student.active_days if hasattr(student, 'active_days') else 0
            
            # æ›´æ–°ç¸½çµ±è¨ˆ
            total_stats['total_messages'] += message_count
            total_stats['total_questions'] += question_count
            total_stats['total_participation'] += student.participation_rate
            
            # æ·»åŠ åˆ°TSV
            tsv_lines.append(
                f'{student.id}\t{student.name}\t{student.participation_rate}%\t{message_count}\t{question_count}\t{last_active}\t{created_at}\t{active_days}\t{avg_word_count:.1f}'
            )
        
        tsv_content = '\n'.join(tsv_lines)
        
        # è¨ˆç®—ç­ç´šå¹³å‡å€¼
        total_students = len(all_students)
        avg_participation = total_stats['total_participation'] / max(total_students, 1)
        avg_messages_per_student = total_stats['total_messages'] / max(total_students, 1)
        avg_questions_per_student = total_stats['total_questions'] / max(total_students, 1)
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'class_analytics_{timestamp}.tsv'
        
        logger.info(f"âœ… æˆåŠŸåŒ¯å‡ºå…¨ç­åˆ†æè³‡æ–™ï¼ŒåŒ…å« {total_students} ä½å­¸ç”Ÿ")
        
        return {
            'status': 'success',
            'content': tsv_content,
            'total_students': total_students,
            'total_messages': total_stats['total_messages'],
            'total_questions': total_stats['total_questions'],
            'avg_participation': round(avg_participation, 2),
            'avg_messages_per_student': round(avg_messages_per_student, 2),
            'avg_questions_per_student': round(avg_questions_per_student, 2),
            'filename': filename,
            'generated_at': datetime.datetime.now().isoformat(),
            'file_size': len(tsv_content.encode('utf-8'))
        }
        
    except Exception as e:
        logger.error(f"âŒ åŒ¯å‡ºå…¨ç­åˆ†æTSVéŒ¯èª¤: {e}")
        logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")
        return {
            'error': f'åŒ¯å‡ºå¤±æ•—: {str(e)}',
            'status': 'error'
        }

# æª”æ¡ˆç¬¬å››æ®µçµæŸ - æ¥ä¸‹ä¾†æ˜¯ç³»çµ±ç®¡ç†å’Œåˆå§‹åŒ–å‡½æ•¸

# teaching_analytics.py - ç¬¬äº”æ®µï¼šç³»çµ±ç®¡ç†å’Œåˆå§‹åŒ–å‡½æ•¸
# æ¥çºŒç¬¬å››æ®µï¼šTSVåŒ¯å‡ºåŠŸèƒ½ä¹‹å¾Œ

# =================== ç³»çµ±ç®¡ç†å‡½æ•¸ ===================

def get_system_status() -> Dict[str, Any]:
    """ç²å–ç³»çµ±ç‹€æ…‹è³‡è¨Š
    
    Returns:
        Dict[str, Any]: ç³»çµ±ç‹€æ…‹è³‡è¨Š
    """
    try:
        # æª¢æŸ¥AIæœå‹™ç‹€æ…‹
        ai_status = 'available' if current_analytics_model else 'unavailable'
        
        # æª¢æŸ¥è³‡æ–™åº«é€£æ¥
        try:
            total_students = Student.select().count()
            total_messages = Message.select().count()
            db_status = 'connected'
        except Exception:
            total_students = 0
            total_messages = 0
            db_status = 'error'
        
        # ç²å–å¿«å–çµ±è¨ˆ
        cache_stats = get_cache_statistics()
        
        # è¨ˆç®—ç³»çµ±è² è¼‰
        system_load = 'low'
        if cache_stats.get('active_items', 0) > 50:
            system_load = 'high'
        elif cache_stats.get('active_items', 0) > 20:
            system_load = 'medium'
        
        return {
            'status': 'operational',
            'ai_service': {
                'status': ai_status,
                'current_model': analytics_model_name,
                'model_switches': model_switch_count
            },
            'database': {
                'status': db_status,
                'total_students': total_students,
                'total_messages': total_messages
            },
            'cache': cache_stats,
            'system_load': system_load,
            'uptime_info': {
                'cache_duration_minutes': CACHE_DURATION / 60,
                'available_models': len(ANALYTICS_MODELS)
            },
            'last_check': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ç³»çµ±ç‹€æ…‹éŒ¯èª¤: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'last_check': datetime.datetime.now().isoformat()
        }

def perform_system_health_check() -> Dict[str, Any]:
    """åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥
    
    Returns:
        Dict[str, Any]: å¥åº·æª¢æŸ¥çµæœ
    """
    try:
        logger.info("ğŸ¥ åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥...")
        
        health_results = {
            'overall_status': 'healthy',
            'checks': {},
            'warnings': [],
            'errors': [],
            'recommendations': []
        }
        
        # 1. AIæœå‹™æª¢æŸ¥
        try:
            if current_analytics_model:
                test_response = call_ai_service("å¥åº·æª¢æŸ¥æ¸¬è©¦")
                if test_response:
                    health_results['checks']['ai_service'] = 'pass'
                else:
                    health_results['checks']['ai_service'] = 'fail'
                    health_results['errors'].append('AIæœå‹™å›æ‡‰ç•°å¸¸')
            else:
                health_results['checks']['ai_service'] = 'fail'
                health_results['errors'].append('AIæœå‹™æœªåˆå§‹åŒ–')
        except Exception as e:
            health_results['checks']['ai_service'] = 'fail'
            health_results['errors'].append(f'AIæœå‹™æª¢æŸ¥å¤±æ•—: {str(e)}')
        
        # 2. è³‡æ–™åº«é€£æ¥æª¢æŸ¥
        try:
            db.execute_sql("SELECT 1")
            student_count = Student.select().count()
            message_count = Message.select().count()
            
            health_results['checks']['database'] = 'pass'
            health_results['checks']['data_availability'] = 'pass' if student_count > 0 and message_count > 0 else 'warning'
            
            if student_count == 0:
                health_results['warnings'].append('æ²’æœ‰å­¸ç”Ÿè³‡æ–™')
            if message_count == 0:
                health_results['warnings'].append('æ²’æœ‰è¨Šæ¯è³‡æ–™')
                
        except Exception as e:
            health_results['checks']['database'] = 'fail'
            health_results['errors'].append(f'è³‡æ–™åº«é€£æ¥å¤±æ•—: {str(e)}')
        
        # 3. å¿«å–ç³»çµ±æª¢æŸ¥
        try:
            cache_stats = get_cache_statistics()
            if 'error' in cache_stats:
                health_results['checks']['cache_system'] = 'fail'
                health_results['errors'].append('å¿«å–ç³»çµ±ç•°å¸¸')
            else:
                health_results['checks']['cache_system'] = 'pass'
                
                # æª¢æŸ¥å¿«å–æ•ˆç‡
                if cache_stats.get('expired_items', 0) > cache_stats.get('active_items', 0):
                    health_results['warnings'].append('å¿«å–éæœŸé …ç›®éå¤šï¼Œå»ºè­°æ¸…ç†')
                    health_results['recommendations'].append('åŸ·è¡Œå¿«å–æ¸…ç†')
                    
        except Exception as e:
            health_results['checks']['cache_system'] = 'fail'
            health_results['errors'].append(f'å¿«å–ç³»çµ±æª¢æŸ¥å¤±æ•—: {str(e)}')
        
        # 4. APIé‡‘é‘°æª¢æŸ¥
        if not GEMINI_API_KEY:
            health_results['checks']['api_key'] = 'fail'
            health_results['errors'].append('GEMINI_API_KEY æœªè¨­å®š')
        else:
            health_results['checks']['api_key'] = 'pass'
        
        # 5. æ¨¡å‹åˆ‡æ›é »ç‡æª¢æŸ¥
        if model_switch_count > 10:
            health_results['warnings'].append(f'æ¨¡å‹åˆ‡æ›éæ–¼é »ç¹ ({model_switch_count} æ¬¡)')
            health_results['recommendations'].append('æª¢æŸ¥ç¶²è·¯é€£æ¥å’ŒAPIé…é¡')
        
        # æ±ºå®šæ•´é«”ç‹€æ…‹
        if health_results['errors']:
            health_results['overall_status'] = 'unhealthy'
        elif health_results['warnings']:
            health_results['overall_status'] = 'warning'
        else:
            health_results['overall_status'] = 'healthy'
        
        # æ·»åŠ å»ºè­°
        if health_results['overall_status'] == 'healthy':
            health_results['recommendations'].append('ç³»çµ±é‹ä½œæ­£å¸¸')
        
        health_results['check_time'] = datetime.datetime.now().isoformat()
        
        logger.info(f"ğŸ¥ å¥åº·æª¢æŸ¥å®Œæˆï¼Œç‹€æ…‹: {health_results['overall_status']}")
        
        return health_results
        
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±å¥åº·æª¢æŸ¥éŒ¯èª¤: {e}")
        return {
            'overall_status': 'error',
            'error': str(e),
            'check_time': datetime.datetime.now().isoformat()
        }

def clear_all_cache() -> Dict[str, Any]:
    """æ¸…é™¤æ‰€æœ‰å¿«å–
    
    Returns:
        Dict[str, Any]: æ¸…é™¤çµæœ
    """
    try:
        global analysis_cache
        
        cache_count = len(analysis_cache)
        analysis_cache.clear()
        
        logger.info(f"ğŸ§¹ å·²æ¸…é™¤ {cache_count} å€‹å¿«å–é …ç›®")
        
        return {
            'status': 'success',
            'cleared_items': cache_count,
            'message': f'æˆåŠŸæ¸…é™¤ {cache_count} å€‹å¿«å–é …ç›®',
            'cleared_at': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¸…é™¤å¿«å–éŒ¯èª¤: {e}")
        return {
            'status': 'error',
            'error': str(e)
        }

def reset_system() -> Dict[str, Any]:
    """é‡ç½®ç³»çµ±ï¼ˆæ¸…é™¤å¿«å–ä¸¦é‡æ–°åˆå§‹åŒ–AIæœå‹™ï¼‰
    
    Returns:
        Dict[str, Any]: é‡ç½®çµæœ
    """
    try:
        logger.info("ğŸ”„ é‡ç½®ç³»çµ±...")
        
        # æ¸…é™¤å¿«å–
        cache_result = clear_all_cache()
        
        # é‡æ–°åˆå§‹åŒ–AIæœå‹™
        ai_init_success = initialize_ai_service()
        
        # åŸ·è¡Œå¥åº·æª¢æŸ¥
        health_check = perform_system_health_check()
        
        reset_success = ai_init_success and health_check['overall_status'] != 'error'
        
        return {
            'status': 'success' if reset_success else 'partial',
            'cache_cleared': cache_result['status'] == 'success',
            'ai_reinitialized': ai_init_success,
            'health_status': health_check['overall_status'],
            'message': 'ç³»çµ±é‡ç½®å®Œæˆ' if reset_success else 'ç³»çµ±é‡ç½®éƒ¨åˆ†å®Œæˆï¼Œè«‹æª¢æŸ¥éŒ¯èª¤',
            'reset_at': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±é‡ç½®éŒ¯èª¤: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'reset_at': datetime.datetime.now().isoformat()
        }

def get_analytics_statistics() -> Dict[str, Any]:
    """ç²å–åˆ†æçµ±è¨ˆè³‡è¨Š
    
    Returns:
        Dict[str, Any]: åˆ†æçµ±è¨ˆè³‡è¨Š
    """
    try:
        logger.info("ğŸ“Š è¨ˆç®—åˆ†æçµ±è¨ˆè³‡è¨Š...")
        
        # è³‡æ–™åº«çµ±è¨ˆ
        total_students = Student.select().count()
        total_messages = Message.select().count()
        
        # æ´»èºåº¦çµ±è¨ˆ
        week_ago = datetime.datetime.now() - timedelta(days=7)
        active_students = Student.select().where(Student.last_active >= week_ago).count()
        
        # æå•çµ±è¨ˆ
        question_messages = Message.select().where(
            (Message.content.contains('?')) | (Message.content.contains('ï¼Ÿ'))
        ).count()
        
        # å¿«å–çµ±è¨ˆ
        cache_stats = get_cache_statistics()
        
        # è¨ˆç®—åˆ†æè¦†è“‹ç‡
        students_with_messages = Student.select().join(Message).distinct().count()
        coverage_rate = (students_with_messages / max(total_students, 1)) * 100
        
        # è¨ˆç®—å¹³å‡å€¼
        avg_messages_per_student = total_messages / max(total_students, 1)
        avg_questions_per_student = question_messages / max(total_students, 1)
        
        # ç³»çµ±æ•ˆèƒ½æŒ‡æ¨™
        if cache_stats.get('active_items', 0) > 0:
            cache_hit_potential = 'high'
        elif cache_stats.get('active_items', 0) > 0:
            cache_hit_potential = 'medium'
        else:
            cache_hit_potential = 'low'
        
        return {
            'status': 'success',
            'data_statistics': {
                'total_students': total_students,
                'total_messages': total_messages,
                'active_students': active_students,
                'question_messages': question_messages,
                'coverage_rate': round(coverage_rate, 2),
                'avg_messages_per_student': round(avg_messages_per_student, 2),
                'avg_questions_per_student': round(avg_questions_per_student, 2)
            },
            'system_statistics': {
                'current_model': analytics_model_name,
                'model_switches': model_switch_count,
                'cache_items': cache_stats.get('active_items', 0),
                'cache_hit_potential': cache_hit_potential
            },
            'performance_indicators': {
                'data_richness': 'high' if avg_messages_per_student >= 10 else 'medium' if avg_messages_per_student >= 5 else 'low',
                'question_engagement': 'high' if (question_messages / max(total_messages, 1)) >= 0.2 else 'medium' if (question_messages / max(total_messages, 1)) >= 0.1 else 'low',
                'system_stability': 'stable' if model_switch_count < 5 else 'moderate' if model_switch_count < 15 else 'unstable'
            },
            'generated_at': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–åˆ†æçµ±è¨ˆéŒ¯èª¤: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'generated_at': datetime.datetime.now().isoformat()
        }

# =================== ç³»çµ±åˆå§‹åŒ– ===================

def initialize_system() -> Dict[str, Any]:
    """åˆå§‹åŒ–æ•´å€‹åˆ†æç³»çµ±
    
    Returns:
        Dict[str, Any]: åˆå§‹åŒ–çµæœ
    """
    try:
        logger.info("ğŸš€ åˆå§‹åŒ– EMI æ•™å­¸åˆ†æç³»çµ±...")
        
        initialization_results = {
            'status': 'success',
            'components': {},
            'warnings': [],
            'errors': []
        }
        
        # 1. æª¢æŸ¥ç’°å¢ƒé…ç½®
        if not GEMINI_API_KEY:
            initialization_results['warnings'].append('GEMINI_API_KEY æœªè¨­å®šï¼ŒAIåŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨')
            initialization_results['components']['api_key'] = 'missing'
        else:
            initialization_results['components']['api_key'] = 'configured'
        
        # 2. åˆå§‹åŒ–AIæœå‹™
        if GEMINI_API_KEY:
            ai_init = initialize_ai_service()
            initialization_results['components']['ai_service'] = 'success' if ai_init else 'failed'
            if not ai_init:
                initialization_results['errors'].append('AIæœå‹™åˆå§‹åŒ–å¤±æ•—')
        else:
            initialization_results['components']['ai_service'] = 'skipped'
        
        # 3. æª¢æŸ¥è³‡æ–™åº«é€£æ¥
        try:
            db.connect()
            initialization_results['components']['database'] = 'connected'
            
            # æª¢æŸ¥è³‡æ–™å¯ç”¨æ€§
            student_count = Student.select().count()
            message_count = Message.select().count()
            
            if student_count == 0:
                initialization_results['warnings'].append('æ²’æœ‰å­¸ç”Ÿè³‡æ–™')
            if message_count == 0:
                initialization_results['warnings'].append('æ²’æœ‰è¨Šæ¯è³‡æ–™')
                
        except Exception as e:
            initialization_results['components']['database'] = 'failed'
            initialization_results['errors'].append(f'è³‡æ–™åº«é€£æ¥å¤±æ•—: {str(e)}')
        
        # 4. åˆå§‹åŒ–å¿«å–ç³»çµ±
        try:
            clear_expired_cache()  # æ¸…ç†å¯èƒ½å­˜åœ¨çš„éæœŸå¿«å–
            initialization_results['components']['cache_system'] = 'initialized'
        except Exception as e:
            initialization_results['components']['cache_system'] = 'failed'
            initialization_results['errors'].append(f'å¿«å–ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {str(e)}')
        
        # 5. åŸ·è¡Œå¥åº·æª¢æŸ¥
        health_check = perform_system_health_check()
        initialization_results['health_status'] = health_check['overall_status']
        
        # æ±ºå®šæ•´é«”åˆå§‹åŒ–ç‹€æ…‹
        if initialization_results['errors']:
            initialization_results['status'] = 'failed'
        elif initialization_results['warnings']:
            initialization_results['status'] = 'partial'
        else:
            initialization_results['status'] = 'success'
        
        # ç³»çµ±è³‡è¨Š
        initialization_results['system_info'] = {
            'version': '2025.06.28',
            'available_models': ANALYTICS_MODELS,
            'current_model': analytics_model_name,
            'cache_duration_minutes': CACHE_DURATION / 60
        }
        
        initialization_results['initialized_at'] = datetime.datetime.now().isoformat()
        
        status_message = {
            'success': 'âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆ',
            'partial': 'âš ï¸ ç³»çµ±éƒ¨åˆ†åˆå§‹åŒ–å®Œæˆ',
            'failed': 'âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—'
        }
        
        logger.info(status_message[initialization_results['status']])
        
        return initialization_results
        
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±åˆå§‹åŒ–éŒ¯èª¤: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'initialized_at': datetime.datetime.now().isoformat()
        }

# =================== åŒ¯å‡ºçš„ä¸»è¦å‡½æ•¸åˆ—è¡¨ ===================

# å¿«å–ç®¡ç†å‡½æ•¸
__cache_functions__ = [
    'get_cached_analysis',
    'cache_analysis_result', 
    'clear_expired_cache',
    'get_cached_or_generate',
    'get_cache_statistics',
    'clear_all_cache'
]

# AIåˆ†æå‡½æ•¸
__analysis_functions__ = [
    'generate_individual_summary',
    'generate_class_summary',
    'extract_learning_keywords'
]

# TSVåŒ¯å‡ºå‡½æ•¸
__export_functions__ = [
    'export_student_questions_tsv',
    'export_all_questions_tsv',
    'export_student_analytics_tsv',
    'export_class_analytics_tsv'
]

# ç³»çµ±ç®¡ç†å‡½æ•¸
__system_functions__ = [
    'get_system_status',
    'perform_system_health_check',
    'reset_system',
    'get_analytics_statistics',
    'initialize_system'
]

# éŒ¯èª¤è™•ç†å‡½æ•¸
__error_handling_functions__ = [
    'safe_ai_analysis',
    'get_fallback_individual_summary',
    'get_fallback_class_summary',
    'get_fallback_keywords'
]

# AIæœå‹™å‡½æ•¸
__ai_service_functions__ = [
    'initialize_ai_service',
    'call_ai_service',
    'switch_to_next_model'
]

# æª”æ¡ˆç¬¬äº”æ®µçµæŸ - æ¥ä¸‹ä¾†æ˜¯æœ€çµ‚çš„åŒ¯å‡ºå’Œåˆå§‹åŒ–

# teaching_analytics.py - ç¬¬å…­æ®µï¼šåŒ¯å‡ºå’Œç³»çµ±å•Ÿå‹•ï¼ˆæœ€çµ‚æ®µï¼‰
# æ¥çºŒç¬¬äº”æ®µï¼šç³»çµ±ç®¡ç†å’Œåˆå§‹åŒ–å‡½æ•¸ä¹‹å¾Œ

# =================== çµ±ä¸€åŒ¯å‡ºåˆ—è¡¨ ===================

__all__ = [
    # === æ ¸å¿ƒåˆ†æå‡½æ•¸ ===
    'generate_individual_summary',
    'generate_class_summary', 
    'extract_learning_keywords',
    
    # === TSVåŒ¯å‡ºåŠŸèƒ½ ===
    'export_student_questions_tsv',
    'export_all_questions_tsv',
    'export_student_analytics_tsv',
    'export_class_analytics_tsv',
    
    # === å¿«å–ç³»çµ± ===
    'get_cached_analysis',
    'cache_analysis_result',
    'clear_expired_cache',
    'get_cached_or_generate',
    'get_cache_statistics',
    'clear_all_cache',
    
    # === éŒ¯èª¤è™•ç† ===
    'safe_ai_analysis',
    'get_fallback_individual_summary',
    'get_fallback_class_summary',
    'get_fallback_keywords',
    
    # === AIæœå‹™ç®¡ç† ===
    'initialize_ai_service',
    'call_ai_service',
    'switch_to_next_model',
    
    # === ç³»çµ±ç®¡ç† ===
    'get_system_status',
    'perform_system_health_check',
    'reset_system',
    'get_analytics_statistics',
    'initialize_system',
    
    # === ç³»çµ±è®Šæ•¸ï¼ˆå”¯è®€ï¼‰ ===
    'analytics_model_name',
    'model_switch_count',
    'CACHE_DURATION',
    'ANALYTICS_MODELS'
]

# =================== ç›¸å®¹æ€§å‡½æ•¸ï¼ˆèˆ‡ç¾æœ‰ç¨‹å¼ç¢¼æ•´åˆï¼‰ ===================

def get_analytics_status() -> Dict[str, Any]:
    """ç²å–åˆ†æç³»çµ±ç‹€æ…‹ï¼ˆç›¸å®¹æ€§å‡½æ•¸ï¼‰
    
    Returns:
        Dict[str, Any]: ç³»çµ±ç‹€æ…‹
    """
    return get_system_status()

def cleanup_old_cache() -> Dict[str, Any]:
    """æ¸…ç†èˆŠå¿«å–ï¼ˆç›¸å®¹æ€§å‡½æ•¸ï¼‰
    
    Returns:
        Dict[str, Any]: æ¸…ç†çµæœ
    """
    clear_expired_cache()
    return get_cache_statistics()

# =================== ç³»çµ±ç‰ˆæœ¬è³‡è¨Š ===================

SYSTEM_VERSION_INFO = {
    'name': 'EMI Teaching Analytics System - Backend Core',
    'version': '2025.06.28',
    'description': 'EMIæ™ºèƒ½æ•™å­¸åŠ©ç†ç³»çµ±å¾Œç«¯æ ¸å¿ƒï¼Œæä¾›AIåˆ†æã€å¿«å–ã€éŒ¯èª¤è™•ç†å’ŒTSVåŒ¯å‡ºåŠŸèƒ½',
    'features': [
        'æ™ºèƒ½å¿«å–ç³»çµ±ï¼ˆ30åˆ†é˜æœ‰æ•ˆæœŸï¼‰',
        'å®Œå–„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶',
        'AIåˆ†æå¼•æ“ï¼ˆå€‹äººå’Œå…¨ç­æ‘˜è¦ï¼‰',
        'TSVæª”æ¡ˆåŒ¯å‡ºåŠŸèƒ½',
        'å¤šæ¨¡å‹æ”¯æ´å’Œè‡ªå‹•åˆ‡æ›',
        'ç³»çµ±å¥åº·ç›£æ§',
        'æ•ˆèƒ½çµ±è¨ˆå’Œå„ªåŒ–å»ºè­°'
    ],
    'supported_models': ANALYTICS_MODELS,
    'cache_duration_minutes': CACHE_DURATION / 60,
    'last_updated': '2025-06-28',
    'author': 'EMI Backend Core Development Team',
    'performance_targets': {
        'ai_analysis_first_load': 'â‰¤ 10ç§’',
        'cache_hit_load': 'â‰¤ 1ç§’', 
        'api_error_rate': '< 1%',
        'system_stability': '99%+'
    }
}

# =================== æ•ˆèƒ½åŸºæº–æ¸¬è©¦å‡½æ•¸ ===================

def benchmark_performance() -> Dict[str, Any]:
    """æ•ˆèƒ½åŸºæº–æ¸¬è©¦
    
    Returns:
        Dict[str, Any]: æ•ˆèƒ½æ¸¬è©¦çµæœ
    """
    try:
        logger.info("â±ï¸ é–‹å§‹æ•ˆèƒ½åŸºæº–æ¸¬è©¦...")
        
        benchmark_results = {
            'test_status': 'completed',
            'test_time': datetime.datetime.now().isoformat(),
            'results': {},
            'performance_grade': 'unknown'
        }
        
        # æ¸¬è©¦1ï¼šAIåˆ†ææ•ˆèƒ½ï¼ˆå¦‚æœæœ‰å­¸ç”Ÿè³‡æ–™ï¼‰
        try:
            students = list(Student.select().limit(1))
            if students:
                student_id = students[0].id
                
                # æ¸…é™¤å¯èƒ½çš„å¿«å–
                cache_key = f"individual_summary_{student_id}"
                if cache_key in analysis_cache:
                    del analysis_cache[cache_key]
                
                # æ¸¬è©¦AIåˆ†ææ™‚é–“
                start_time = time.time()
                result = generate_individual_summary(student_id)
                analysis_time = time.time() - start_time
                
                benchmark_results['results']['ai_analysis_time'] = {
                    'time_seconds': round(analysis_time, 2),
                    'target_seconds': 10.0,
                    'meets_target': analysis_time <= 10.0,
                    'status': result.get('status', 'unknown')
                }
                
                # æ¸¬è©¦å¿«å–å­˜å–æ™‚é–“
                start_time = time.time()
                cached_result = generate_individual_summary(student_id)
                cache_time = time.time() - start_time
                
                benchmark_results['results']['cache_access_time'] = {
                    'time_seconds': round(cache_time, 2),
                    'target_seconds': 1.0,
                    'meets_target': cache_time <= 1.0,
                    'is_from_cache': cached_result.get('cached', True)
                }
            else:
                benchmark_results['results']['ai_analysis_time'] = {
                    'status': 'skipped',
                    'reason': 'no_student_data'
                }
                benchmark_results['results']['cache_access_time'] = {
                    'status': 'skipped', 
                    'reason': 'no_student_data'
                }
                
        except Exception as e:
            benchmark_results['results']['ai_analysis_error'] = str(e)
        
        # æ¸¬è©¦2ï¼šç³»çµ±å›æ‡‰æ™‚é–“
        start_time = time.time()
        system_status = get_system_status()
        system_response_time = time.time() - start_time
        
        benchmark_results['results']['system_response_time'] = {
            'time_seconds': round(system_response_time, 2),
            'target_seconds': 0.5,
            'meets_target': system_response_time <= 0.5
        }
        
        # æ¸¬è©¦3ï¼šå¿«å–ç³»çµ±æ•ˆèƒ½
        start_time = time.time()
        cache_stats = get_cache_statistics()
        cache_response_time = time.time() - start_time
        
        benchmark_results['results']['cache_system_time'] = {
            'time_seconds': round(cache_response_time, 2),
            'target_seconds': 0.1,
            'meets_target': cache_response_time <= 0.1
        }
        
        # è¨ˆç®—æ•ˆèƒ½ç­‰ç´š
        passed_tests = 0
        total_tests = 0
        
        for test_name, test_result in benchmark_results['results'].items():
            if isinstance(test_result, dict) and 'meets_target' in test_result:
                total_tests += 1
                if test_result['meets_target']:
                    passed_tests += 1
        
        if total_tests > 0:
            pass_rate = passed_tests / total_tests
            if pass_rate >= 0.9:
                benchmark_results['performance_grade'] = 'excellent'
            elif pass_rate >= 0.7:
                benchmark_results['performance_grade'] = 'good'
            elif pass_rate >= 0.5:
                benchmark_results['performance_grade'] = 'acceptable'
            else:
                benchmark_results['performance_grade'] = 'needs_improvement'
        
        benchmark_results['summary'] = {
            'passed_tests': passed_tests,
            'total_tests': total_tests,
            'pass_rate': round((passed_tests / max(total_tests, 1)) * 100, 1)
        }
        
        logger.info(f"â±ï¸ æ•ˆèƒ½æ¸¬è©¦å®Œæˆï¼Œç­‰ç´š: {benchmark_results['performance_grade']}")
        
        return benchmark_results
        
    except Exception as e:
        logger.error(f"âŒ æ•ˆèƒ½æ¸¬è©¦éŒ¯èª¤: {e}")
        return {
            'test_status': 'error',
            'error': str(e),
            'test_time': datetime.datetime.now().isoformat()
        }

# =================== ç³»çµ±å•Ÿå‹•å’Œè‡ªå‹•åˆå§‹åŒ– ===================

def auto_startup():
    """ç³»çµ±è‡ªå‹•å•Ÿå‹•
    
    é€™å€‹å‡½æ•¸æœƒåœ¨æ¨¡çµ„è¼‰å…¥æ™‚è‡ªå‹•åŸ·è¡Œï¼ŒåŸ·è¡Œå¿…è¦çš„åˆå§‹åŒ–
    """
    try:
        logger.info("ğŸ”„ æ•™å­¸åˆ†æç³»çµ±è‡ªå‹•å•Ÿå‹•ä¸­...")
        
        # æ¸…ç†éæœŸå¿«å–
        clear_expired_cache()
        
        # å¦‚æœæœ‰APIé‡‘é‘°ï¼Œå˜—è©¦åˆå§‹åŒ–AIæœå‹™
        if GEMINI_API_KEY:
            ai_init_success = initialize_ai_service()
            if ai_init_success:
                logger.info("âœ… AIæœå‹™è‡ªå‹•åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš ï¸ AIæœå‹™è‡ªå‹•åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡åœ¨éœ€è¦æ™‚é‡è©¦")
        else:
            logger.warning("âš ï¸ æœªè¨­å®šAPIé‡‘é‘°ï¼ŒAIåŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
        
        # è¼¸å‡ºç³»çµ±è³‡è¨Š
        logger.info(f"ğŸ“š {SYSTEM_VERSION_INFO['name']} v{SYSTEM_VERSION_INFO['version']}")
        logger.info(f"ğŸ¯ æ”¯æ´ {len(ANALYTICS_MODELS)} å€‹AIæ¨¡å‹")
        logger.info(f"ğŸ’¾ å¿«å–æœ‰æ•ˆæœŸ: {CACHE_DURATION/60:.0f} åˆ†é˜")
        logger.info("ğŸš€ ç³»çµ±å•Ÿå‹•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±è‡ªå‹•å•Ÿå‹•éŒ¯èª¤: {e}")

# =================== æ¨¡çµ„è¼‰å…¥æ™‚è‡ªå‹•åŸ·è¡Œ ===================

# åªåœ¨æ¨¡çµ„è¢«åŒ¯å…¥æ™‚åŸ·è¡Œè‡ªå‹•å•Ÿå‹•ï¼Œä¸åœ¨ç›´æ¥åŸ·è¡Œæ™‚åŸ·è¡Œ
if __name__ != '__main__':
    auto_startup()

# =================== ä¸»ç¨‹å¼å…¥å£ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰ ===================

if __name__ == '__main__':
    print("=== EMI Teaching Analytics System - Backend Core ===")
    print(f"ç‰ˆæœ¬: {SYSTEM_VERSION_INFO['version']}")
    print("æ­£åœ¨åŸ·è¡Œå®Œæ•´ç³»çµ±æ¸¬è©¦...")
    
    # åŸ·è¡Œå®Œæ•´ç³»çµ±åˆå§‹åŒ–
    init_result = initialize_system()
    print(f"åˆå§‹åŒ–ç‹€æ…‹: {init_result['status']}")
    
    # åŸ·è¡Œå¥åº·æª¢æŸ¥
    health_result = perform_system_health_check()
    print(f"å¥åº·ç‹€æ…‹: {health_result['overall_status']}")
    
    # åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
    benchmark_result = benchmark_performance()
    print(f"æ•ˆèƒ½ç­‰ç´š: {benchmark_result['performance_grade']}")
    
    # è¼¸å‡ºç³»çµ±çµ±è¨ˆ
    stats_result = get_analytics_statistics()
    if stats_result['status'] == 'success':
        data_stats = stats_result['data_statistics']
        print(f"è³‡æ–™çµ±è¨ˆ: {data_stats['total_students']} å­¸ç”Ÿ, {data_stats['total_messages']} è¨Šæ¯")
    
    print("=== æ¸¬è©¦å®Œæˆ ===")

# =================== æª”æ¡ˆçµæŸ ===================

"""
teaching_analytics.py - EMIæ™ºèƒ½æ•™å­¸åŠ©ç†ç³»çµ±å¾Œç«¯æ ¸å¿ƒ
Version: 2025.06.28

é€™å€‹æª”æ¡ˆåŒ…å«äº†å®Œæ•´çš„å¾Œç«¯æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ™ºèƒ½å¿«å–ç³»çµ±ï¼ˆ30åˆ†é˜æœ‰æ•ˆæœŸï¼‰
2. å®Œå–„çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶  
3. AIåˆ†æå¼•æ“ï¼ˆå€‹äººå’Œå…¨ç­æ‘˜è¦ï¼‰
4. TSVæª”æ¡ˆåŒ¯å‡ºåŠŸèƒ½
5. å¤šæ¨¡å‹æ”¯æ´å’Œè‡ªå‹•åˆ‡æ›
6. ç³»çµ±å¥åº·ç›£æ§
7. æ•ˆèƒ½çµ±è¨ˆå’Œå„ªåŒ–å»ºè­°

ä¸»è¦å‡½æ•¸ï¼š
- generate_individual_summary(): å€‹äººå­¸ç¿’æ‘˜è¦
- generate_class_summary(): å…¨ç­å­¸ç¿’æ‘˜è¦  
- extract_learning_keywords(): å­¸ç¿’é—œéµè©æå–
- export_student_questions_tsv(): åŒ¯å‡ºå­¸ç”Ÿæå•
- export_all_questions_tsv(): åŒ¯å‡ºå…¨ç­æå•
- get_system_status(): ç³»çµ±ç‹€æ…‹æª¢æŸ¥
- perform_system_health_check(): å¥åº·æª¢æŸ¥
- benchmark_performance(): æ•ˆèƒ½æ¸¬è©¦

æ•ˆèƒ½ç›®æ¨™ï¼š
- AIåˆ†æé¦–æ¬¡è¼‰å…¥ï¼šâ‰¤ 10ç§’
- å¿«å–å‘½ä¸­è¼‰å…¥ï¼šâ‰¤ 1ç§’
- APIéŒ¯èª¤ç‡ï¼š< 1%
- ç³»çµ±ç©©å®šæ€§ï¼š99%+
"""
