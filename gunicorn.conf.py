# gunicorn.conf.py - Gunicorn é…ç½®æª”æ¡ˆ

import os
import multiprocessing

# æœå‹™å™¨è¨­å®š
bind = f"0.0.0.0:{os.getenv('PORT', 5000)}"
workers = int(os.getenv('WEB_CONCURRENCY', multiprocessing.cpu_count() * 2 + 1))
worker_class = "sync"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 100

# è¶…æ™‚è¨­å®š
timeout = 120
keepalive = 2
graceful_timeout = 30

# è¨˜æ†¶é«”ç®¡ç†
preload_app = True
max_worker_memory = 200  # MB

# æ—¥èªŒè¨­å®š
accesslog = "-"  # stdout
errorlog = "-"   # stderr
loglevel = os.getenv('LOG_LEVEL', 'info')
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# å®‰å…¨è¨­å®š
limit_request_line = 8190
limit_request_fields = 100
limit_request_field_size = 8190

# é€²ç¨‹ç®¡ç†
user = None
group = None
tmp_upload_dir = "/tmp"

# é–‹ç™¼/ç”Ÿç”¢ç’°å¢ƒå€åˆ†
if os.getenv('FLASK_ENV') == 'development':
    # é–‹ç™¼ç’°å¢ƒè¨­å®š
    reload = True
    workers = 1
    timeout = 0
    loglevel = 'debug'
else:
    # ç”Ÿç”¢ç’°å¢ƒè¨­å®š
    reload = False
    preload_app = True
    
# Heroku/Railway ç‰¹æ®Šè¨­å®š
if os.getenv('DYNO'):  # Heroku
    workers = int(os.getenv('WEB_CONCURRENCY', 2))
    max_requests = 1200
    
if os.getenv('RAILWAY_ENVIRONMENT'):  # Railway
    workers = int(os.getenv('WEB_CONCURRENCY', 2))
    timeout = 60

# çµ±è¨ˆå’Œç›£æ§
statsd_host = os.getenv('STATSD_HOST')
if statsd_host:
    statsd_prefix = 'ai-teaching-assistant'

# Worker å•Ÿå‹•å’Œé—œé–‰äº‹ä»¶
def when_ready(server):
    """ç•¶æœå‹™å™¨å•Ÿå‹•å®Œæˆæ™‚åŸ·è¡Œ"""
    server.log.info("ğŸš€ AI Teaching Assistant æœå‹™å™¨å·²å•Ÿå‹•")
    server.log.info(f"ğŸ“Š Workers: {workers}")
    server.log.info(f"ğŸŒ ç¶å®šåœ°å€: {bind}")

def worker_int(worker):
    """Worker æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿæ™‚åŸ·è¡Œ"""
    worker.log.info("ğŸ‘‹ Worker æ­£åœ¨å„ªé›…åœ°é—œé–‰...")

def post_fork(server, worker):
    """Worker é€²ç¨‹åˆ†å‰å¾ŒåŸ·è¡Œ"""
    server.log.info(f"ğŸ”§ Worker {worker.pid} å·²å•Ÿå‹•")

def pre_fork(server, worker):
    """Worker é€²ç¨‹åˆ†å‰å‰åŸ·è¡Œ"""
    pass

def worker_exit(server, worker):
    """Worker é€€å‡ºæ™‚åŸ·è¡Œ"""
    server.log.info(f"ğŸ”» Worker {worker.pid} å·²é€€å‡º")

# å¥åº·æª¢æŸ¥å’Œè³‡æºæ¸…ç†
def on_exit(server):
    """æœå‹™å™¨é€€å‡ºæ™‚åŸ·è¡Œæ¸…ç†"""
    server.log.info("ğŸ§¹ åŸ·è¡Œè³‡æºæ¸…ç†...")
    
    # é—œé–‰è³‡æ–™åº«é€£æ¥
    try:
        from models import db
        if not db.is_closed():
            db.close()
            server.log.info("ğŸ“Š è³‡æ–™åº«é€£æ¥å·²é—œé–‰")
    except Exception as e:
        server.log.error(f"âŒ è³‡æ–™åº«é—œé–‰éŒ¯èª¤: {e}")
    
    server.log.info("âœ… AI Teaching Assistant æœå‹™å™¨å·²å®‰å…¨é—œé–‰")

# éŒ¯èª¤è™•ç†
def worker_abort(worker):
    """Worker ç•°å¸¸çµ‚æ­¢æ™‚åŸ·è¡Œ"""
    worker.log.error(f"ğŸ’¥ Worker {worker.pid} ç•°å¸¸çµ‚æ­¢")

# è‡ªå®šç¾©é…ç½®é©—è­‰
def validate_config():
    """é©—è­‰é…ç½®åƒæ•¸"""
    errors = []
    
    if workers < 1:
        errors.append("Workers æ•¸é‡å¿…é ˆå¤§æ–¼ 0")
    
    if timeout < 10:
        errors.append("Timeout ä¸æ‡‰å°‘æ–¼ 10 ç§’")
        
    if errors:
        raise ValueError(f"é…ç½®éŒ¯èª¤: {', '.join(errors)}")

# åŸ·è¡Œé…ç½®é©—è­‰
validate_config()

# ç’°å¢ƒè®Šæ•¸æ—¥èªŒ
print(f"""
ğŸ“ AI Teaching Assistant - Gunicorn é…ç½®
{'='*50}
ğŸ“ ç¶å®šåœ°å€: {bind}
ğŸ‘¥ Worker æ•¸é‡: {workers}
â±ï¸  è¶…æ™‚æ™‚é–“: {timeout}s
ğŸ“ æ—¥èªŒç´šåˆ¥: {loglevel}
ğŸ”„ é åŠ è¼‰æ‡‰ç”¨: {preload_app}
ğŸ› ï¸  ç’°å¢ƒ: {os.getenv('FLASK_ENV', 'production')}
{'='*50}
""")
