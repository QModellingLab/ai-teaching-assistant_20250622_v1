# teaching_analytics.py - æ•™å­¸åˆ†ææ ¸å¿ƒåŠŸèƒ½
# åŒ…å«ï¼šå°è©±æ‘˜è¦ã€å€‹äººåŒ–å»ºè­°ã€ç­ç´šåˆ†æ

import os
import json
import datetime
import logging
from collections import defaultdict, Counter
import google.generativeai as genai
from models import Student, Message, Analysis, db

logger = logging.getLogger(__name__)

# åˆå§‹åŒ– Gemini AI
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash')
    except:
        model = None
else:
    model = None

# =========================================
# 1. æ™ºèƒ½å°è©±æ‘˜è¦åŠŸèƒ½
# =========================================

def generate_conversation_summary(student_id, days=30):
    """ç”Ÿæˆå­¸ç”Ÿå°è©±æ‘˜è¦"""
    try:
        if not model:
            return {'error': 'AI model not available'}
            
        student = Student.get_by_id(student_id)
        
        # å–å¾—æŒ‡å®šæœŸé–“çš„å°è©±
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)
        messages = list(Message.select().where(
            (Message.student_id == student_id) &
            (Message.timestamp > cutoff_date)
        ).order_by(Message.timestamp.asc()))
        
        if len(messages) < 3:
            return {'status': 'insufficient_data', 'message_count': len(messages)}
        
        # æ§‹å»ºå°è©±å…§å®¹
        conversation_text = []
        for msg in messages:
            if msg.message_type in ['question', 'statement']:
                conversation_text.append(f"Student: {msg.content[:100]}")
        
        # ç”Ÿæˆæ•™å­¸é‡é»æ‘˜è¦
        summary_prompt = f"""As an educational expert, analyze this student's conversation patterns for teaching insights:

Student: {student.name}
Participation Rate: {student.participation_rate}%
Total Messages: {len(messages)}

Recent Conversation Excerpts:
{chr(10).join(conversation_text[-10:])}  # æœ€è¿‘10å‰‡

Create a teaching-focused summary with these sections:

**ğŸ¯ Key Topics Discussed:**
[Main subjects and concepts the student engaged with]

**ğŸ“ˆ Understanding Level:**
[Assessment of student's current comprehension and learning progress]

**ğŸ’¡ Teaching Recommendations:**
[Specific suggestions for continued learning and areas to focus on]

**ğŸ” Learning Patterns:**
[Observable patterns in how this student learns and asks questions]

Format as clear, actionable insights for EMI instructors (max 250 words):"""

        response = model.generate_content(summary_prompt)
        
        if response and response.text:
            # è§£ææ‘˜è¦å…§å®¹
            summary_text = response.text.strip()
            parsed_summary = parse_summary_sections(summary_text)
            
            return {
                'success': True,
                'raw_summary': summary_text,
                'parsed_summary': parsed_summary,
                'key_topics': parsed_summary.get('key_topics', 'Analyzing discussion content...'),
                'understanding_level': parsed_summary.get('understanding_level', 'Assessing comprehension...'),
                'recommendations': parsed_summary.get('recommendations', 'Generating teaching suggestions...'),
                'learning_patterns': parsed_summary.get('learning_patterns', 'Identifying patterns...'),
                'message_count': len(messages),
                'analysis_period': f"{days} days",
                'generated_at': datetime.datetime.now().isoformat()
            }
        else:
            return {'error': 'Failed to generate summary'}
            
    except Exception as e:
        logger.error(f"å°è©±æ‘˜è¦ç”ŸæˆéŒ¯èª¤: {e}")
        return {'error': str(e)}

def parse_summary_sections(summary_text):
    """è§£ææ‘˜è¦æ–‡æœ¬çš„å„å€‹éƒ¨åˆ†"""
    try:
        sections = {
            'key_topics': '',
            'understanding_level': '',
            'recommendations': '',
            'learning_patterns': ''
        }
        
        # ç°¡å–®çš„æ–‡æœ¬è§£æ
        lines = summary_text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if 'ğŸ¯' in line or 'Key Topics' in line:
                current_section = 'key_topics'
            elif 'ğŸ“ˆ' in line or 'Understanding Level' in line:
                current_section = 'understanding_level'
            elif 'ğŸ’¡' in line or 'Teaching Recommendations' in line:
                current_section = 'recommendations'
            elif 'ğŸ”' in line or 'Learning Patterns' in line:
                current_section = 'learning_patterns'
            elif line and current_section and not line.startswith('**'):
                sections[current_section] += line + ' '
        
        # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨æ•´å€‹æ‘˜è¦ä½œç‚ºç†è§£ç¨‹åº¦
        if not any(sections.values()):
            sections['understanding_level'] = summary_text
        
        return sections
        
    except Exception as e:
        logger.error(f"æ‘˜è¦è§£æéŒ¯èª¤: {e}")
        return {'understanding_level': summary_text}

def generate_teaching_focused_summary(student_id):
    """ç”Ÿæˆæ•™å­¸é‡é»æ‘˜è¦ï¼ˆæ›´è©³ç´°ç‰ˆæœ¬ï¼‰"""
    try:
        if not model:
            return {'error': 'AI model not available'}
            
        student = Student.get_by_id(student_id)
        
        # å–å¾—æ‰€æœ‰å°è©±å’Œåˆ†æè³‡æ–™
        all_messages = list(Message.select().where(
            Message.student_id == student_id
        ).order_by(Message.timestamp.asc()))
        
        question_analyses = list(Analysis.select().where(
            (Analysis.student_id == student_id) &
            (Analysis.analysis_type == 'question_classification')
        ))
        
        if len(all_messages) < 5:
            return {'status': 'insufficient_data'}
        
        # åˆ†æå­¸ç¿’é€²å±•
        learning_progression = analyze_learning_progression(all_messages, question_analyses)
        
        # ç”Ÿæˆè©³ç´°æ•™å­¸æ‘˜è¦
        detailed_prompt = f"""Create a comprehensive teaching summary for this EMI student:

Student Profile:
- Name: {student.name}
- Total Interactions: {len(all_messages)}
- Questions Asked: {student.question_count}
- Participation Rate: {student.participation_rate}%
- Learning Period: {(all_messages[-1].timestamp - all_messages[0].timestamp).days} days

Learning Progression Analysis:
{json.dumps(learning_progression, indent=2)}

Provide a detailed teaching analysis covering:

1. **Learning Journey Overview**: How has this student's learning evolved?
2. **Cognitive Development**: What thinking skills have they demonstrated?
3. **Engagement Patterns**: When and how do they participate most effectively?
4. **Knowledge Gaps**: What areas need additional support?
5. **Strengths to Leverage**: What learning strengths can be built upon?
6. **Next Learning Steps**: Specific recommendations for continued growth

Format as structured insights for EMI instructors (300-400 words):"""

        response = model.generate_content(detailed_prompt)
        
        if response and response.text:
            return {
                'success': True,
                'detailed_summary': response.text.strip(),
                'learning_progression': learning_progression,
                'generated_at': datetime.datetime.now().isoformat()
            }
        else:
            return {'error': 'Failed to generate detailed summary'}
            
    except Exception as e:
        logger.error(f"è©³ç´°æ•™å­¸æ‘˜è¦ç”ŸæˆéŒ¯èª¤: {e}")
        return {'error': str(e)}

def analyze_learning_progression(messages, analyses):
    """åˆ†æå­¸ç¿’é€²å±•"""
    try:
        progression = {
            'early_phase': {'questions': 0, 'cognitive_levels': [], 'topics': []},
            'middle_phase': {'questions': 0, 'cognitive_levels': [], 'topics': []},
            'recent_phase': {'questions': 0, 'cognitive_levels': [], 'topics': []}
        }
        
        # å°‡è¨Šæ¯åˆ†æˆä¸‰å€‹éšæ®µ
        total_messages = len(messages)
        phase_size = total_messages // 3
        
        phases = [
            ('early_phase', messages[:phase_size]),
            ('middle_phase', messages[phase_size:phase_size*2]),
            ('recent_phase', messages[phase_size*2:])
        ]
        
        # åˆ†æå°æ‡‰çš„å•é¡Œåˆ†é¡
        for phase_name, phase_messages in phases:
            if not phase_messages:
                continue
                
            phase_analyses = [a for a in analyses 
                            if phase_messages[0].timestamp <= a.timestamp <= phase_messages[-1].timestamp]
            
            progression[phase_name]['questions'] = len([m for m in phase_messages if m.message_type == 'question'])
            
            for analysis in phase_analyses:
                try:
                    data = json.loads(analysis.analysis_data)
                    progression[phase_name]['cognitive_levels'].append(data.get('cognitive_level', 'Unknown'))
                    progression[phase_name]['topics'].append(data.get('content_domain', 'Unknown'))
                except json.JSONDecodeError:
                    continue
        
        return progression
        
    except Exception as e:
        logger.error(f"å­¸ç¿’é€²å±•åˆ†æéŒ¯èª¤: {e}")
        return {}

# =========================================
# 2. å€‹äººåŒ–å­¸ç¿’å»ºè­°åŠŸèƒ½
# =========================================

def build_comprehensive_student_profile(student_id):
    """å»ºç«‹ç¶œåˆå­¸ç”Ÿæª”æ¡ˆ"""
    try:
        student = Student.get_by_id(student_id)
        
        # æ”¶é›†æ‰€æœ‰ç›¸é—œè³‡æ–™
        messages = list(Message.select().where(Message.student_id == student_id))
        analyses = list(Analysis.select().where(
            (Analysis.student_id == student_id) &
            (Analysis.analysis_type == 'question_classification')
        ))
        
        # åˆ†æå•é¡Œæ¨¡å¼
        question_patterns = analyze_question_patterns(analyses)
        
        # åƒèˆ‡åº¦åˆ†æ
        engagement_analysis = analyze_student_engagement(student, messages)
        
        # èªçŸ¥ç™¼å±•è¿½è¹¤
        cognitive_development = track_cognitive_development(analyses)
        
        # å­¸ç¿’é¢¨æ ¼è­˜åˆ¥
        learning_style = identify_learning_style(messages, analyses)
        
        profile = {
            'student_info': {
                'id': student.id,
                'name': student.name,
                'participation_rate': student.participation_rate,
                'question_count': student.question_count,
                'message_count': student.message_count,
                'learning_period_days': (datetime.datetime.now() - student.created_at).days if student.created_at else 0
            },
            'question_patterns': question_patterns,
            'engagement_analysis': engagement_analysis,
            'cognitive_development': cognitive_development,
            'learning_style': learning_style,
            'profile_generated': datetime.datetime.now().isoformat()
        }
        
        return profile
        
    except Exception as e:
        logger.error(f"å­¸ç”Ÿæª”æ¡ˆå»ºç«‹éŒ¯èª¤: {e}")
        return {'error': str(e)}

def analyze_question_patterns(analyses):
    """åˆ†æå•é¡Œæ¨¡å¼"""
    try:
        if not analyses:
            return {'status': 'no_data'}
        
        patterns = {
            'total_questions': len(analyses),
            'content_domains': Counter(),
            'cognitive_levels': Counter(),
            'question_types': Counter(),
            'difficulty_levels': Counter(),
            'complexity_trend': []
        }
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                
                patterns['content_domains'][data.get('content_domain', 'Unknown')] += 1
                patterns['cognitive_levels'][data.get('cognitive_level', 'Unknown')] += 1
                patterns['question_types'][data.get('question_type', 'Unknown')] += 1
                patterns['difficulty_levels'][data.get('difficulty', 'Unknown')] += 1
                
                # è¿½è¹¤è¤‡é›œåº¦è¶¨å‹¢
                patterns['complexity_trend'].append({
                    'date': analysis.timestamp.isoformat(),
                    'complexity': data.get('language_complexity', 'Basic')
                })
                
            except json.JSONDecodeError:
                continue
        
        # è½‰æ› Counter ç‚ºå­—å…¸
        patterns['content_domains'] = dict(patterns['content_domains'])
        patterns['cognitive_levels'] = dict(patterns['cognitive_levels'])
        patterns['question_types'] = dict(patterns['question_types'])
        patterns['difficulty_levels'] = dict(patterns['difficulty_levels'])
        
        return patterns
        
    except Exception as e:
        logger.error(f"å•é¡Œæ¨¡å¼åˆ†æéŒ¯èª¤: {e}")
        return {'error': str(e)}

def analyze_student_engagement(student, messages):
    """åˆ†æå­¸ç”Ÿåƒèˆ‡åº¦"""
    try:
        if not messages:
            return {'status': 'no_data'}
        
        # æ™‚é–“åˆ†æ
        active_days = len(set(msg.timestamp.date() for msg in messages))
        
        # äº’å‹•æ¨¡å¼åˆ†æ
        questions = [msg for msg in messages if msg.message_type == 'question']
        statements = [msg for msg in messages if msg.message_type == 'statement']
        
        # æœ€è¿‘æ´»å‹•è¶¨å‹¢
        recent_messages = [msg for msg in messages 
                          if msg.timestamp > datetime.datetime.now() - datetime.timedelta(days=7)]
        
        engagement = {
            'total_messages': len(messages),
            'total_questions': len(questions),
            'total_statements': len(statements),
            'active_days': active_days,
            'avg_daily_messages': len(messages) / max(active_days, 1),
            'question_ratio': len(questions) / max(len(messages), 1),
            'recent_activity': len(recent_messages),
            'engagement_level': classify_engagement_level(student.participation_rate),
            'activity_pattern': analyze_activity_pattern(messages)
        }
        
        return engagement
        
    except Exception as e:
        logger.error(f"åƒèˆ‡åº¦åˆ†æéŒ¯èª¤: {e}")
        return {'error': str(e)}

def classify_engagement_level(participation_rate):
    """åˆ†é¡åƒèˆ‡åº¦ç­‰ç´š"""
    if participation_rate >= 75:
        return 'high'
    elif participation_rate >= 50:
        return 'medium'
    else:
        return 'low'

def analyze_activity_pattern(messages):
    """åˆ†ææ´»å‹•æ¨¡å¼"""
    try:
        # é€±é–“æ´»å‹•åˆ†æ
        weekday_activity = defaultdict(int)
        hour_activity = defaultdict(int)
        
        for msg in messages:
            weekday_activity[msg.timestamp.strftime('%A')] += 1
            hour_activity[msg.timestamp.hour] += 1
        
        # æ‰¾å‡ºæœ€æ´»èºçš„æ™‚æ®µ
        most_active_weekday = max(weekday_activity.items(), key=lambda x: x[1]) if weekday_activity else ('Unknown', 0)
        most_active_hour = max(hour_activity.items(), key=lambda x: x[1]) if hour_activity else (0, 0)
        
        return {
            'most_active_weekday': most_active_weekday[0],
            'most_active_hour': most_active_hour[0],
            'weekday_distribution': dict(weekday_activity),
            'hour_distribution': dict(hour_activity)
        }
        
    except Exception as e:
        logger.error(f"æ´»å‹•æ¨¡å¼åˆ†æéŒ¯èª¤: {e}")
        return {}

def track_cognitive_development(analyses):
    """è¿½è¹¤èªçŸ¥ç™¼å±•"""
    try:
        if len(analyses) < 3:
            return {'status': 'insufficient_data'}
        
        # æŒ‰æ™‚é–“æ’åºåˆ†æ
        sorted_analyses = sorted(analyses, key=lambda x: x.timestamp)
        
        cognitive_progression = []
        for analysis in sorted_analyses:
            try:
                data = json.loads(analysis.analysis_data)
                cognitive_progression.append({
                    'date': analysis.timestamp.isoformat(),
                    'cognitive_level': data.get('cognitive_level', 'Unknown'),
                    'difficulty': data.get('difficulty', 'Unknown')
                })
            except json.JSONDecodeError:
                continue
        
        # åˆ†æé€²å±•è¶¨å‹¢
        development_analysis = {
            'total_analyses': len(cognitive_progression),
            'progression': cognitive_progression,
            'cognitive_distribution': Counter(item['cognitive_level'] for item in cognitive_progression),
            'difficulty_progression': Counter(item['difficulty'] for item in cognitive_progression),
            'development_trend': assess_cognitive_trend(cognitive_progression)
        }
        
        return development_analysis
        
    except Exception as e:
        logger.error(f"èªçŸ¥ç™¼å±•è¿½è¹¤éŒ¯èª¤: {e}")
        return {'error': str(e)}

def assess_cognitive_trend(progression):
    """è©•ä¼°èªçŸ¥ç™¼å±•è¶¨å‹¢"""
    try:
        if len(progression) < 3:
            return 'insufficient_data'
        
        # ç°¡å–®çš„è¶¨å‹¢åˆ†æï¼šæ¯”è¼ƒå‰1/3å’Œå¾Œ1/3çš„èªçŸ¥å±¤æ¬¡
        third = len(progression) // 3
        early_levels = [item['cognitive_level'] for item in progression[:third]]
        recent_levels = [item['cognitive_level'] for item in progression[-third:]]
        
        # èªçŸ¥å±¤æ¬¡ç­‰ç´šï¼ˆç°¡åŒ–ï¼‰
        level_scores = {
            'Remember': 1, 'Understand': 2, 'Apply': 3,
            'Analyze': 4, 'Evaluate': 5, 'Create': 6, 'Unknown': 0
        }
        
        early_avg = sum(level_scores.get(level, 0) for level in early_levels) / max(len(early_levels), 1)
        recent_avg = sum(level_scores.get(level, 0) for level in recent_levels) / max(len(recent_levels), 1)
        
        if recent_avg > early_avg * 1.2:
            return 'improving'
        elif recent_avg < early_avg * 0.8:
            return 'declining'
        else:
            return 'stable'
            
    except Exception as e:
        logger.error(f"èªçŸ¥è¶¨å‹¢è©•ä¼°éŒ¯èª¤: {e}")
        return 'unknown'

def identify_learning_style(messages, analyses):
    """è­˜åˆ¥å­¸ç¿’é¢¨æ ¼"""
    try:
        if not messages and not analyses:
            return {'status': 'no_data'}
        
        style_indicators = {
            'question_asking_frequency': 0,
            'statement_making_frequency': 0,
            'preferred_question_types': [],
            'interaction_pattern': '',
            'learning_pace': ''
        }
        
        # åˆ†ææå•èˆ‡é™³è¿°æ¯”ä¾‹
        questions = [msg for msg in messages if msg.message_type == 'question']
        statements = [msg for msg in messages if msg.message_type == 'statement']
        
        style_indicators['question_asking_frequency'] = len(questions) / max(len(messages), 1)
        style_indicators['statement_making_frequency'] = len(statements) / max(len(messages), 1)
        
        # åˆ†æåå¥½çš„å•é¡Œé¡å‹
        if analyses:
            question_types = []
            for analysis in analyses:
                try:
                    data = json.loads(analysis.analysis_data)
                    question_types.append(data.get('question_type', 'Unknown'))
                except json.JSONDecodeError:
                    continue
            
            style_indicators['preferred_question_types'] = Counter(question_types).most_common(3)
        
        # è­˜åˆ¥å­¸ç¿’é¢¨æ ¼é¡å‹
        learning_style = classify_learning_style(style_indicators)
        
        return {
            'style_indicators': style_indicators,
            'identified_style': learning_style,
            'confidence': calculate_style_confidence(style_indicators)
        }
        
    except Exception as e:
        logger.error(f"å­¸ç¿’é¢¨æ ¼è­˜åˆ¥éŒ¯èª¤: {e}")
        return {'error': str(e)}

def classify_learning_style(indicators):
    """åˆ†é¡å­¸ç¿’é¢¨æ ¼"""
    try:
        question_freq = indicators['question_asking_frequency']
        preferred_types = [item[0] for item in indicators['preferred_question_types']]
        
        # åŸºæ–¼å•é¡Œé »ç‡å’Œé¡å‹çš„ç°¡å–®åˆ†é¡
        if question_freq > 0.4:
            if 'Definition' in preferred_types:
                return {
                    'type': 'inquisitive_learner',
                    'description': 'å¥½å¥‡æ¢ç©¶å‹ï¼šç©æ¥µæå•ï¼Œå–œæ­¡æ·±å…¥äº†è§£æ¦‚å¿µå®šç¾©'
                }
            elif 'Example' in preferred_types:
                return {
                    'type': 'example_oriented',
                    'description': 'å¯¦ä¾‹å°å‘å‹ï¼šé€šéå…·é«”ä¾‹å­ä¾†ç†è§£æŠ½è±¡æ¦‚å¿µ'
                }
            else:
                return {
                    'type': 'active_questioner',
                    'description': 'ä¸»å‹•æå•å‹ï¼šç¶“å¸¸æå•ï¼Œç©æ¥µåƒèˆ‡è¨è«–'
                }
        elif question_freq > 0.2:
            return {
                'type': 'moderate_participant',
                'description': 'é©åº¦åƒèˆ‡å‹ï¼šæœ‰é¸æ“‡æ€§åœ°åƒèˆ‡è¨è«–'
            }
        else:
            return {
                'type': 'observer_learner',
                'description': 'è§€å¯Ÿå­¸ç¿’å‹ï¼šå‚¾å‘æ–¼è½å–å’Œè§€å¯Ÿï¼Œè¼ƒå°‘ä¸»å‹•æå•'
            }
            
    except Exception as e:
        logger.error(f"å­¸ç¿’é¢¨æ ¼åˆ†é¡éŒ¯èª¤: {e}")
        return {'type': 'unknown', 'description': 'å­¸ç¿’é¢¨æ ¼åˆ†æä¸­'}

def calculate_style_confidence(indicators):
    """è¨ˆç®—é¢¨æ ¼è­˜åˆ¥ä¿¡å¿ƒåº¦"""
    try:
        # åŸºæ–¼è³‡æ–™é‡å’Œä¸€è‡´æ€§è¨ˆç®—ä¿¡å¿ƒåº¦
        total_interactions = len(indicators.get('preferred_question_types', []))
        
        if total_interactions >= 10:
            return 'high'
        elif total_interactions >= 5:
            return 'medium'
        else:
            return 'low'
            
    except Exception as e:
        return 'unknown'

def generate_personalized_recommendations(student_id):
    """ç”Ÿæˆå€‹äººåŒ–å­¸ç¿’å»ºè­°"""
    try:
        if not model:
            return {'error': 'AI model not available'}
        
        # å»ºç«‹å­¸ç”Ÿæª”æ¡ˆ
        profile = build_comprehensive_student_profile(student_id)
        
        if 'error' in profile:
            return profile
        
        # ç”Ÿæˆ AI å»ºè­°
        recommendations_prompt = f"""Based on this comprehensive student profile, provide personalized learning recommendations for EMI instruction:

Student Profile Summary:
{json.dumps(profile, indent=2)}

Generate specific, actionable recommendations in these categories:

1. **Immediate Focus Areas**: What needs attention right now?
2. **Skill Development**: What abilities should be developed next?
3. **Challenge Level**: What difficulty level is appropriate?
4. **Learning Resources**: What types of materials would help?
5. **Teacher Actions**: Specific strategies for the instructor?

Format as structured recommendations suitable for EMI educators:"""

        response = model.generate_content(recommendations_prompt)
        
        if response and response.text:
            # è§£æå»ºè­°å…§å®¹
            parsed_recommendations = parse_recommendations(response.text)
            
            return {
                'success': True,
                'student_name': profile['student_info']['name'],
                'recommendations': parsed_recommendations,
                'raw_recommendations': response.text,
                'challenge_level': determine_challenge_level(profile),
                'analysis_based_on': profile['question_patterns'].get('total_questions', 0),
                'generated_at': datetime.datetime.now().isoformat()
            }
        else:
            return {'error': 'Failed to generate recommendations'}
            
    except Exception as e:
        logger.error(f"å€‹äººåŒ–å»ºè­°ç”ŸæˆéŒ¯èª¤: {e}")
        return {'error': str(e)}

def parse_recommendations(recommendations_text):
    """è§£æå»ºè­°æ–‡æœ¬"""
    try:
        # ç°¡åŒ–çš„å»ºè­°è§£æ
        recommendations = {
            'immediate_focus': [],
            'skill_development': [],
            'learning_resources': [],
            'teacher_notes': []
        }
        
        # å°‡æ•´å€‹å»ºè­°æ–‡æœ¬ä½œç‚ºæ•™å¸«ç­†è¨˜
        recommendations['teacher_notes'] = [recommendations_text]
        
        # åŸºæ–¼å…§å®¹ç”Ÿæˆçµæ§‹åŒ–å»ºè­°
        if 'participation' in recommendations_text.lower():
            recommendations['immediate_focus'].append({
                'area': 'Participation',
                'suggestion': 'Encourage more active engagement in discussions',
                'action': 'Set specific participation goals'
            })
        
        if 'question' in recommendations_text.lower():
            recommendations['skill_development'].append({
                'area': 'Questioning Skills',
                'suggestion': 'Develop higher-order thinking questions',
                'action': 'Practice analytical and evaluative questions'
            })
        
        return recommendations
        
    except Exception as e:
        logger.error(f"å»ºè­°è§£æéŒ¯èª¤: {e}")
        return {'teacher_notes': [recommendations_text]}

def determine_challenge_level(profile):
    """ç¢ºå®šé©åˆçš„æŒ‘æˆ°ç¨‹åº¦"""
    try:
        cognitive_dev = profile.get('cognitive_development', {})
        
        participation_rate = profile['student_info']['participation_rate']
        
        if participation_rate >= 75 and cognitive_dev.get('development_trend') == 'improving':
            return 'Ready for advanced challenges'
        elif participation_rate >= 50:
            return 'Suitable for moderate complexity tasks'
        else:
            return 'Focus on foundational engagement'
            
    except Exception as e:
        return 'Assessment in progress'

# =========================================
# 3. ç­ç´šæ•´é«”åˆ†æåŠŸèƒ½
# =========================================

def analyze_class_engagement():
    """åˆ†æç­ç´šæ•´é«”åƒèˆ‡åº¦"""
    try:
        students = list(Student.select().where(~Student.name.startswith('[DEMO]')))
        
        if not students:
            return {'status': 'no_students'}
        
        # åƒèˆ‡åº¦åˆ†ç´šçµ±è¨ˆ
        engagement_levels = {
            'high': len([s for s in students if s.participation_rate >= 75]),
            'medium': len([s for s in students if 50 <= s.participation_rate < 75]),
            'low': len([s for s in students if s.participation_rate < 50])
        }
        
        # å¹³å‡çµ±è¨ˆ
        avg_participation = sum(s.participation_rate for s in students) / len(students)
        avg_questions = sum(s.question_count for s in students) / len(students)
        avg_messages = sum(s.message_count for s in students) / len(students)
        
        # è¶¨å‹¢åˆ†æï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        recent_activity = analyze_recent_class_activity()
        
        return {
            'total_students': len(students),
            'engagement_levels': engagement_levels,
            'avg_participation': round(avg_participation, 1),
            'avg_questions': round(avg_questions, 1),
            'avg_messages': round(avg_messages, 1),
            'trend': recent_activity.get('trend', 'stable'),
            'class_performance': classify_class_performance(avg_participation)
        }
        
    except Exception as e:
        logger.error(f"ç­ç´šåƒèˆ‡åº¦åˆ†æéŒ¯èª¤: {e}")
        return {'error': str(e)}

def analyze_recent_class_activity():
    """åˆ†ææœ€è¿‘ç­ç´šæ´»å‹•è¶¨å‹¢"""
    try:
        # æœ€è¿‘ä¸€é€± vs å‰ä¸€é€±çš„æ´»å‹•æ¯”è¼ƒ
        now = datetime.datetime.now()
        recent_week = now - datetime.timedelta(days=7)
        previous_week = now - datetime.timedelta(days=14)
        
        recent_messages = Message.select().where(Message.timestamp > recent_week).count()
        previous_messages = Message.select().where(
            Message.timestamp.between(previous_week, recent_week)
        ).count()
        
        if previous_messages > 0:
            change_ratio = recent_messages / previous_messages
            if change_ratio > 1.1:
                trend = 'increasing'
            elif change_ratio < 0.9:
                trend = 'decreasing'
            else:
                trend = 'stable'
        else:
            trend = 'insufficient_data'
        
        return {
            'recent_messages': recent_messages,
            'previous_messages': previous_messages,
            'trend': trend,
            'change_ratio': round(change_ratio if previous_messages > 0 else 0, 2)
        }
        
    except Exception as e:
        logger.error(f"è¿‘æœŸæ´»å‹•è¶¨å‹¢åˆ†æéŒ¯èª¤: {e}")
        return {'trend': 'unknown'}

def classify_class_performance(avg_participation):
    """åˆ†é¡ç­ç´šæ•´é«”è¡¨ç¾"""
    if avg_participation >= 75:
        return 'excellent'
    elif avg_participation >= 60:
        return 'good'
    elif avg_participation >= 45:
        return 'satisfactory'
    else:
        return 'needs_attention'

def analyze_cognitive_development_trends():
    """åˆ†æç­ç´šèªçŸ¥ç™¼å±•è¶¨å‹¢"""
    try:
        # å–å¾—æ‰€æœ‰å•é¡Œåˆ†é¡åˆ†æ
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ).order_by(Analysis.timestamp.asc()))
        
        if len(analyses) < 10:
            return {'status': 'insufficient_data'}
        
        # æŒ‰æœˆåˆ†çµ„åˆ†æèªçŸ¥å±¤æ¬¡åˆ†å¸ƒ
        monthly_cognitive = defaultdict(lambda: Counter())
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                month_key = analysis.timestamp.strftime('%Y-%m')
                cognitive_level = data.get('cognitive_level', 'Unknown')
                monthly_cognitive[month_key][cognitive_level] += 1
            except json.JSONDecodeError:
                continue
        
        # è¨ˆç®—è¶¨å‹¢
        trends = {
            'monthly_distribution': dict(monthly_cognitive),
            'overall_distribution': Counter(),
            'development_direction': 'analyzing'
        }
        
        # è¨ˆç®—æ•´é«”åˆ†å¸ƒ
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                trends['overall_distribution'][data.get('cognitive_level', 'Unknown')] += 1
            except json.JSONDecodeError:
                continue
        
        trends['overall_distribution'] = dict(trends['overall_distribution'])
        
        return trends
        
    except Exception as e:
        logger.error(f"èªçŸ¥ç™¼å±•è¶¨å‹¢åˆ†æéŒ¯èª¤: {e}")
        return {'error': str(e)}

def analyze_learning_difficulties():
    """åˆ†æå­¸ç¿’å›°é›£é»"""
    try:
        # åˆ†æä½åƒèˆ‡åº¦å­¸ç”Ÿ
        struggling_students = list(Student.select().where(
            (Student.participation_rate < 50) & 
            (~Student.name.startswith('[DEMO]'))
        ))
        
        # åˆ†æå¸¸è¦‹å•é¡Œé¡å‹ä¸­çš„å›°é›£æ¨¡å¼
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        difficulty_patterns = {
            'struggling_students_count': len(struggling_students),
            'common_difficulty_areas': Counter(),
            'question_complexity_issues': Counter()
        }
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                if data.get('difficulty') == 'Hard':
                    difficulty_patterns['common_difficulty_areas'][data.get('content_domain', 'Unknown')] += 1
                
                if data.get('language_complexity') == 'Advanced':
                    difficulty_patterns['question_complexity_issues'][data.get('question_type', 'Unknown')] += 1
                    
            except json.JSONDecodeError:
                continue
        
        # è½‰æ›ç‚ºå­—å…¸
        difficulty_patterns['common_difficulty_areas'] = dict(difficulty_patterns['common_difficulty_areas'])
        difficulty_patterns['question_complexity_issues'] = dict(difficulty_patterns['question_complexity_issues'])
        
        return difficulty_patterns
        
    except Exception as e:
        logger.error(f"å­¸ç¿’å›°é›£é»åˆ†æéŒ¯èª¤: {e}")
        return {'error': str(e)}

def generate_class_teaching_recommendations():
    """ç”Ÿæˆç­ç´šæ•™å­¸å»ºè­°"""
    try:
        if not model:
            return [{'title': 'AI æœå‹™ä¸å¯ç”¨', 'description': 'ç„¡æ³•ç”Ÿæˆæ™ºèƒ½å»ºè­°'}]
        
        # æ”¶é›†ç­ç´šæ•´é«”åˆ†æè³‡æ–™
        engagement_analysis = analyze_class_engagement()
        cognitive_trends = analyze_cognitive_development_trends()
        difficulty_analysis = analyze_learning_difficulties()
        
        # ç”Ÿæˆç­ç´šå»ºè­°
        class_prompt = f"""Based on this EMI class analysis, provide teaching recommendations:

Class Engagement Analysis:
{json.dumps(engagement_analysis, indent=2)}

Cognitive Development Trends:
{json.dumps(cognitive_trends, indent=2)}

Learning Difficulties Analysis:
{json.dumps(difficulty_analysis, indent=2)}

Provide 3-5 specific, actionable teaching recommendations for this EMI class:"""

        response = model.generate_content(class_prompt)
        
        if response and response.text:
            # è§£æç‚ºå»ºè­°åˆ—è¡¨
            recommendations = parse_class_recommendations(response.text)
            return recommendations
        else:
            return [{'title': 'å»ºè­°ç”Ÿæˆä¸­', 'description': 'ç³»çµ±æ­£åœ¨åˆ†æç­ç´šç‹€æ³...'}]
            
    except Exception as e:
        logger.error(f"ç­ç´šæ•™å­¸å»ºè­°ç”ŸæˆéŒ¯èª¤: {e}")
        return [{'title': 'åˆ†æéŒ¯èª¤', 'description': f'å»ºè­°ç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)[:50]}'}]

def parse_class_recommendations(recommendations_text):
    """è§£æç­ç´šå»ºè­°æ–‡æœ¬"""
    try:
        # ç°¡å–®çš„æ–‡æœ¬è§£æç‚ºå»ºè­°åˆ—è¡¨
        lines = recommendations_text.split('\n')
        recommendations = []
        
        current_title = ""
        current_desc = ""
        
        for line in lines:
            line = line.strip()
            if line and (line.startswith('**') or line.startswith('#') or line.endswith(':')):
                # å¦‚æœæœ‰å‰ä¸€å€‹å»ºè­°ï¼Œå…ˆåŠ å…¥åˆ—è¡¨
                if current_title:
                    recommendations.append({
                        'title': current_title,
                        'description': current_desc.strip()
                    })
                
                # é–‹å§‹æ–°å»ºè­°
                current_title = line.replace('**', '').replace('#', '').replace(':', '').strip()
                current_desc = ""
            elif line and current_title:
                current_desc += line + " "
        
        # åŠ å…¥æœ€å¾Œä¸€å€‹å»ºè­°
        if current_title:
            recommendations.append({
                'title': current_title,
                'description': current_desc.strip()
            })
        
        # å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å›æ•´å€‹æ–‡æœ¬ä½œç‚ºå–®ä¸€å»ºè­°
        if not recommendations:
            recommendations = [{
                'title': 'ç­ç´šæ•™å­¸å»ºè­°',
                'description': recommendations_text[:200] + "..." if len(recommendations_text) > 200 else recommendations_text
            }]
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5å€‹å»ºè­°
        
    except Exception as e:
        logger.error(f"ç­ç´šå»ºè­°è§£æéŒ¯èª¤: {e}")
        return [{'title': 'å»ºè­°è§£æä¸­', 'description': 'æ­£åœ¨è™•ç†æ•™å­¸å»ºè­°...'}]

# =========================================
# è¼”åŠ©å‡½æ•¸
# =========================================

def get_question_category_distribution():
    """å–å¾—å•é¡Œåˆ†é¡åˆ†å¸ƒ"""
    try:
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        categories = {}
        cognitive_levels = {}
        question_types = {}
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                
                # å…§å®¹é ˜åŸŸ
                domain = data.get('content_domain', 'Unknown')
                categories[domain] = categories.get(domain, 0) + 1
                
                # èªçŸ¥å±¤æ¬¡
                cognitive = data.get('cognitive_level', 'Unknown')
                cognitive_levels[cognitive] = cognitive_levels.get(cognitive, 0) + 1
                
                # å•é¡Œé¡å‹
                q_type = data.get('question_type', 'Unknown')
                question_types[q_type] = question_types.get(q_type, 0) + 1
                
            except json.JSONDecodeError:
                continue
        
        return {
            'content_domains': categories,
            'cognitive_levels': cognitive_levels,
            'question_types': question_types
        }
        
    except Exception as e:
        return {'error': str(e)}

def get_cognitive_level_distribution():
    """å–å¾—èªçŸ¥å±¤æ¬¡åˆ†å¸ƒ"""
    try:
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        distribution = Counter()
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                cognitive_level = data.get('cognitive_level', 'Unknown')
                distribution[cognitive_level] += 1
            except json.JSONDecodeError:
                continue
        
        return dict(distribution)
        
    except Exception as e:
        return {'error': str(e)}

def get_engagement_timeline():
    """å–å¾—åƒèˆ‡åº¦æ™‚é–“ç·š"""
    try:
        # æŒ‰é€±çµ±è¨ˆåƒèˆ‡åº¦
        messages = list(Message.select().order_by(Message.timestamp.asc()))
        
        if not messages:
            return {'status': 'no_data'}
        
        # æŒ‰é€±åˆ†çµ„
        weekly_engagement = defaultdict(int)
        
        for message in messages:
            week_key = message.timestamp.strftime('%Y-W%U')
            weekly_engagement[week_key] += 1
        
        return {
            'weekly_data': dict(weekly_engagement),
            'total_weeks': len(weekly_engagement)
        }
        
    except Exception as e:
        return {'error': str(e)}

def get_difficulty_heatmap():
    """å–å¾—å›°é›£åº¦ç†±åŠ›åœ–è³‡æ–™"""
    try:
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        heatmap_data = defaultdict(lambda: defaultdict(int))
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                content_domain = data.get('content_domain', 'Unknown')
                difficulty = data.get('difficulty', 'Unknown')
                heatmap_data[content_domain][difficulty] += 1
            except json.JSONDecodeError:
                continue
        
        # è½‰æ›ç‚ºé©åˆå‰ç«¯çš„æ ¼å¼
        formatted_data = []
        for domain, difficulties in heatmap_data.items():
            for difficulty, count in difficulties.items():
                formatted_data.append({
                    'domain': domain,
                    'difficulty': difficulty,
                    'count': count
                })
        
        return formatted_data
        
    except Exception as e:
        return {'error': str(e)}

def get_class_learning_progress():
    """å–å¾—ç­ç´šå­¸ç¿’é€²åº¦"""
    try:
        students = list(Student.select().where(~Student.name.startswith('[DEMO]')))
        
        progress_data = []
        
        for student in students:
            analyses = list(Analysis.select().where(
                (Analysis.student_id == student.id) &
                (Analysis.analysis_type == 'question_classification')
            ).order_by(Analysis.timestamp.asc()))
            
            if analyses:
                # è¨ˆç®—èªçŸ¥å±¤æ¬¡é€²å±•
                cognitive_progression = []
                for analysis in analyses:
                    try:
                        data = json.loads(analysis.analysis_data)
                        cognitive_level = data.get('cognitive_level', 'Unknown')
                        cognitive_progression.append(cognitive_level)
                    except json.JSONDecodeError:
                        continue
                
                progress_data.append({
                    'student_name': student.name,
                    'participation_rate': student.participation_rate,
                    'cognitive_progression': cognitive_progression,
                    'total_analyses': len(analyses)
                })
        
        return progress_data
        
    except Exception as e:
        return {'error': str(e)}
