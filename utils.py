# utils.py - é…é¡æ„ŸçŸ¥çš„æ™ºæ…§å‚™æ¡ˆç³»çµ±

import os
import json
import datetime
import logging
import time
import google.generativeai as genai
from models import Student, Message, Analysis, db

logger = logging.getLogger(__name__)

# åˆå§‹åŒ– Gemini AI - æ™ºæ…§é…é¡ç®¡ç†
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
model = None
current_model_name = None

# é…é¡è¿½è¹¤å­—å…¸
quota_tracker = {
    'gemini-2.0-flash': {'daily_limit': 200, 'used_today': 0, 'last_reset': None},
    'gemini-2.0-flash-lite': {'daily_limit': 200, 'used_today': 0, 'last_reset': None},
    'gemini-1.5-flash': {'daily_limit': 1500, 'used_today': 0, 'last_reset': None},  # 1.5 ç‰ˆæœ¬é€šå¸¸æœ‰æ›´é«˜é™åˆ¶
    'gemini-1.5-pro': {'daily_limit': 50, 'used_today': 0, 'last_reset': None},
}

def reset_daily_quota_if_needed():
    """æª¢æŸ¥æ˜¯å¦éœ€è¦é‡ç½®æ¯æ—¥é…é¡è¨ˆæ•¸"""
    today = datetime.date.today()
    
    for model_name in quota_tracker:
        tracker = quota_tracker[model_name]
        if tracker['last_reset'] != today:
            tracker['used_today'] = 0
            tracker['last_reset'] = today
            logger.info(f"ğŸ”„ é‡ç½® {model_name} æ¯æ—¥é…é¡è¨ˆæ•¸")

def is_model_available(model_name):
    """æª¢æŸ¥æ¨¡å‹æ˜¯å¦é‚„æœ‰é…é¡å¯ç”¨"""
    reset_daily_quota_if_needed()
    
    if model_name not in quota_tracker:
        return True  # æœªçŸ¥æ¨¡å‹ï¼Œå‡è¨­å¯ç”¨
    
    tracker = quota_tracker[model_name]
    available = tracker['used_today'] < tracker['daily_limit']
    
    if not available:
        logger.warning(f"âš ï¸ {model_name} é…é¡å·²ç”¨å®Œ ({tracker['used_today']}/{tracker['daily_limit']})")
    
    return available

def record_model_usage(model_name):
    """è¨˜éŒ„æ¨¡å‹ä½¿ç”¨æ¬¡æ•¸"""
    if model_name in quota_tracker:
        quota_tracker[model_name]['used_today'] += 1
        used = quota_tracker[model_name]['used_today']
        limit = quota_tracker[model_name]['daily_limit']
        logger.info(f"ğŸ“Š {model_name} ä½¿ç”¨é‡: {used}/{limit}")

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # æ™ºæ…§æ¨¡å‹é¸æ“‡ - ä¾é…é¡å¯ç”¨æ€§æ’åº
        models_to_try = [
            # å„ªå…ˆä½¿ç”¨é‚„æœ‰é…é¡çš„æ¨¡å‹
            'gemini-2.0-flash-lite',     # æ‚¨é‚„æœ‰ 36% é…é¡å¯ç”¨
            'gemini-1.5-flash',          # é€šå¸¸é…é¡æ›´é«˜
            'gemini-1.5-flash-001',      
            'gemini-1.5-flash-8b',       # 8B ç‰ˆæœ¬æ›´ç¶“æ¿Ÿ
            'gemini-1.5-pro',            # åŠŸèƒ½æ›´å¼·ä½†é…é¡è¼ƒå°‘
            'gemini-1.5-pro-001',
            'gemini-2.0-flash',          # å·²è¶…é™ï¼Œä½†å¯èƒ½åŠå¤œé‡ç½®
            'gemini-2.0-flash-001',      
            'gemini-1.0-pro',            # æœ€å¾Œå‚™æ¡ˆ
            'gemini-1.0-pro-001'
        ]
        
        for model_name in models_to_try:
            # æª¢æŸ¥é…é¡ç‹€æ…‹
            if not is_model_available(model_name):
                logger.info(f"â­ï¸ è·³é {model_name} (é…é¡ä¸è¶³)")
                continue
                
            try:
                test_model = genai.GenerativeModel(model_name)
                
                # è¼•é‡æ¸¬è©¦ï¼ˆé¿å…æµªè²»é…é¡ï¼‰
                test_response = test_model.generate_content(
                    "Test",
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=5,
                        temperature=0.1
                    )
                )
                
                if test_response and test_response.text:
                    model = test_model
                    current_model_name = model_name
                    record_model_usage(model_name)  # è¨˜éŒ„æ¸¬è©¦ä½¿ç”¨
                    logger.info(f"âœ… Gemini AI æˆåŠŸåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
                    break
                    
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg:
                    logger.warning(f"âš ï¸ {model_name} é…é¡è¶…é™ï¼Œæ¨™è¨˜ç‚ºä¸å¯ç”¨")
                    # æ¨™è¨˜ç‚ºå·²ç”¨å®Œ
                    if model_name in quota_tracker:
                        quota_tracker[model_name]['used_today'] = quota_tracker[model_name]['daily_limit']
                elif "403" in error_msg:
                    logger.warning(f"âš ï¸ {model_name} æ¬Šé™ä¸è¶³: {error_msg[:50]}")
                elif "404" in error_msg:
                    logger.warning(f"âš ï¸ {model_name} æ¨¡å‹ä¸å­˜åœ¨")
                else:
                    logger.warning(f"âš ï¸ {model_name} æ¸¬è©¦å¤±æ•—: {error_msg[:50]}")
                continue
        
        if not model:
            logger.error("âŒ æ‰€æœ‰ Gemini æ¨¡å‹éƒ½ä¸å¯ç”¨")
            logger.info("ğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆ:")
            logger.info("   1. ç­‰å¾…é…é¡é‡ç½®ï¼ˆé€šå¸¸ç‚º UTC åˆå¤œï¼‰")
            logger.info("   2. å‡ç´šåˆ°ä»˜è²»æ–¹æ¡ˆä»¥ç²å¾—æ›´é«˜é…é¡")
            logger.info("   3. æ–°å¢å…¶ä»– AI æœå‹™å•†ä½œç‚ºå‚™æ¡ˆ")
            
    except Exception as e:
        logger.error(f"âŒ Gemini AI åˆå§‹åŒ–å¤±æ•—: {e}")
else:
    logger.warning("âš ï¸ Gemini API key not found")

def generate_ai_response_with_smart_fallback(student_id, query, conversation_context="", student_context="", group_id=None):
    """æ™ºæ…§å‚™æ¡ˆçš„ AI å›æ‡‰ç”Ÿæˆ"""
    global model, current_model_name
    
    if not model:
        logger.error("âŒ AI æ¨¡å‹æœªåˆå§‹åŒ–")
        return "Sorry, AI service is currently unavailable. This might be due to daily quota limits. Please try again later."
    
    try:
        # æª¢æŸ¥ç•¶å‰æ¨¡å‹æ˜¯å¦é‚„æœ‰é…é¡
        if not is_model_available(current_model_name):
            logger.warning(f"âš ï¸ ç•¶å‰æ¨¡å‹ {current_model_name} é…é¡ä¸è¶³ï¼Œå˜—è©¦åˆ‡æ›...")
            
            # å˜—è©¦åˆ‡æ›åˆ°å…¶ä»–å¯ç”¨æ¨¡å‹
            success = switch_to_available_model()
            if not success:
                return "AI service has reached daily quota limits. Please try again later or contact administrator to upgrade the service plan."
        
        # æ§‹å»ºæç¤ºè©
        student = Student.get_by_id(student_id) if student_id else None
        
        prompt = f"""You are an AI Teaching Assistant for English-medium instruction (EMI) courses.

{"Previous conversation context:" + chr(10) + conversation_context + chr(10) if conversation_context else ""}

Instructions:
- Respond primarily in clear, simple English suitable for university-level ESL learners
- Use vocabulary appropriate for intermediate English learners
- For technical terms, provide Chinese translation in parentheses when helpful
- Maintain a friendly, encouraging, and educational tone
- If this continues a previous conversation, build on what was discussed before
- Encourage further questions and deeper thinking

{student_context if student_context else ""}

Student question: {query}

Please provide a helpful response (100-150 words):"""
        
        logger.info(f"ğŸ¤– ä½¿ç”¨ {current_model_name} ç”Ÿæˆå›æ‡‰...")
        
        # æ ¹æ“šæ¨¡å‹èª¿æ•´é…ç½®
        if 'lite' in current_model_name or '8b' in current_model_name:
            # è¼•é‡æ¨¡å‹ä½¿ç”¨è¼ƒä¿å®ˆçš„è¨­å®š
            generation_config = genai.types.GenerationConfig(
                candidate_count=1,
                max_output_tokens=300,
                temperature=0.6,
                top_p=0.8,
                top_k=30
            )
        else:
            # æ¨™æº–æ¨¡å‹è¨­å®š
            generation_config = genai.types.GenerationConfig(
                candidate_count=1,
                max_output_tokens=350,
                temperature=0.7,
                top_p=0.9,
                top_k=40
            )
        
        response = model.generate_content(prompt, generation_config=generation_config)
        
        if response and response.text:
            # è¨˜éŒ„æˆåŠŸä½¿ç”¨
            record_model_usage(current_model_name)
            
            ai_response = response.text.strip()
            logger.info(f"âœ… AI å›æ‡‰æˆåŠŸç”Ÿæˆï¼Œé•·åº¦: {len(ai_response)} å­—")
            return ai_response
        else:
            logger.error("âŒ AI å›æ‡‰ç‚ºç©º")
            return "Sorry, I cannot generate an appropriate response right now. Please try again later."
            
    except Exception as e:
        error_msg = str(e).lower()
        logger.error(f"âŒ AI å›æ‡‰éŒ¯èª¤: {str(e)}")
        
        # æ™ºæ…§éŒ¯èª¤è™•ç†
        if "429" in error_msg or "quota" in error_msg or "limit" in error_msg:
            # é…é¡å•é¡Œï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹
            logger.warning("ğŸ”„ åµæ¸¬åˆ°é…é¡å•é¡Œï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹...")
            success = switch_to_available_model()
            if success:
                logger.info(f"âœ… å·²åˆ‡æ›åˆ° {current_model_name}ï¼Œé‡æ–°å˜—è©¦...")
                # éè¿´é‡è©¦ä¸€æ¬¡
                return generate_ai_response_with_smart_fallback(student_id, query, conversation_context, student_context, group_id)
            else:
                return "AI service quota exceeded. Please try again later when quota resets (typically at midnight UTC)."
        else:
            return "An error occurred while processing your question. Please try again later."

def switch_to_available_model():
    """åˆ‡æ›åˆ°å¯ç”¨çš„æ¨¡å‹"""
    global model, current_model_name
    
    models_to_try = [
        'gemini-2.0-flash-lite',
        'gemini-1.5-flash', 
        'gemini-1.5-flash-8b',
        'gemini-1.5-pro',
        'gemini-2.0-flash',
        'gemini-1.0-pro'
    ]
    
    for model_name in models_to_try:
        if model_name == current_model_name:
            continue  # è·³éç•¶å‰æ¨¡å‹
            
        if not is_model_available(model_name):
            continue
            
        try:
            test_model = genai.GenerativeModel(model_name)
            # å¿«é€Ÿæ¸¬è©¦
            test_response = test_model.generate_content(
                "Hi",
                generation_config=genai.types.GenerationConfig(max_output_tokens=3)
            )
            
            if test_response and test_response.text:
                model = test_model
                current_model_name = model_name
                record_model_usage(model_name)
                logger.info(f"âœ… æˆåŠŸåˆ‡æ›åˆ° {model_name}")
                return True
                
        except Exception as e:
            if "429" in str(e):
                # æ¨™è¨˜ç‚ºé…é¡ç”¨å®Œ
                if model_name in quota_tracker:
                    quota_tracker[model_name]['used_today'] = quota_tracker[model_name]['daily_limit']
            continue
    
    logger.error("âŒ æ²’æœ‰å¯ç”¨çš„å‚™æ¡ˆæ¨¡å‹")
    return False

def get_quota_status():
    """å–å¾—é…é¡ç‹€æ…‹å ±å‘Š"""
    reset_daily_quota_if_needed()
    
    status = {
        'current_model': current_model_name,
        'models': {},
        'recommendations': []
    }
    
    for model_name, tracker in quota_tracker.items():
        used_pct = (tracker['used_today'] / tracker['daily_limit']) * 100 if tracker['daily_limit'] > 0 else 0
        status['models'][model_name] = {
            'used': tracker['used_today'],
            'limit': tracker['daily_limit'],
            'available': tracker['daily_limit'] - tracker['used_today'],
            'usage_percent': round(used_pct, 1),
            'status': 'å¯ç”¨' if used_pct < 100 else 'å·²ç”¨å®Œ'
        }
    
    # ç”Ÿæˆå»ºè­°
    available_models = [name for name, info in status['models'].items() if info['usage_percent'] < 100]
    if not available_models:
        status['recommendations'].append("æ‰€æœ‰æ¨¡å‹é…é¡å·²ç”¨å®Œï¼Œå»ºè­°ç­‰å¾…é‡ç½®æˆ–å‡ç´šæ–¹æ¡ˆ")
    elif len(available_models) == 1:
        status['recommendations'].append(f"åƒ…å‰© {available_models[0]} å¯ç”¨ï¼Œå»ºè­°ç¯€ç´„ä½¿ç”¨")
    
    return status

def test_ai_connection():
    """æ¸¬è©¦ AI é€£æ¥"""
    try:
        if not model:
            return False, "AI æ¨¡å‹æœªåˆå§‹åŒ–"
        
        quota_status = get_quota_status()
        available_models = [name for name, info in quota_status['models'].items() if info['usage_percent'] < 100]
        
        if not available_models:
            return False, "æ‰€æœ‰æ¨¡å‹é…é¡å·²ç”¨å®Œ"
        
        return True, f"é€£æ¥æ­£å¸¸ - ç•¶å‰: {current_model_name}, å¯ç”¨æ¨¡å‹: {len(available_models)}"
        
    except Exception as e:
        return False, f"é€£æ¥éŒ¯èª¤: {str(e)[:60]}..."

# å…¼å®¹æ€§ï¼šä¿æŒåŸæœ‰å‡½æ•¸åç¨±
def generate_ai_response(student_id, query, conversation_context="", student_context="", group_id=None):
    """åŸæœ‰å‡½æ•¸çš„å…¼å®¹æ€§åŒ…è£"""
    return generate_ai_response_with_smart_fallback(student_id, query, conversation_context, student_context, group_id)
# å°‡é€™äº›å‡½æ•¸æ·»åŠ åˆ° utils.py æª”æ¡ˆçš„æœ«å°¾

def analyze_student_patterns(student_id):
    """åˆ†æå­¸ç”Ÿå­¸ç¿’æ¨¡å¼"""
    try:
        student = Student.get_by_id(student_id)
        messages = list(Message.select().where(Message.student_id == student_id))
        
        # åˆ†æè¨Šæ¯é¡å‹åˆ†å¸ƒ
        message_types = {}
        for msg in messages:
            msg_type = msg.message_type or 'general'
            message_types[msg_type] = message_types.get(msg_type, 0) + 1
        
        # åˆ†ææ´»å‹•æ™‚é–“æ¨¡å¼
        if messages:
            timestamps = [msg.timestamp for msg in messages if msg.timestamp]
            if timestamps:
                earliest = min(timestamps)
                latest = max(timestamps)
                active_days = (latest - earliest).days + 1
            else:
                active_days = 0
        else:
            active_days = 0
        
        # è¨ˆç®—å¹³å‡è¨Šæ¯é•·åº¦
        if messages:
            avg_message_length = sum(len(msg.content) for msg in messages) / len(messages)
        else:
            avg_message_length = 0
        
        return {
            'student_id': student_id,
            'student_name': student.name,
            'total_messages': len(messages),
            'message_types': message_types,
            'participation_rate': student.participation_rate,
            'question_count': student.question_count,
            'active_days': active_days,
            'avg_message_length': round(avg_message_length, 2),
            'analysis_timestamp': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"åˆ†æå­¸ç”Ÿæ¨¡å¼éŒ¯èª¤: {e}")
        return {'error': str(e)}

def update_student_stats(student_id, message_type='message'):
    """æ›´æ–°å­¸ç”Ÿçµ±è¨ˆè³‡æ–™"""
    try:
        student = Student.get_by_id(student_id)
        
        # é‡æ–°è¨ˆç®—æ‰€æœ‰çµ±è¨ˆ
        messages = list(Message.select().where(Message.student_id == student_id))
        
        # æ›´æ–°è¨Šæ¯è¨ˆæ•¸
        student.message_count = len(messages)
        
        # æ›´æ–°å•é¡Œè¨ˆæ•¸
        questions = [msg for msg in messages if msg.message_type == 'question']
        student.question_count = len(questions)
        
        # è¨ˆç®—åƒèˆ‡ç‡
        if student.message_count > 0:
            # é€™è£¡çš„å…¬å¼å¯ä»¥æ ¹æ“šä½ çš„éœ€æ±‚èª¿æ•´
            question_ratio = student.question_count / student.message_count
            student.participation_rate = min(100, question_ratio * 100)
        else:
            student.participation_rate = 0
        
        # æ›´æ–°æœ€å¾Œæ´»å‹•æ™‚é–“
        if messages:
            latest_message = max(messages, key=lambda m: m.timestamp if m.timestamp else datetime.datetime.min)
            student.last_active = latest_message.timestamp
        else:
            student.last_active = datetime.datetime.now()
        
        # å„²å­˜æ›´æ–°
        student.save()
        
        logger.info(f"âœ… å­¸ç”Ÿ {student.name} çµ±è¨ˆå·²æ›´æ–°: {student.message_count} è¨Šæ¯, {student.question_count} å•é¡Œ")
        
        return {
            'success': True,
            'student_id': student_id,
            'message_count': student.message_count,
            'question_count': student.question_count,
            'participation_rate': round(student.participation_rate, 2),
            'last_active': student.last_active.isoformat() if student.last_active else None
        }
        
    except Exception as e:
        logger.error(f"æ›´æ–°å­¸ç”Ÿçµ±è¨ˆéŒ¯èª¤: {e}")
        return {'success': False, 'error': str(e)}

def get_question_category_stats():
    """å–å¾—å•é¡Œåˆ†é¡çµ±è¨ˆ"""
    try:
        # å¾ Analysis è¡¨æ ¼å–å¾—åˆ†é¡è³‡æ–™
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        if not analyses:
            return {
                'total_questions': 0,
                'categories': {},
                'message': 'ç›®å‰æ²’æœ‰å•é¡Œåˆ†é¡è³‡æ–™'
            }
        
        # çµ±è¨ˆå„é¡åˆ¥
        categories = {}
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                category = data.get('content_domain', 'Unknown')
                categories[category] = categories.get(category, 0) + 1
            except (json.JSONDecodeError, KeyError):
                categories['Unknown'] = categories.get('Unknown', 0) + 1
        
        return {
            'total_questions': len(analyses),
            'categories': categories,
            'top_category': max(categories.items(), key=lambda x: x[1])[0] if categories else None,
            'generated_at': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"å•é¡Œåˆ†é¡çµ±è¨ˆéŒ¯èª¤: {e}")
        return {'error': str(e)}

def get_student_conversation_summary(student_id, days=30):
    """å–å¾—å­¸ç”Ÿå°è©±æ‘˜è¦"""
    try:
        student = Student.get_by_id(student_id)
        
        # å–å¾—æŒ‡å®šå¤©æ•¸å…§çš„è¨Šæ¯
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)
        messages = list(Message.select().where(
            (Message.student_id == student_id) &
            (Message.timestamp > cutoff_date)
        ).order_by(Message.timestamp.desc()))
        
        if not messages:
            return {
                'student_id': student_id,
                'student_name': student.name,
                'period_days': days,
                'message_count': 0,
                'summary': 'åœ¨æ­¤æœŸé–“æ²’æœ‰å°è©±è¨˜éŒ„',
                'status': 'no_data'
            }
        
        # åˆ†æè¨Šæ¯é¡å‹
        questions = [msg for msg in messages if msg.message_type == 'question']
        statements = [msg for msg in messages if msg.message_type == 'statement']
        
        # ç”¢ç”Ÿç°¡å–®æ‘˜è¦
        summary_parts = []
        summary_parts.append(f"åœ¨æœ€è¿‘ {days} å¤©å…§ï¼Œ{student.name} å…±ç™¼é€äº† {len(messages)} å‰‡è¨Šæ¯")
        
        if questions:
            summary_parts.append(f"å…¶ä¸­åŒ…å« {len(questions)} å€‹å•é¡Œ")
        
        if statements:
            summary_parts.append(f"ä»¥åŠ {len(statements)} å€‹é™³è¿°")
        
        # è¨ˆç®—æ´»èºåº¦
        if len(messages) >= 10:
            activity_level = "é«˜åº¦æ´»èº"
        elif len(messages) >= 5:
            activity_level = "é©åº¦æ´»èº"
        else:
            activity_level = "è¼ƒå°‘åƒèˆ‡"
        
        summary_parts.append(f"æ•´é«”åƒèˆ‡åº¦ç‚ºï¼š{activity_level}")
        
        return {
            'student_id': student_id,
            'student_name': student.name,
            'period_days': days,
            'message_count': len(messages),
            'question_count': len(questions),
            'statement_count': len(statements),
            'activity_level': activity_level,
            'summary': 'ã€‚'.join(summary_parts) + 'ã€‚',
            'generated_at': datetime.datetime.now().isoformat(),
            'status': 'success'
        }
        
    except Exception as e:
        logger.error(f"å°è©±æ‘˜è¦éŒ¯èª¤: {e}")
        return {
            'student_id': student_id,
            'error': str(e),
            'status': 'error'
        }

# å…¼å®¹æ€§åˆ¥å
get_ai_response = generate_ai_response_with_smart_fallback
