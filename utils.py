import os
import json
import datetime
import logging
import random
import google.generativeai as genai
from models import Student, Message, Analysis, db

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)

# åˆå§‹åŒ– Gemini AI - ä½¿ç”¨ 2.0 æ¨¡å‹
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
model = None
current_model_name = None

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # æ ¹æ“šå®˜æ–¹æ–‡ä»¶ï¼Œä½¿ç”¨å¯ç”¨çš„ Gemini 2.0 æ¨¡å‹
        models_to_try = [
            'gemini-2.0-flash',           # è‡ªå‹•æ›´æ–°åˆ¥åï¼ŒæŒ‡å‘æœ€æ–°ç©©å®šç‰ˆ
            'gemini-2.0-flash-001',       # æœ€æ–°ç©©å®šç‰ˆæœ¬
            'gemini-2.0-flash-lite',      # è¼•é‡ç‰ˆè‡ªå‹•æ›´æ–°åˆ¥å
            'gemini-2.0-flash-lite-001',  # è¼•é‡ç‰ˆç©©å®šç‰ˆæœ¬
        ]
        
        for model_name in models_to_try:
            try:
                test_model = genai.GenerativeModel(model_name)
                # é€²è¡Œç°¡å–®æ¸¬è©¦ç¢ºèªæ¨¡å‹å¯ç”¨
                test_response = test_model.generate_content("æ¸¬è©¦")
                if test_response and test_response.text:
                    model = test_model
                    current_model_name = model_name
                    logger.info(f"âœ… Gemini AI æˆåŠŸåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} æ¸¬è©¦å¤±æ•—: {str(e)[:100]}")
                continue
        
        if not model:
            logger.error("âŒ æ‰€æœ‰ Gemini 2.0 æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œå¯èƒ½éœ€è¦æª¢æŸ¥ API æ¬Šé™")
            
    except Exception as e:
        logger.error(f"âŒ Gemini AI åˆå§‹åŒ–å¤±æ•—: {e}")
else:
    logger.warning("âš ï¸ Gemini API key not found")

def get_ai_response(query, student_id=None):
    """å–å¾— AI å›æ‡‰"""
    try:
        if not model:
            logger.error("âŒ AI æ¨¡å‹æœªåˆå§‹åŒ–")
            return "æŠ±æ­‰ï¼ŒAI æœå‹™ç›®å‰ç„¡æ³•ä½¿ç”¨ã€‚è«‹æª¢æŸ¥ç³»çµ±è¨­å®šã€‚"
        
        if not query or len(query.strip()) == 0:
            return "è«‹æä¾›æ‚¨çš„å•é¡Œï¼Œæˆ‘å¾ˆæ¨‚æ„ç‚ºæ‚¨è§£ç­”ï¼"
        
        # å–å¾—å­¸ç”Ÿè³‡è¨Š
        student_context = ""
        if student_id:
            try:
                student = Student.get_by_id(student_id)
                student_context = f"ï¼ˆå­¸ç”Ÿï¼š{student.name}ï¼Œåƒèˆ‡åº¦ï¼š{student.participation_rate}%ï¼‰"
            except Exception as e:
                logger.warning(f"ç„¡æ³•å–å¾—å­¸ç”Ÿè³‡è¨Š: {e}")
        
        # ç‚º Gemini 2.0 å„ªåŒ–çš„æç¤ºè©
        prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„é›™èªæ•™å­¸ AI åŠ©ç†ï¼Œå°ˆé–€å”åŠ© EMI èª²ç¨‹å­¸ç¿’ã€‚

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å­¸ç”Ÿå•é¡Œï¼Œä¿æŒå‹å–„ã€å°ˆæ¥­ä¸”å…·æœ‰æ•™è‚²åƒ¹å€¼ã€‚
{student_context}

å­¸ç”Ÿå•é¡Œï¼š{query}

è«‹æä¾›æ¸…æ™°ã€æœ‰å¹«åŠ©çš„å›ç­”ï¼ˆå»ºè­° 100-150 å­—ï¼‰ï¼š"""
        
        logger.info(f"ğŸ¤– ä½¿ç”¨ {current_model_name} ç”Ÿæˆå›æ‡‰...")
        
        # Gemini 2.0 optimized generation config
        generation_config = genai.types.GenerationConfig(
            candidate_count=1,
            max_output_tokens=300,
            temperature=0.7,
            top_p=0.9,
            top_k=40
        )
        
        response = model.generate_content(
            prompt,
            generation_config=generation_config
        )
        
        if response and response.text:
            ai_response = response.text.strip()
            logger.info(f"âœ… AI å›æ‡‰æˆåŠŸç”Ÿæˆï¼Œé•·åº¦: {len(ai_response)} å­—")
            return ai_response
        else:
            logger.error("âŒ AI å›æ‡‰ç‚ºç©º")
            return "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•ç”Ÿæˆé©ç•¶çš„å›æ‡‰ã€‚è«‹ç¨å¾Œå†è©¦æˆ–é‡æ–°è¡¨é”æ‚¨çš„å•é¡Œã€‚"
            
    except Exception as e:
        error_msg = str(e).lower()
        logger.error(f"âŒ AI å›æ‡‰éŒ¯èª¤: {str(e)}")
        
        # è©³ç´°çš„éŒ¯èª¤è™•ç†
        if "404" in error_msg or "not found" in error_msg:
            return "AI æ¨¡å‹æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚æ‚¨çš„å°ˆæ¡ˆå¯èƒ½ç„¡æ³•å­˜å– Gemini 1.5 æ¨¡å‹ï¼Œç³»çµ±æ­£å˜—è©¦ä½¿ç”¨ Gemini 2.0ã€‚"
        elif "quota" in error_msg or "limit" in error_msg or "exceeded" in error_msg:
            return "AI æœå‹™ä½¿ç”¨é‡å·²é”ä¸Šé™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        elif "permission" in error_msg or "denied" in error_msg:
            return "AI æœå‹™æ¬Šé™ä¸è¶³ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°è¨­å®šã€‚"
        elif "unavailable" in error_msg or "not available" in error_msg:
            return "æ‚¨çš„ Google Cloud å°ˆæ¡ˆå¯èƒ½ç„¡æ³•ä½¿ç”¨è¼ƒæ–°çš„ Gemini æ¨¡å‹ã€‚å»ºè­°è¯çµ¡ç®¡ç†å“¡æˆ–å‡ç´šå°ˆæ¡ˆã€‚"
        elif "safety" in error_msg:
            return "ç‚ºäº†å®‰å…¨è€ƒé‡ï¼ŒAI ç„¡æ³•å›æ‡‰æ­¤å•é¡Œã€‚è«‹å˜—è©¦é‡æ–°è¡¨é”æ‚¨çš„å•é¡Œã€‚"
        else:
            return f"è™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"

def analyze_student_patterns(student_id):
    """åˆ†æå­¸ç”Ÿå­¸ç¿’æ¨¡å¼"""
    try:
        if not model:
            logger.warning("âš ï¸ AI æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
            return None
            
        student = Student.get_by_id(student_id)
        
        # å–å¾—æœ€è¿‘è¨Šæ¯
        recent_messages = list(Message.select().where(
            Message.student == student
        ).order_by(Message.timestamp.desc()).limit(8))
        
        if len(recent_messages) < 3:
            return "è©²å­¸ç”Ÿäº’å‹•è¨˜éŒ„ä¸è¶³ï¼ˆå°‘æ–¼3å‰‡ï¼‰ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆåˆ†æã€‚"
        
        # æº–å‚™åˆ†æè³‡æ–™
        messages_text = [msg.content[:80] for msg in recent_messages]
        questions = [msg.content[:80] for msg in recent_messages if msg.message_type == 'question']
        
        # ç‚º Gemini 2.0 å„ªåŒ–çš„åˆ†ææç¤º
        analysis_prompt = f"""ä½œç‚ºæ•™è‚²å°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹å­¸ç”Ÿçš„å­¸ç¿’æ¨¡å¼ï¼š

å­¸ç”ŸåŸºæœ¬è³‡æ–™ï¼š
- å§“åï¼š{student.name}
- ç¸½ç™¼è¨€ï¼š{student.message_count} æ¬¡
- æå•æ•¸ï¼š{student.question_count} æ¬¡
- åƒèˆ‡åº¦ï¼š{student.participation_rate}%

è¿‘æœŸäº’å‹•å…§å®¹ï¼š
{chr(10).join(f"â€¢ {msg}" for msg in messages_text)}

ä¸»è¦æå•ï¼š
{chr(10).join(f"â€¢ {q}" for q in questions) if questions else "â€¢ å°šç„¡æå•è¨˜éŒ„"}

è«‹ç”¨ 120-150 å­—åˆ†æè©²å­¸ç”Ÿçš„ï¼š
1. å­¸ç¿’é¢¨æ ¼ç‰¹é»
2. åƒèˆ‡ç¨‹åº¦è©•ä¼°  
3. å…·é«”å­¸ç¿’å»ºè­°

åˆ†æå ±å‘Šï¼š"""
        
        generation_config = genai.types.GenerationConfig(
            candidate_count=1,
            max_output_tokens=250,
            temperature=0.6,
        )
        
        response = model.generate_content(
            analysis_prompt,
            generation_config=generation_config
        )
        
        if response and response.text:
            logger.info(f"âœ… å­¸ç”Ÿå­¸ç¿’æ¨¡å¼åˆ†æå®Œæˆ: {student.name}")
            return response.text.strip()
        else:
            logger.error("âŒ å­¸ç¿’æ¨¡å¼åˆ†æå›æ‡‰ç‚ºç©º")
            return "AI åˆ†ææœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            
    except Exception as e:
        logger.error(f"âŒ å­¸ç”Ÿæ¨¡å¼åˆ†æéŒ¯èª¤: {e}")
        return f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)[:50]}..."

def test_ai_connection():
    """æ¸¬è©¦ AI é€£æ¥"""
    try:
        if not model:
            return False, "AI æ¨¡å‹æœªåˆå§‹åŒ–"
        
        # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
        test_response = model.generate_content("è«‹ç°¡å–®å›ç­”ï¼šä½ å¥½")
        
        if test_response and test_response.text:
            return True, f"é€£æ¥æ­£å¸¸ï¼Œä½¿ç”¨æ¨¡å‹ï¼š{current_model_name}"
        else:
            return False, "AI å›æ‡‰ç‚ºç©º"
            
    except Exception as e:
        return False, f"é€£æ¥éŒ¯èª¤ï¼š{str(e)[:60]}..."

def list_available_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    try:
        if not GEMINI_API_KEY:
            return ["ç„¡ API é‡‘é‘°"]
        
        genai.configure(api_key=GEMINI_API_KEY)
        models = []
        
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    models.append(m.name)
        except Exception as e:
            logger.warning(f"ç„¡æ³•å‹•æ…‹åˆ—å‡ºæ¨¡å‹: {e}")
            # æ ¹æ“šå®˜æ–¹æ–‡ä»¶è¿”å›å·²çŸ¥å¯ç”¨æ¨¡å‹
            models = [
                'models/gemini-2.0-flash-001',
                'models/gemini-2.0-flash-lite-001',
                'models/gemini-2.0-flash',
                'models/gemini-2.0-flash-lite'
            ]
            
        return models
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ¨¡å‹æ™‚éŒ¯èª¤: {e}")
        return [f"éŒ¯èª¤ï¼š{str(e)[:50]}"]

def get_model_info():
    """å–å¾—ç•¶å‰æ¨¡å‹è³‡è¨Š"""
    if not model:
        return "æœªåˆå§‹åŒ–"
    
    return current_model_name or "æœªçŸ¥æ¨¡å‹"

def update_student_stats(student_id):
    """æ›´æ–°å­¸ç”Ÿçµ±è¨ˆè³‡æ–™"""
    try:
        student = Student.get_by_id(student_id)
        student.update_stats()
        logger.info(f"âœ… æ›´æ–°å­¸ç”Ÿçµ±è¨ˆ: {student.name}")
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°çµ±è¨ˆéŒ¯èª¤: {e}")

def create_sample_data():
    """å»ºç«‹ç¯„ä¾‹è³‡æ–™"""
    try:
        sample_students = [
            {
                'name': '[DEMO] ç‹å°æ˜',
                'line_user_id': 'demo_student_001',
                'message_count': 25,
                'question_count': 8,
                'participation_rate': 75.5,
                'question_rate': 32.0,
                'learning_style': 'ä¸»å‹•æ¢ç´¢å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            },
            {
                'name': '[DEMO] æç¾è¯',
                'line_user_id': 'demo_student_002', 
                'message_count': 18,
                'question_count': 12,
                'participation_rate': 68.2,
                'question_rate': 66.7,
                'learning_style': 'å•é¡Œå°å‘å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            },
            {
                'name': '[DEMO] John Smith',
                'line_user_id': 'demo_student_003',
                'message_count': 32,
                'question_count': 5,
                'participation_rate': 82.3,
                'question_rate': 15.6,
                'learning_style': 'å¯¦ä½œå°å‘å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            }
        ]
        
        for student_data in sample_students:
            try:
                existing = Student.select().where(
                    Student.line_user_id == student_data['line_user_id']
                ).first()
                
                if not existing:
                    student = Student.create(**{
                        **student_data,
                        'created_at': datetime.datetime.now() - datetime.timedelta(days=random.randint(1, 30)),
                        'last_active': datetime.datetime.now() - datetime.timedelta(hours=random.randint(1, 48))
                    })
                    
                    create_sample_messages(student)
                    logger.info(f"âœ… å»ºç«‹æ¼”ç¤ºå­¸ç”Ÿ: {student.name}")
                    
            except Exception as e:
                logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºå­¸ç”ŸéŒ¯èª¤: {e}")
                
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºè³‡æ–™éŒ¯èª¤: {e}")

def create_sample_messages(student):
    """å»ºç«‹æ¼”ç¤ºè¨Šæ¯"""
    try:
        sample_messages = [
            {'content': 'è€å¸«å¥½ï¼Œè«‹å•ä»Šå¤©çš„ä½œæ¥­è¦æ€éº¼åšï¼Ÿ', 'type': 'question'},
            {'content': 'æˆ‘è¦ºå¾—é€™å€‹æ¦‚å¿µå¾ˆæœ‰è¶£ï¼', 'type': 'statement'},
            {'content': 'å¯ä»¥å†è§£é‡‹ä¸€ä¸‹ machine learning å—ï¼Ÿ', 'type': 'question'},
            {'content': 'è¬è¬è€å¸«çš„èªªæ˜ï¼Œæˆ‘æ˜ç™½äº†', 'type': 'statement'},
            {'content': 'What is the difference between AI and ML?', 'type': 'question'},
            {'content': 'é€™å€‹ä¾‹å­å¾ˆæ¸…æ¥šï¼', 'type': 'statement'},
            {'content': 'è«‹å•æœ‰æ¨è–¦çš„åƒè€ƒæ›¸ç±å—ï¼Ÿ', 'type': 'question'},
        ]
        
        messages_to_create = min(len(sample_messages), student.message_count)
        
        for i in range(messages_to_create):
            msg_data = sample_messages[i % len(sample_messages)]
            Message.create(
                student=student,
                content=msg_data['content'],
                message_type=msg_data['type'],
                timestamp=datetime.datetime.now() - datetime.timedelta(hours=random.randint(1, 72)),
                source_type='demo'
            )
                
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºè¨Šæ¯éŒ¯èª¤: {e}")

def validate_environment():
    """é©—è­‰ç’°å¢ƒè®Šæ•¸"""
    required_vars = ['GEMINI_API_KEY', 'CHANNEL_ACCESS_TOKEN', 'CHANNEL_SECRET']
    missing_vars = []
    
    for var in required_vars:
        value = os.getenv(var) or os.getenv(f'LINE_{var}')
        if not value:
            missing_vars.append(var)
    
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘ç’°å¢ƒè®Šæ•¸: {', '.join(missing_vars)}")
        return False
    
    logger.info("âœ… ç’°å¢ƒè®Šæ•¸é©—è­‰é€šé")
    return True

def get_system_status():
    """å–å¾—ç³»çµ±ç‹€æ…‹"""
    try:
        ai_ok, ai_msg = test_ai_connection()
        available_models = list_available_models()
        
        status = {
            'database': 'connected' if not db.is_closed() else 'disconnected',
            'ai_service': 'available' if ai_ok else 'error',
            'ai_message': ai_msg,
            'current_model': get_model_info(),
            'available_models': available_models[:8],
            'total_students': Student.select().count(),
            'real_students': Student.select().where(~Student.name.startswith('[DEMO]')).count(),
            'demo_students': Student.select().where(Student.name.startswith('[DEMO]')).count(),
            'total_messages': Message.select().count(),
            'model_info': f'ä½¿ç”¨ Gemini 2.0 ç³»åˆ—æ¨¡å‹ï¼ˆæ¨è–¦ç”¨æ–¼æ–°å°ˆæ¡ˆï¼‰',
            'last_update': datetime.datetime.now().isoformat()
        }
        
        return status
        
    except Exception as e:
        logger.error(f"âŒ å–å¾—ç³»çµ±ç‹€æ…‹éŒ¯èª¤: {e}")
        return {'error': str(e)}

def initialize_utils():
    """åˆå§‹åŒ–å·¥å…·æ¨¡çµ„"""
    logger.info("ğŸ”§ åˆå§‹åŒ– utils æ¨¡çµ„...")
    
    env_ok = validate_environment()
    if not env_ok:
        logger.warning("âš ï¸ ç’°å¢ƒè®Šæ•¸æª¢æŸ¥æœªé€šé")
    
    ai_ok, ai_msg = test_ai_connection()
    logger.info(f"ğŸ¤– AI ç‹€æ…‹: {ai_msg}")
    
    models = list_available_models()
    if models:
        logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {', '.join(models[:3])}...")
    
    logger.info(f"ğŸš€ ç•¶å‰ä½¿ç”¨æ¨¡å‹: {get_model_info()}")
    logger.info("âœ… Utils æ¨¡çµ„åˆå§‹åŒ–å®Œæˆ")

# è‡ªå‹•åŸ·è¡Œåˆå§‹åŒ–
initialize_utils()
