# utils.py - ä¿®å¾©ç‰ˆæœ¬ï¼ˆè§£æ±ºç¬¬ 595 è¡Œ f-string åæ–œç·šéŒ¯èª¤ï¼‰

import os
import logging
import json
import datetime
import time
from typing import Dict, List, Optional, Tuple, Any
from collections import Counter
import google.generativeai as genai
from models import Student, Message, Analysis, AIResponse, db

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)

# =================== AI æ¨¡å‹é…ç½® ===================

# å–å¾— API é‡‘é‘°
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# åˆå§‹åŒ– Gemini
model = None
current_model_name = "gemini-1.5-flash"
model_rotation_index = 0

# å»ºè­°çš„æ¨¡å‹å„ªå…ˆé †åºé…ç½®
# åŸºæ–¼é…é¡ã€æ€§èƒ½å’Œç‰ˆæœ¬æ–°èˆŠç¨‹åº¦

AVAILABLE_MODELS = [
    "gemini-2.0-flash",        # ğŸ¥‡ æœ€å„ªå…ˆï¼šæœ€æ–°ç‰ˆæœ¬ + é«˜é…é¡(200æ¬¡/æ—¥)
    "gemini-2.0-flash-lite",   # ğŸ¥ˆ ç¬¬äºŒï¼šè¼•é‡ç‰ˆ + é«˜é…é¡(200æ¬¡/æ—¥)  
    "gemini-1.5-flash",        # ğŸ¥‰ ç¬¬ä¸‰ï¼šæˆç†Ÿç©©å®š + ä¸­é…é¡(50æ¬¡/æ—¥)
    "gemini-1.5-flash-8b",     # ğŸ… ç¬¬å››ï¼šæ•ˆç‡å„ªåŒ– + ä¸­é…é¡(50æ¬¡/æ—¥)
    "gemini-1.5-pro",          # ğŸ… ç¬¬äº”ï¼šåŠŸèƒ½å®Œæ•´ä½†è¼ƒæ…¢
    "gemini-1.0-pro",          # ğŸ… æœ€å¾Œå‚™ç”¨ï¼šèˆŠç‰ˆæœ¬ä½†ç©©å®š
]

# èª¿æ•´ç†ç”±ï¼š
# 1. 2.0 ç‰ˆæœ¬å„ªå…ˆï¼ˆé…é¡æ›´é«˜ï¼Œæ€§èƒ½æ›´å¥½ï¼‰
# 2. 1.5-flash-8b æ¯” 1.0-pro å„ªå…ˆï¼ˆç‰ˆæœ¬æ›´æ–° + é€Ÿåº¦æ›´å¿«ï¼‰
# 3. ä¿æŒå‘ä¸‹å…¼å®¹çš„å‚™ç”¨æ–¹æ¡ˆ

# æ¨¡å‹ä½¿ç”¨çµ±è¨ˆ
model_usage_stats = {model: {'calls': 0, 'errors': 0, 'last_used': None} for model in AVAILABLE_MODELS}

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel(current_model_name)
        logger.info(f"âœ… Gemini AI åˆå§‹åŒ–æˆåŠŸ - ä½¿ç”¨æ¨¡å‹: {current_model_name}")
    except Exception as e:
        logger.error(f"âŒ Gemini AI åˆå§‹åŒ–å¤±æ•—: {e}")
        model = None
else:
    logger.warning("âš ï¸ GEMINI_API_KEY æœªè¨­å®š")

# =================== æ¨¡å‹ç®¡ç†åŠŸèƒ½ ===================

def record_model_usage(model_name: str, success: bool = True):
    """è¨˜éŒ„æ¨¡å‹ä½¿ç”¨çµ±è¨ˆ"""
    if model_name in model_usage_stats:
        model_usage_stats[model_name]['calls'] += 1
        model_usage_stats[model_name]['last_used'] = time.time()
        if not success:
            model_usage_stats[model_name]['errors'] += 1

def get_next_available_model() -> str:
    """å–å¾—ä¸‹ä¸€å€‹å¯ç”¨æ¨¡å‹"""
    global model_rotation_index
    
    # ç°¡å–®çš„å¾ªç’°é¸æ“‡
    model_rotation_index = (model_rotation_index + 1) % len(AVAILABLE_MODELS)
    return AVAILABLE_MODELS[model_rotation_index]

def switch_to_available_model() -> bool:
    """åˆ‡æ›åˆ°å¯ç”¨æ¨¡å‹"""
    global model, current_model_name
    
    if not GEMINI_API_KEY:
        return False
    
    # å˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹æ¨¡å‹
    new_model_name = get_next_available_model()
    
    try:
        new_model = genai.GenerativeModel(new_model_name)
        model = new_model
        current_model_name = new_model_name
        logger.info(f"âœ… æˆåŠŸåˆ‡æ›åˆ°æ¨¡å‹: {current_model_name}")
        return True
    except Exception as e:
        logger.error(f"âŒ åˆ‡æ›æ¨¡å‹å¤±æ•—: {e}")
        return False

def get_quota_status() -> Dict:
    """å–å¾—é…é¡ç‹€æ…‹"""
    status = {
        'current_model': current_model_name,
        'models': {},
        'recommendations': []
    }
    
    # æ¨¡æ“¬é…é¡æª¢æŸ¥ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦çœŸå¯¦çš„é…é¡æª¢æŸ¥ï¼‰
    for model_name in AVAILABLE_MODELS:
        stats = model_usage_stats[model_name]
        error_rate = (stats['errors'] / max(stats['calls'], 1)) * 100
        
        # åŸºæ–¼éŒ¯èª¤ç‡ä¼°ç®—å¯ç”¨æ€§
        if error_rate > 50:
            usage_percent = 100  # å¯èƒ½é…é¡å·²ç”¨å®Œ
        elif error_rate > 20:
            usage_percent = 80
        else:
            usage_percent = min(50, stats['calls'] * 2)  # åŸºæ–¼ä½¿ç”¨æ¬¡æ•¸ä¼°ç®—
        
        status['models'][model_name] = {
            'usage_percent': usage_percent,
            'calls': stats['calls'],
            'errors': stats['errors'],
            'status': 'å¯ç”¨' if usage_percent < 100 else 'å·²ç”¨å®Œ'
        }
    
    # ç”Ÿæˆå»ºè­°
    available_models = [name for name, info in status['models'].items() if info['usage_percent'] < 100]
    if not available_models:
        status['recommendations'].append("æ‰€æœ‰æ¨¡å‹é…é¡å·²ç”¨å®Œï¼Œå»ºè­°ç­‰å¾…é‡ç½®æˆ–å‡ç´šæ–¹æ¡ˆ")
    elif len(available_models) == 1:
        status['recommendations'].append(f"åƒ…å‰© {available_models[0]} å¯ç”¨ï¼Œå»ºè­°ç¯€ç´„ä½¿ç”¨")
    
    return status

def test_ai_connection():
    """æ¸¬è©¦ AI é€£æ¥"""
    try:
        if not model:
            return False, "AI æ¨¡å‹æœªåˆå§‹åŒ–"
        
        quota_status = get_quota_status()
        available_models = [name for name, info in quota_status['models'].items() if info['usage_percent'] < 100]
        
        if not available_models:
            return False, "æ‰€æœ‰æ¨¡å‹é…é¡å·²ç”¨å®Œ"
        
        return True, f"é€£æ¥æ­£å¸¸ - ç•¶å‰: {current_model_name}, å¯ç”¨æ¨¡å‹: {len(available_models)}"
        
    except Exception as e:
        return False, f"é€£æ¥éŒ¯èª¤: {str(e)[:60]}..."

# =================== AI å›æ‡‰ç”Ÿæˆ ===================

def generate_ai_response_with_smart_fallback(student_id, query, conversation_context="", student_context="", group_id=None):
    """æ™ºæ…§å›æ‡‰ç”Ÿæˆ - åŒ…å«æ¨¡å‹åˆ‡æ›å’ŒéŒ¯èª¤è™•ç†"""
    try:
        if not GEMINI_API_KEY:
            logger.error("âŒ GEMINI_API_KEY æœªè¨­å®š")
            return "Hello! I'm currently being configured. Please check back soon. ğŸ‘‹"
        
        if not model:
            logger.error("âŒ Gemini æ¨¡å‹æœªåˆå§‹åŒ–")
            return "I'm having trouble connecting to my AI brain right now. Please try again in a moment. ğŸ¤–"
        
        # æª¢æŸ¥ä¸¦è™•ç†é…é¡é™åˆ¶
        quota_status = get_quota_status()
        available_models = [name for name, info in quota_status['models'].items() if info['usage_percent'] < 100]
        
        if not available_models:
            logger.warning("âš ï¸ æ‰€æœ‰æ¨¡å‹é…é¡å·²ç”¨å®Œ")
            return "AI service quota exceeded. Please try again later when quota resets (typically at midnight UTC). Please try again later or contact administrator to upgrade the service plan."
        
        # æ§‹å»ºæç¤ºè© - ä¿®å¾© f-string åæ–œç·šå•é¡Œ
        student = Student.get_by_id(student_id) if student_id else None
        
        # ä¿®å¾©ï¼šä½¿ç”¨ chr(10) æ›¿ä»£ \n ä¾†é¿å… f-string ä¸­çš„åæ–œç·š
        newline = chr(10)
        
        # æ§‹å»ºå‰ç½®å°è©±å…§å®¹
        conversation_prefix = f"Previous conversation context:{newline}{conversation_context}{newline}" if conversation_context else ""
        
        prompt = f"""You are an AI Teaching Assistant for English-medium instruction (EMI) courses.

{conversation_prefix}

Instructions:
- Respond primarily in clear, simple English suitable for university-level ESL learners
- Use vocabulary appropriate for intermediate English learners
- For technical terms, provide Chinese translation in parentheses when helpful
- Maintain a friendly, encouraging, and educational tone
- Keep responses concise but helpful (50-150 words)
- If this continues a previous conversation, build on what was discussed before

{student_context if student_context else ""}

Student question: {query}

Please provide a helpful response:"""
        
        logger.info(f"ğŸ¤– ä½¿ç”¨ {current_model_name} ç”Ÿæˆå›æ‡‰...")
        
        # æ ¹æ“šæ¨¡å‹èª¿æ•´é…ç½®
        if 'lite' in current_model_name or '8b' in current_model_name:
            # è¼•é‡æ¨¡å‹ä½¿ç”¨è¼ƒä¿å®ˆçš„è¨­å®š
            generation_config = genai.types.GenerationConfig(
                candidate_count=1,
                max_output_tokens=300,
                temperature=0.6,
                top_p=0.8,
                top_k=30
            )
        else:
            # æ¨™æº–æ¨¡å‹è¨­å®š
            generation_config = genai.types.GenerationConfig(
                candidate_count=1,
                max_output_tokens=350,
                temperature=0.7,
                top_p=0.9,
                top_k=40
            )
        
        response = model.generate_content(prompt, generation_config=generation_config)
        
        if response and response.text:
            # è¨˜éŒ„æˆåŠŸä½¿ç”¨
            record_model_usage(current_model_name, True)
            
            ai_response = response.text.strip()
            logger.info(f"âœ… AI å›æ‡‰æˆåŠŸç”Ÿæˆï¼Œé•·åº¦: {len(ai_response)} å­—")
            
            # åŸºæœ¬å…§å®¹æª¢æŸ¥
            if len(ai_response) < 10:
                logger.warning("âš ï¸ AI å›æ‡‰éçŸ­ï¼Œä½¿ç”¨å‚™ç”¨å›æ‡‰")
                return get_fallback_response(query)
            
            return ai_response
        else:
            logger.error("âŒ AI å›æ‡‰ç‚ºç©º")
            record_model_usage(current_model_name, False)
            return get_fallback_response(query)
            
    except Exception as e:
        error_msg = str(e).lower()
        logger.error(f"âŒ AI å›æ‡‰éŒ¯èª¤: {str(e)}")
        record_model_usage(current_model_name, False)
        
        # æ™ºæ…§éŒ¯èª¤è™•ç†
        if "429" in error_msg or "quota" in error_msg or "limit" in error_msg:
            # é…é¡å•é¡Œï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹
            logger.warning("ğŸ”„ åµæ¸¬åˆ°é…é¡å•é¡Œï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹...")
            success = switch_to_available_model()
            if success:
                logger.info(f"âœ… å·²åˆ‡æ›åˆ° {current_model_name}ï¼Œé‡æ–°å˜—è©¦...")
                # éè¿´é‡è©¦ä¸€æ¬¡
                return generate_ai_response_with_smart_fallback(student_id, query, conversation_context, student_context, group_id)
            else:
                return "AI service quota exceeded. Please try again later when quota resets (typically at midnight UTC)."
        elif "403" in error_msg or "unauthorized" in error_msg:
            return "I'm having authentication issues. Please contact your teacher to check the system configuration. ğŸ”§"
        elif "network" in error_msg or "connection" in error_msg:
            return "I'm having connection problems. Please try again in a moment. ğŸ“¡"
        else:
            return get_fallback_response(query)

def get_fallback_response(user_message):
    """å‚™ç”¨å›æ‡‰ç”Ÿæˆå™¨"""
    user_msg_lower = user_message.lower()
    
    # åŸºæ–¼é—œéµè©çš„ç°¡å–®å›æ‡‰
    if any(word in user_msg_lower for word in ['hello', 'hi', 'hey']):
        return "Hello! I'm your English learning assistant. How can I help you today? ğŸ‘‹"
    
    elif any(word in user_msg_lower for word in ['grammar', 'grammer']):
        return "I'd love to help with grammar! Can you share the specific sentence or rule you're wondering about? ğŸ“"
    
    elif any(word in user_msg_lower for word in ['vocabulary', 'word', 'meaning']):
        return "I'm here to help with vocabulary! What word would you like to learn about? ğŸ“š"
    
    elif any(word in user_msg_lower for word in ['pronunciation', 'pronounce', 'speak']):
        return "Pronunciation is important! While I can't hear you speak, I can help explain how words are pronounced. What word are you working on? ğŸ—£ï¸"
    
    elif '?' in user_message:
        return "That's a great question! I'm having some technical difficulties right now, but I'm working to get back to full functionality. Can you try asking again in a moment? ğŸ¤”"
    
    else:
        return "I received your message! I'm currently having some technical issues, but I'm here to help with your English learning. Please try again in a moment. ğŸ“š"

# å…¼å®¹æ€§ï¼šä¿æŒåŸæœ‰å‡½æ•¸åç¨±
def generate_ai_response(student_id, query, conversation_context="", student_context="", group_id=None):
    """åŸæœ‰å‡½æ•¸çš„å…¼å®¹æ€§åŒ…è£"""
    return generate_ai_response_with_smart_fallback(student_id, query, conversation_context, student_context, group_id)

# =================== å­¸ç”Ÿåˆ†æåŠŸèƒ½ ===================

def analyze_student_patterns(student_id):
    """åˆ†æå­¸ç”Ÿå­¸ç¿’æ¨¡å¼"""
    try:
        student = Student.get_by_id(student_id)
        messages = list(Message.select().where(Message.student_id == student_id))
        
        # åˆ†æè¨Šæ¯é¡å‹åˆ†å¸ƒ
        message_types = {}
        for msg in messages:
            msg_type = msg.message_type or 'general'
            message_types[msg_type] = message_types.get(msg_type, 0) + 1
        
        # åˆ†ææ´»å‹•æ™‚é–“æ¨¡å¼
        if messages:
            timestamps = [msg.timestamp for msg in messages if msg.timestamp]
            if timestamps:
                earliest = min(timestamps)
                latest = max(timestamps)
                active_days = (latest - earliest).days + 1
            else:
                active_days = 0
        else:
            active_days = 0
        
        # è¨ˆç®—å¹³å‡è¨Šæ¯é•·åº¦
        if messages:
            avg_length = sum(len(msg.content) for msg in messages) / len(messages)
        else:
            avg_length = 0
        
        # åˆ†æåƒèˆ‡åº¦
        total_messages = len(messages)
        if total_messages >= 20:
            engagement_level = "é«˜åº¦åƒèˆ‡"
        elif total_messages >= 10:
            engagement_level = "ä¸­åº¦åƒèˆ‡"
        elif total_messages >= 5:
            engagement_level = "è¼•åº¦åƒèˆ‡"
        else:
            engagement_level = "æ¥µå°‘åƒèˆ‡"
        
        return {
            'student_id': student_id,
            'student_name': student.name,
            'total_messages': total_messages,
            'message_types': message_types,
            'active_days': active_days,
            'avg_message_length': round(avg_length, 2),
            'engagement_level': engagement_level,
            'analysis_date': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"å­¸ç”Ÿæ¨¡å¼åˆ†æéŒ¯èª¤: {e}")
        return {
            'student_id': student_id,
            'error': str(e),
            'analysis_date': datetime.datetime.now().isoformat()
        }

def update_student_stats(student_id):
    """æ›´æ–°å­¸ç”Ÿçµ±è¨ˆè³‡æ–™"""
    try:
        student = Student.get_by_id(student_id)
        
        # è¨ˆç®—è¨Šæ¯çµ±è¨ˆ
        messages = list(Message.select().where(Message.student_id == student_id))
        total_messages = len(messages)
        
        # è¨ˆç®—åƒèˆ‡ç‡ï¼ˆåŸºæ–¼è¨Šæ¯æ•¸é‡ï¼‰
        if total_messages >= 50:
            participation_rate = 95
        elif total_messages >= 20:
            participation_rate = 80
        elif total_messages >= 10:
            participation_rate = 60
        elif total_messages >= 5:
            participation_rate = 40
        else:
            participation_rate = 20
        
        # æ›´æ–°å­¸ç”Ÿè¨˜éŒ„
        student.total_messages = total_messages
        student.participation_rate = participation_rate
        student.last_active = datetime.datetime.now()
        student.save()
        
        logger.info(f"âœ… å­¸ç”Ÿçµ±è¨ˆå·²æ›´æ–° - {student.name}: {total_messages} è¨Šæ¯, åƒèˆ‡ç‡ {participation_rate}%")
        
    except Exception as e:
        logger.error(f"æ›´æ–°å­¸ç”Ÿçµ±è¨ˆéŒ¯èª¤: {e}")

def get_question_category_stats():
    """å–å¾—å•é¡Œåˆ†é¡çµ±è¨ˆ"""
    try:
        # å–å¾—æ‰€æœ‰åˆ†æè¨˜éŒ„
        analyses = list(Analysis.select().where(
            Analysis.analysis_type == 'question_classification'
        ))
        
        category_stats = {
            'total_questions': len(analyses),
            'categories': Counter(),
            'cognitive_levels': Counter(),
            'content_domains': Counter()
        }
        
        for analysis in analyses:
            try:
                data = json.loads(analysis.analysis_data)
                category_stats['categories'][data.get('category', 'Unknown')] += 1
                category_stats['cognitive_levels'][data.get('cognitive_level', 'Unknown')] += 1
                category_stats['content_domains'][data.get('content_domain', 'Unknown')] += 1
            except json.JSONDecodeError:
                continue
        
        # è½‰æ› Counter ç‚ºå­—å…¸
        for key in ['categories', 'cognitive_levels', 'content_domains']:
            category_stats[key] = dict(category_stats[key])
        
        return category_stats
        
    except Exception as e:
        logger.error(f"å•é¡Œåˆ†é¡çµ±è¨ˆéŒ¯èª¤: {e}")
        return {
            'total_questions': 0,
            'categories': {},
            'cognitive_levels': {},
            'content_domains': {},
            'error': str(e)
        }

def get_student_conversation_summary(student_id, days=30):
    """å–å¾—å­¸ç”Ÿå°è©±æ‘˜è¦"""
    try:
        student = Student.get_by_id(student_id)
        
        # å–å¾—æŒ‡å®šå¤©æ•¸å…§çš„è¨Šæ¯
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)
        messages = list(Message.select().where(
            (Message.student_id == student_id) &
            (Message.timestamp >= cutoff_date)
        ).order_by(Message.timestamp.desc()))
        
        if not messages:
            return {
                'student_id': student_id,
                'student_name': student.name,
                'period_days': days,
                'message_count': 0,
                'summary': 'åœ¨æ­¤æœŸé–“æ²’æœ‰å°è©±è¨˜éŒ„',
                'status': 'no_data'
            }
        
        # åˆ†æè¨Šæ¯é¡å‹
        questions = [msg for msg in messages if msg.message_type == 'question']
        statements = [msg for msg in messages if msg.message_type == 'statement']
        
        # ç”¢ç”Ÿç°¡å–®æ‘˜è¦
        summary_parts = []
        summary_parts.append(f"åœ¨æœ€è¿‘ {days} å¤©å…§ï¼Œ{student.name} å…±ç™¼é€äº† {len(messages)} å‰‡è¨Šæ¯")
        
        if questions:
            summary_parts.append(f"å…¶ä¸­åŒ…å« {len(questions)} å€‹å•é¡Œ")
        
        if statements:
            summary_parts.append(f"ä»¥åŠ {len(statements)} å€‹é™³è¿°")
        
        # è¨ˆç®—æ´»èºåº¦
        if len(messages) >= 10:
            activity_level = "é«˜åº¦æ´»èº"
        elif len(messages) >= 5:
            activity_level = "é©åº¦æ´»èº"
        else:
            activity_level = "è¼ƒå°‘åƒèˆ‡"
        
        summary_parts.append(f"æ•´é«”åƒèˆ‡åº¦ç‚ºï¼š{activity_level}")
        
        return {
            'student_id': student_id,
            'student_name': student.name,
            'period_days': days,
            'message_count': len(messages),
            'question_count': len(questions),
            'statement_count': len(statements),
            'activity_level': activity_level,
            'summary': 'ã€‚'.join(summary_parts) + 'ã€‚',
            'generated_at': datetime.datetime.now().isoformat(),
            'status': 'success'
        }
        
    except Exception as e:
        logger.error(f"å°è©±æ‘˜è¦éŒ¯èª¤: {e}")
        return {
            'student_id': student_id,
            'error': str(e),
            'status': 'error'
        }

# =================== ç›¸å®¹æ€§å‡½æ•¸ ===================

# ä¸»è¦ AI å›æ‡‰å‡½æ•¸åˆ¥å
get_ai_response = generate_ai_response_with_smart_fallback

# å­¸ç”Ÿåˆ†æå‡½æ•¸åˆ¥å
analyze_student_pattern = analyze_student_patterns

# =================== åŒ¯å‡ºå‡½æ•¸åˆ—è¡¨ ===================

__all__ = [
    # AI å›æ‡‰ç”Ÿæˆ
    'generate_ai_response_with_smart_fallback',
    'generate_ai_response',
    'get_ai_response',
    'get_fallback_response',
    
    # æ¨¡å‹ç®¡ç†
    'switch_to_available_model',
    'get_quota_status',
    'test_ai_connection',
    'record_model_usage',
    
    # å­¸ç”Ÿåˆ†æ
    'analyze_student_patterns',
    'analyze_student_pattern',
    'update_student_stats',
    'get_question_category_stats',
    'get_student_conversation_summary',
    
    # å¸¸æ•¸
    'AVAILABLE_MODELS',
    'current_model_name'
]
