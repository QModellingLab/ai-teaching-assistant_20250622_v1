import os
import json
import datetime
import logging
import random
import google.generativeai as genai
from models import Student, Message, Analysis, db

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)

# åˆå§‹åŒ– Gemini AI - ä½¿ç”¨æœ€æ–°å¯ç”¨æ¨¡å‹
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
model = None

if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # å˜—è©¦ä½¿ç”¨æœ€æ–°çš„å¯ç”¨æ¨¡å‹ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
        models_to_try = [
            'gemini-2.0-flash',      # æœ€æ–° 2.0 æ¨¡å‹
            'gemini-1.5-flash',      # å¦‚æœæœ‰ä½¿ç”¨è¨˜éŒ„
            'gemini-1.5-pro',        # å¦‚æœæœ‰ä½¿ç”¨è¨˜éŒ„
            'gemini-pro',            # èˆŠç‰ˆå‚™ç”¨
            'models/gemini-pro'      # å®Œæ•´è·¯å¾‘
        ]
        
        for model_name in models_to_try:
            try:
                test_model = genai.GenerativeModel(model_name)
                # é€²è¡Œç°¡å–®æ¸¬è©¦
                test_response = test_model.generate_content("Hello")
                if test_response and test_response.text:
                    model = test_model
                    logger.info(f"âœ… Gemini AI æˆåŠŸåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
                    break
            except Exception as e:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} ä¸å¯ç”¨: {e}")
                continue
        
        if not model:
            logger.error("âŒ æ‰€æœ‰ Gemini æ¨¡å‹éƒ½ä¸å¯ç”¨")
            
    except Exception as e:
        logger.error(f"âŒ Gemini AI åˆå§‹åŒ–å¤±æ•—: {e}")
else:
    logger.warning("âš ï¸ Gemini API key not found")

def get_ai_response(query, student_id=None):
    """å–å¾— AI å›æ‡‰ - æ”¯æ´å¤šç¨®æ¨¡å‹"""
    try:
        if not model:
            logger.error("âŒ AI æ¨¡å‹æœªåˆå§‹åŒ–")
            return "æŠ±æ­‰ï¼ŒAI æœå‹™ç›®å‰ç„¡æ³•ä½¿ç”¨ã€‚ç³»çµ±å¯èƒ½éœ€è¦å‡ç´šæ¨¡å‹ç‰ˆæœ¬ã€‚"
        
        if not query or len(query.strip()) == 0:
            return "è«‹æä¾›æ‚¨çš„å•é¡Œï¼Œæˆ‘å¾ˆæ¨‚æ„ç‚ºæ‚¨è§£ç­”ï¼"
        
        # å–å¾—å­¸ç”Ÿè³‡è¨Š
        student_context = ""
        if student_id:
            try:
                student = Student.get_by_id(student_id)
                student_context = f"å­¸ç”Ÿï¼š{student.name}ï¼Œåƒèˆ‡åº¦ï¼š{student.participation_rate}%"
            except Exception as e:
                logger.warning(f"ç„¡æ³•å–å¾—å­¸ç”Ÿè³‡è¨Š: {e}")
        
        # æ§‹å»ºç°¡åŒ–çš„æç¤ºè©ï¼ˆé©ç”¨æ–¼å„ç¨®æ¨¡å‹ï¼‰
        prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æ•™å­¸åŠ©ç†ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡æ½”å›ç­”ï¼š

{student_context}

å•é¡Œï¼š{query}

å›ç­”ï¼ˆ100å­—å…§ï¼‰ï¼š"""
        
        logger.info(f"ğŸ¤– æ­£åœ¨ç”Ÿæˆ AI å›æ‡‰...")
        
        # åŸºæœ¬ç”Ÿæˆé…ç½®
        try:
            response = model.generate_content(
                prompt,
                generation_config={
                    'max_output_tokens': 200,
                    'temperature': 0.7,
                }
            )
        except:
            # å¦‚æœé…ç½®å¤±æ•—ï¼Œä½¿ç”¨åŸºæœ¬æ–¹å¼
            response = model.generate_content(prompt)
        
        if response and hasattr(response, 'text') and response.text:
            ai_response = response.text.strip()
            logger.info(f"âœ… AI å›æ‡‰æˆåŠŸï¼Œé•·åº¦: {len(ai_response)} å­—")
            return ai_response
        elif response and hasattr(response, 'candidates') and response.candidates:
            # è™•ç†å€™é¸å›æ‡‰
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and candidate.content:
                ai_response = candidate.content.parts[0].text.strip()
                logger.info(f"âœ… AI å›æ‡‰æˆåŠŸï¼ˆå€™é¸ï¼‰ï¼Œé•·åº¦: {len(ai_response)} å­—")
                return ai_response
        
        logger.error("âŒ AI å›æ‡‰ç‚ºç©º")
        return "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•ç”Ÿæˆé©ç•¶çš„å›æ‡‰ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"
            
    except Exception as e:
        error_msg = str(e).lower()
        logger.error(f"âŒ AI å›æ‡‰éŒ¯èª¤: {str(e)}")
        
        # æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›é©ç•¶å›æ‡‰
        if "404" in error_msg or "not found" in error_msg:
            return "AI æ¨¡å‹æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚ç³»çµ±å¯èƒ½éœ€è¦æ›´æ–°æ¨¡å‹ç‰ˆæœ¬ã€‚"
        elif "quota" in error_msg or "limit" in error_msg or "exceeded" in error_msg:
            return "AI æœå‹™ä½¿ç”¨é‡å·²é”ä¸Šé™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        elif "permission" in error_msg or "denied" in error_msg:
            return "AI æœå‹™æ¬Šé™æœ‰å•é¡Œï¼Œè«‹æª¢æŸ¥ API è¨­å®šã€‚"
        elif "unavailable" in error_msg:
            return "æ‚¨çš„å°ˆæ¡ˆå¯èƒ½ç„¡æ³•ä½¿ç”¨è¼ƒæ–°çš„ Gemini æ¨¡å‹ï¼Œè«‹è¯çµ¡ç®¡ç†å“¡ã€‚"
        else:
            return "è™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

def analyze_student_patterns(student_id):
    """åˆ†æå­¸ç”Ÿå­¸ç¿’æ¨¡å¼"""
    try:
        if not model:
            logger.warning("âš ï¸ AI æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
            return None
            
        student = Student.get_by_id(student_id)
        
        # å–å¾—æœ€è¿‘è¨Šæ¯
        recent_messages = list(Message.select().where(
            Message.student == student
        ).order_by(Message.timestamp.desc()).limit(5))
        
        if not recent_messages:
            return "è©²å­¸ç”Ÿäº’å‹•è¨˜éŒ„ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚"
        
        # ç°¡åŒ–åˆ†ææç¤º
        messages_text = [msg.content[:50] for msg in recent_messages]
        analysis_prompt = f"""åˆ†æå­¸ç”Ÿå­¸ç¿’æ¨¡å¼ï¼š

å­¸ç”Ÿï¼š{student.name}
ç™¼è¨€ï¼š{student.message_count}æ¬¡
æå•ï¼š{student.question_count}æ¬¡

è¿‘æœŸå…§å®¹ï¼š{', '.join(messages_text)}

è«‹ç”¨50å­—å…§åˆ†æå­¸ç¿’é¢¨æ ¼ï¼š"""
        
        try:
            response = model.generate_content(analysis_prompt)
            if response and hasattr(response, 'text') and response.text:
                return response.text.strip()
        except:
            pass
            
        return "ç„¡æ³•é€²è¡ŒAIåˆ†æï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            
    except Exception as e:
        logger.error(f"âŒ å­¸ç¿’æ¨¡å¼åˆ†æéŒ¯èª¤: {e}")
        return None

def list_available_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    try:
        if not GEMINI_API_KEY:
            return []
        
        genai.configure(api_key=GEMINI_API_KEY)
        models = []
        
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    models.append(m.name)
        except Exception as e:
            logger.warning(f"ç„¡æ³•åˆ—å‡ºæ¨¡å‹: {e}")
            # è¿”å›å¯èƒ½å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
            models = [
                'gemini-2.0-flash',
                'gemini-1.5-flash', 
                'gemini-1.5-pro',
                'gemini-pro'
            ]
            
        return models
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ¨¡å‹æ™‚éŒ¯èª¤: {e}")
        return []

def test_ai_connection():
    """æ¸¬è©¦ AI é€£æ¥"""
    try:
        if not model:
            return False, "AI æ¨¡å‹æœªåˆå§‹åŒ–"
        
        # ç°¡å–®æ¸¬è©¦
        test_response = model.generate_content("Hi")
        
        if test_response and hasattr(test_response, 'text') and test_response.text:
            return True, f"é€£æ¥æ­£å¸¸ï¼Œå›æ‡‰: {test_response.text[:30]}..."
        elif test_response and hasattr(test_response, 'candidates'):
            return True, "é€£æ¥æ­£å¸¸ï¼ˆå€™é¸å›æ‡‰æ ¼å¼ï¼‰"
        else:
            return False, "å›æ‡‰æ ¼å¼ç•°å¸¸"
            
    except Exception as e:
        return False, f"é€£æ¥éŒ¯èª¤: {str(e)[:50]}..."

def get_model_info():
    """å–å¾—ç•¶å‰æ¨¡å‹è³‡è¨Š"""
    if not model:
        return "æœªåˆå§‹åŒ–"
    
    try:
        return getattr(model, 'model_name', 'æœªçŸ¥æ¨¡å‹')
    except:
        return "æ¨¡å‹è³‡è¨Šç„¡æ³•å–å¾—"

def update_student_stats(student_id):
    """æ›´æ–°å­¸ç”Ÿçµ±è¨ˆè³‡æ–™"""
    try:
        student = Student.get_by_id(student_id)
        student.update_stats()
        logger.info(f"âœ… æ›´æ–°å­¸ç”Ÿçµ±è¨ˆ: {student.name}")
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°çµ±è¨ˆéŒ¯èª¤: {e}")

def create_sample_data():
    """å»ºç«‹ç¯„ä¾‹è³‡æ–™"""
    try:
        sample_students = [
            {
                'name': '[DEMO] ç‹å°æ˜',
                'line_user_id': 'demo_student_001',
                'message_count': 25,
                'question_count': 8,
                'participation_rate': 75.5,
                'question_rate': 32.0,
                'learning_style': 'ä¸»å‹•æ¢ç´¢å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            },
            {
                'name': '[DEMO] æç¾è¯',
                'line_user_id': 'demo_student_002', 
                'message_count': 18,
                'question_count': 12,
                'participation_rate': 68.2,
                'question_rate': 66.7,
                'learning_style': 'å•é¡Œå°å‘å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            },
            {
                'name': '[DEMO] John Smith',
                'line_user_id': 'demo_student_003',
                'message_count': 32,
                'question_count': 5,
                'participation_rate': 82.3,
                'question_rate': 15.6,
                'learning_style': 'å¯¦ä½œå°å‘å‹',
                'notes': 'ç³»çµ±æ¼”ç¤ºç”¨è™›æ“¬å­¸ç”Ÿè³‡æ–™'
            }
        ]
        
        for student_data in sample_students:
            try:
                existing = Student.select().where(
                    Student.line_user_id == student_data['line_user_id']
                ).first()
                
                if not existing:
                    student = Student.create(**{
                        **student_data,
                        'created_at': datetime.datetime.now() - datetime.timedelta(days=random.randint(1, 30)),
                        'last_active': datetime.datetime.now() - datetime.timedelta(hours=random.randint(1, 48))
                    })
                    
                    create_sample_messages(student)
                    logger.info(f"âœ… å»ºç«‹æ¼”ç¤ºå­¸ç”Ÿ: {student.name}")
                    
            except Exception as e:
                logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºå­¸ç”ŸéŒ¯èª¤: {e}")
                
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºè³‡æ–™éŒ¯èª¤: {e}")

def create_sample_messages(student):
    """å»ºç«‹æ¼”ç¤ºè¨Šæ¯"""
    try:
        sample_messages = [
            {'content': 'è€å¸«å¥½ï¼Œè«‹å•ä»Šå¤©çš„ä½œæ¥­è¦æ€éº¼åšï¼Ÿ', 'type': 'question'},
            {'content': 'æˆ‘è¦ºå¾—é€™å€‹æ¦‚å¿µå¾ˆæœ‰è¶£ï¼', 'type': 'statement'},
            {'content': 'å¯ä»¥å†è§£é‡‹ä¸€ä¸‹ machine learning å—ï¼Ÿ', 'type': 'question'},
            {'content': 'è¬è¬è€å¸«çš„èªªæ˜', 'type': 'statement'},
            {'content': 'What is the difference between AI and ML?', 'type': 'question'},
        ]
        
        messages_to_create = min(len(sample_messages), student.message_count)
        
        for i in range(messages_to_create):
            msg_data = sample_messages[i % len(sample_messages)]
            Message.create(
                student=student,
                content=msg_data['content'],
                message_type=msg_data['type'],
                timestamp=datetime.datetime.now() - datetime.timedelta(hours=random.randint(1, 72)),
                source_type='demo'
            )
                
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹æ¼”ç¤ºè¨Šæ¯éŒ¯èª¤: {e}")

def validate_environment():
    """é©—è­‰ç’°å¢ƒè®Šæ•¸"""
    required_vars = ['GEMINI_API_KEY', 'CHANNEL_ACCESS_TOKEN', 'CHANNEL_SECRET']
    missing_vars = []
    
    for var in required_vars:
        value = os.getenv(var) or os.getenv(f'LINE_{var}')
        if not value:
            missing_vars.append(var)
    
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘ç’°å¢ƒè®Šæ•¸: {', '.join(missing_vars)}")
        return False
    
    logger.info("âœ… ç’°å¢ƒè®Šæ•¸é©—è­‰é€šé")
    return True

def get_system_status():
    """å–å¾—ç³»çµ±ç‹€æ…‹"""
    try:
        ai_ok, ai_msg = test_ai_connection()
        available_models = list_available_models()
        
        status = {
            'database': 'connected' if not db.is_closed() else 'disconnected',
            'ai_service': 'available' if ai_ok else 'error',
            'ai_message': ai_msg,
            'current_model': get_model_info(),
            'available_models': available_models[:5],  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
            'total_students': Student.select().count(),
            'real_students': Student.select().where(~Student.name.startswith('[DEMO]')).count(),
            'demo_students': Student.select().where(Student.name.startswith('[DEMO]')).count(),
            'total_messages': Message.select().count(),
            'last_update': datetime.datetime.now().isoformat(),
            'sdk_warning': 'google-generativeai SDK å°‡æ–¼ 2025å¹´8æœˆ31æ—¥åœæ­¢æ”¯æ´'
        }
        
        return status
        
    except Exception as e:
        logger.error(f"âŒ å–å¾—ç³»çµ±ç‹€æ…‹éŒ¯èª¤: {e}")
        return {'error': str(e)}

def initialize_utils():
    """åˆå§‹åŒ–å·¥å…·æ¨¡çµ„"""
    logger.info("ğŸ”§ åˆå§‹åŒ– utils æ¨¡çµ„...")
    
    env_ok = validate_environment()
    if not env_ok:
        logger.warning("âš ï¸ ç’°å¢ƒè®Šæ•¸æª¢æŸ¥æœªé€šé")
    
    ai_ok, ai_msg = test_ai_connection()
    logger.info(f"ğŸ¤– AI ç‹€æ…‹: {ai_msg}")
    
    models = list_available_models()
    if models:
        logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {', '.join(models[:3])}...")
    
    logger.info(f"ğŸ”§ ç•¶å‰ä½¿ç”¨æ¨¡å‹: {get_model_info()}")
    logger.info("âœ… Utils æ¨¡çµ„åˆå§‹åŒ–å®Œæˆ")

# è‡ªå‹•åŸ·è¡Œåˆå§‹åŒ–
initialize_utils()
